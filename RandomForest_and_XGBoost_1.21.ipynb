{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled69.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1JnO8G8KM3eaL7zL7IrR7NU-Q2MllCCtk",
      "authorship_tag": "ABX9TyNBRjThSSfASQBuc+IYqj2V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/RandomForest_and_XGBoost_1.21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOmIegf1c6s",
        "outputId": "ae5804ec-d185-422a-acba-0d5c179b9166"
      },
      "source": [
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNbbDfQ5lid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "d23788d8-4886-46e5-8847-ecf166ead027"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/result_concat_3.csv\", index_col=0, sep=\",\")\n",
        "df\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>...</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1.1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2.1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3.1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_4.1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_0.1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_1.1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_2.1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_3.1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_4.1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_0.1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_1.1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_2.1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_3.1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_4.1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_0.1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_1.1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_2.1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_3.1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_4.1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_0.1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_1.1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_2.1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_3.1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_4.1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_0.1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_1.1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_2.1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_3.1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_4.1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_0.1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_1.1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_2.1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_3.1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_4.1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_0.1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_1.1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_2.1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_3.1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_4.1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>60.885948</td>\n",
              "      <td>60.356665</td>\n",
              "      <td>50.935251</td>\n",
              "      <td>59.631753</td>\n",
              "      <td>58.965695</td>\n",
              "      <td>45.052648</td>\n",
              "      <td>60.332221</td>\n",
              "      <td>61.809397</td>\n",
              "      <td>59.062302</td>\n",
              "      <td>68.153375</td>\n",
              "      <td>51.562381</td>\n",
              "      <td>58.757454</td>\n",
              "      <td>68.297571</td>\n",
              "      <td>59.610933</td>\n",
              "      <td>55.720055</td>\n",
              "      <td>58.482534</td>\n",
              "      <td>59.504211</td>\n",
              "      <td>45.093548</td>\n",
              "      <td>58.708310</td>\n",
              "      <td>57.960665</td>\n",
              "      <td>44.306228</td>\n",
              "      <td>62.429917</td>\n",
              "      <td>47.746590</td>\n",
              "      <td>60.145330</td>\n",
              "      <td>59.885645</td>\n",
              "      <td>63.356745</td>\n",
              "      <td>62.210029</td>\n",
              "      <td>52.995640</td>\n",
              "      <td>60.519272</td>\n",
              "      <td>57.649809</td>\n",
              "      <td>63.051468</td>\n",
              "      <td>61.155617</td>\n",
              "      <td>60.746276</td>\n",
              "      <td>38.692406</td>\n",
              "      <td>57.933575</td>\n",
              "      <td>51.513016</td>\n",
              "      <td>60.443723</td>\n",
              "      <td>59.180284</td>\n",
              "      <td>57.925946</td>\n",
              "      <td>...</td>\n",
              "      <td>59.452468</td>\n",
              "      <td>60.443723</td>\n",
              "      <td>59.180284</td>\n",
              "      <td>57.925946</td>\n",
              "      <td>61.356062</td>\n",
              "      <td>50.794721</td>\n",
              "      <td>59.937066</td>\n",
              "      <td>57.612771</td>\n",
              "      <td>61.397052</td>\n",
              "      <td>46.190515</td>\n",
              "      <td>45.208085</td>\n",
              "      <td>57.761061</td>\n",
              "      <td>63.372260</td>\n",
              "      <td>58.118635</td>\n",
              "      <td>59.059167</td>\n",
              "      <td>45.416451</td>\n",
              "      <td>62.391269</td>\n",
              "      <td>46.070179</td>\n",
              "      <td>60.394639</td>\n",
              "      <td>58.396441</td>\n",
              "      <td>63.028634</td>\n",
              "      <td>60.167629</td>\n",
              "      <td>63.968348</td>\n",
              "      <td>55.218077</td>\n",
              "      <td>53.921479</td>\n",
              "      <td>61.277235</td>\n",
              "      <td>61.864400</td>\n",
              "      <td>64.423221</td>\n",
              "      <td>47.498825</td>\n",
              "      <td>39.615372</td>\n",
              "      <td>66.959667</td>\n",
              "      <td>66.500616</td>\n",
              "      <td>62.237757</td>\n",
              "      <td>48.370329</td>\n",
              "      <td>61.953497</td>\n",
              "      <td>54.935169</td>\n",
              "      <td>56.899101</td>\n",
              "      <td>60.968000</td>\n",
              "      <td>32.802081</td>\n",
              "      <td>59.452468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>29.766262</td>\n",
              "      <td>30.331397</td>\n",
              "      <td>29.118884</td>\n",
              "      <td>31.672752</td>\n",
              "      <td>30.989829</td>\n",
              "      <td>26.809660</td>\n",
              "      <td>32.241669</td>\n",
              "      <td>30.086446</td>\n",
              "      <td>30.817971</td>\n",
              "      <td>32.113385</td>\n",
              "      <td>26.403788</td>\n",
              "      <td>27.999404</td>\n",
              "      <td>31.571031</td>\n",
              "      <td>26.205668</td>\n",
              "      <td>21.942243</td>\n",
              "      <td>28.228927</td>\n",
              "      <td>28.847709</td>\n",
              "      <td>27.994281</td>\n",
              "      <td>28.715485</td>\n",
              "      <td>28.885067</td>\n",
              "      <td>26.357773</td>\n",
              "      <td>28.899875</td>\n",
              "      <td>26.704368</td>\n",
              "      <td>28.894490</td>\n",
              "      <td>28.859845</td>\n",
              "      <td>28.657392</td>\n",
              "      <td>28.822759</td>\n",
              "      <td>22.991714</td>\n",
              "      <td>28.690979</td>\n",
              "      <td>25.721887</td>\n",
              "      <td>34.075314</td>\n",
              "      <td>31.509855</td>\n",
              "      <td>33.798274</td>\n",
              "      <td>38.365373</td>\n",
              "      <td>29.952043</td>\n",
              "      <td>33.798340</td>\n",
              "      <td>32.601157</td>\n",
              "      <td>31.196275</td>\n",
              "      <td>27.557728</td>\n",
              "      <td>...</td>\n",
              "      <td>33.086747</td>\n",
              "      <td>32.601157</td>\n",
              "      <td>31.196275</td>\n",
              "      <td>27.557728</td>\n",
              "      <td>33.944768</td>\n",
              "      <td>30.446360</td>\n",
              "      <td>29.304698</td>\n",
              "      <td>26.477981</td>\n",
              "      <td>29.368344</td>\n",
              "      <td>27.883038</td>\n",
              "      <td>24.574579</td>\n",
              "      <td>28.125578</td>\n",
              "      <td>30.332983</td>\n",
              "      <td>27.869955</td>\n",
              "      <td>30.062532</td>\n",
              "      <td>28.621274</td>\n",
              "      <td>26.432323</td>\n",
              "      <td>25.892881</td>\n",
              "      <td>28.595570</td>\n",
              "      <td>27.253726</td>\n",
              "      <td>27.305934</td>\n",
              "      <td>29.994479</td>\n",
              "      <td>28.159496</td>\n",
              "      <td>25.735974</td>\n",
              "      <td>21.707861</td>\n",
              "      <td>27.959991</td>\n",
              "      <td>28.589666</td>\n",
              "      <td>28.499722</td>\n",
              "      <td>21.598046</td>\n",
              "      <td>26.380828</td>\n",
              "      <td>35.283571</td>\n",
              "      <td>41.595712</td>\n",
              "      <td>40.237117</td>\n",
              "      <td>50.527757</td>\n",
              "      <td>33.700836</td>\n",
              "      <td>30.545381</td>\n",
              "      <td>32.332805</td>\n",
              "      <td>29.989961</td>\n",
              "      <td>32.775521</td>\n",
              "      <td>33.086747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>58.364809</td>\n",
              "      <td>50.553083</td>\n",
              "      <td>63.250524</td>\n",
              "      <td>54.238850</td>\n",
              "      <td>50.851762</td>\n",
              "      <td>63.289428</td>\n",
              "      <td>54.653805</td>\n",
              "      <td>49.245375</td>\n",
              "      <td>50.571257</td>\n",
              "      <td>57.794720</td>\n",
              "      <td>49.765614</td>\n",
              "      <td>49.845201</td>\n",
              "      <td>54.795003</td>\n",
              "      <td>59.864140</td>\n",
              "      <td>54.611915</td>\n",
              "      <td>57.051009</td>\n",
              "      <td>54.708534</td>\n",
              "      <td>57.299381</td>\n",
              "      <td>49.541694</td>\n",
              "      <td>54.624343</td>\n",
              "      <td>52.290088</td>\n",
              "      <td>56.760901</td>\n",
              "      <td>47.204936</td>\n",
              "      <td>52.778614</td>\n",
              "      <td>52.187645</td>\n",
              "      <td>51.639259</td>\n",
              "      <td>53.236330</td>\n",
              "      <td>44.357553</td>\n",
              "      <td>52.916056</td>\n",
              "      <td>56.503397</td>\n",
              "      <td>47.425610</td>\n",
              "      <td>57.344145</td>\n",
              "      <td>51.043272</td>\n",
              "      <td>55.263293</td>\n",
              "      <td>48.160061</td>\n",
              "      <td>59.604460</td>\n",
              "      <td>67.162800</td>\n",
              "      <td>52.348655</td>\n",
              "      <td>52.609223</td>\n",
              "      <td>...</td>\n",
              "      <td>50.764579</td>\n",
              "      <td>67.162800</td>\n",
              "      <td>52.348655</td>\n",
              "      <td>52.609223</td>\n",
              "      <td>58.175653</td>\n",
              "      <td>49.676123</td>\n",
              "      <td>60.613930</td>\n",
              "      <td>48.423052</td>\n",
              "      <td>51.381540</td>\n",
              "      <td>53.468233</td>\n",
              "      <td>63.071638</td>\n",
              "      <td>48.292780</td>\n",
              "      <td>52.528238</td>\n",
              "      <td>50.668210</td>\n",
              "      <td>50.591427</td>\n",
              "      <td>58.855903</td>\n",
              "      <td>51.447606</td>\n",
              "      <td>50.004244</td>\n",
              "      <td>49.102244</td>\n",
              "      <td>52.055264</td>\n",
              "      <td>51.907486</td>\n",
              "      <td>50.094593</td>\n",
              "      <td>50.960755</td>\n",
              "      <td>52.623403</td>\n",
              "      <td>58.816636</td>\n",
              "      <td>49.755389</td>\n",
              "      <td>53.065294</td>\n",
              "      <td>58.409935</td>\n",
              "      <td>55.093735</td>\n",
              "      <td>55.827039</td>\n",
              "      <td>53.996080</td>\n",
              "      <td>54.605067</td>\n",
              "      <td>49.949187</td>\n",
              "      <td>61.310375</td>\n",
              "      <td>54.841155</td>\n",
              "      <td>50.700021</td>\n",
              "      <td>48.117417</td>\n",
              "      <td>53.539336</td>\n",
              "      <td>62.086725</td>\n",
              "      <td>50.764579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.213056</td>\n",
              "      <td>31.123018</td>\n",
              "      <td>29.923308</td>\n",
              "      <td>31.866950</td>\n",
              "      <td>31.424466</td>\n",
              "      <td>33.026874</td>\n",
              "      <td>27.775347</td>\n",
              "      <td>31.257206</td>\n",
              "      <td>30.184183</td>\n",
              "      <td>31.335768</td>\n",
              "      <td>28.773826</td>\n",
              "      <td>28.549322</td>\n",
              "      <td>29.491693</td>\n",
              "      <td>27.227801</td>\n",
              "      <td>29.133636</td>\n",
              "      <td>28.235692</td>\n",
              "      <td>31.660154</td>\n",
              "      <td>30.401087</td>\n",
              "      <td>29.131159</td>\n",
              "      <td>27.815926</td>\n",
              "      <td>33.806103</td>\n",
              "      <td>34.369171</td>\n",
              "      <td>30.322504</td>\n",
              "      <td>30.721486</td>\n",
              "      <td>30.021170</td>\n",
              "      <td>27.490881</td>\n",
              "      <td>30.023479</td>\n",
              "      <td>23.335579</td>\n",
              "      <td>29.751483</td>\n",
              "      <td>28.661990</td>\n",
              "      <td>33.212128</td>\n",
              "      <td>37.661710</td>\n",
              "      <td>37.906623</td>\n",
              "      <td>35.059234</td>\n",
              "      <td>30.629086</td>\n",
              "      <td>32.447189</td>\n",
              "      <td>34.168077</td>\n",
              "      <td>30.493429</td>\n",
              "      <td>29.301286</td>\n",
              "      <td>...</td>\n",
              "      <td>33.655614</td>\n",
              "      <td>34.168077</td>\n",
              "      <td>30.493429</td>\n",
              "      <td>29.301286</td>\n",
              "      <td>33.749220</td>\n",
              "      <td>31.672558</td>\n",
              "      <td>29.825637</td>\n",
              "      <td>29.177326</td>\n",
              "      <td>31.059107</td>\n",
              "      <td>28.019741</td>\n",
              "      <td>29.460776</td>\n",
              "      <td>28.995550</td>\n",
              "      <td>30.806449</td>\n",
              "      <td>31.359655</td>\n",
              "      <td>30.032742</td>\n",
              "      <td>31.992900</td>\n",
              "      <td>26.391345</td>\n",
              "      <td>27.324587</td>\n",
              "      <td>28.775471</td>\n",
              "      <td>32.848647</td>\n",
              "      <td>31.013748</td>\n",
              "      <td>26.702192</td>\n",
              "      <td>24.901672</td>\n",
              "      <td>27.801692</td>\n",
              "      <td>21.340437</td>\n",
              "      <td>28.522485</td>\n",
              "      <td>29.261309</td>\n",
              "      <td>28.128195</td>\n",
              "      <td>25.244799</td>\n",
              "      <td>26.992267</td>\n",
              "      <td>36.704639</td>\n",
              "      <td>38.350153</td>\n",
              "      <td>35.942692</td>\n",
              "      <td>47.493604</td>\n",
              "      <td>35.055676</td>\n",
              "      <td>27.620485</td>\n",
              "      <td>30.764979</td>\n",
              "      <td>30.090940</td>\n",
              "      <td>38.280925</td>\n",
              "      <td>33.655614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.485062</td>\n",
              "      <td>31.811762</td>\n",
              "      <td>30.549696</td>\n",
              "      <td>32.765386</td>\n",
              "      <td>31.352851</td>\n",
              "      <td>35.573980</td>\n",
              "      <td>32.451853</td>\n",
              "      <td>30.288148</td>\n",
              "      <td>31.099230</td>\n",
              "      <td>30.537629</td>\n",
              "      <td>29.595745</td>\n",
              "      <td>27.726558</td>\n",
              "      <td>31.044161</td>\n",
              "      <td>32.806641</td>\n",
              "      <td>29.797870</td>\n",
              "      <td>29.842737</td>\n",
              "      <td>28.483209</td>\n",
              "      <td>29.473320</td>\n",
              "      <td>28.350401</td>\n",
              "      <td>31.485087</td>\n",
              "      <td>32.985473</td>\n",
              "      <td>37.007666</td>\n",
              "      <td>28.809839</td>\n",
              "      <td>28.963286</td>\n",
              "      <td>29.689914</td>\n",
              "      <td>26.915285</td>\n",
              "      <td>28.129721</td>\n",
              "      <td>24.725600</td>\n",
              "      <td>28.009915</td>\n",
              "      <td>28.578359</td>\n",
              "      <td>31.528470</td>\n",
              "      <td>32.324287</td>\n",
              "      <td>38.401335</td>\n",
              "      <td>32.143921</td>\n",
              "      <td>30.726725</td>\n",
              "      <td>40.375280</td>\n",
              "      <td>33.965418</td>\n",
              "      <td>29.740995</td>\n",
              "      <td>29.303265</td>\n",
              "      <td>...</td>\n",
              "      <td>31.945181</td>\n",
              "      <td>33.965418</td>\n",
              "      <td>29.740995</td>\n",
              "      <td>29.303265</td>\n",
              "      <td>34.901044</td>\n",
              "      <td>28.703645</td>\n",
              "      <td>28.300020</td>\n",
              "      <td>27.297571</td>\n",
              "      <td>30.610925</td>\n",
              "      <td>27.929401</td>\n",
              "      <td>31.178254</td>\n",
              "      <td>29.032320</td>\n",
              "      <td>29.705697</td>\n",
              "      <td>27.765700</td>\n",
              "      <td>33.182472</td>\n",
              "      <td>31.730193</td>\n",
              "      <td>27.523825</td>\n",
              "      <td>26.797888</td>\n",
              "      <td>29.070142</td>\n",
              "      <td>31.052959</td>\n",
              "      <td>28.335732</td>\n",
              "      <td>27.585560</td>\n",
              "      <td>29.050910</td>\n",
              "      <td>27.625880</td>\n",
              "      <td>24.823041</td>\n",
              "      <td>30.414790</td>\n",
              "      <td>29.290730</td>\n",
              "      <td>30.451465</td>\n",
              "      <td>22.950853</td>\n",
              "      <td>27.947775</td>\n",
              "      <td>41.916993</td>\n",
              "      <td>34.301230</td>\n",
              "      <td>36.889029</td>\n",
              "      <td>42.366844</td>\n",
              "      <td>34.267986</td>\n",
              "      <td>29.653075</td>\n",
              "      <td>34.019947</td>\n",
              "      <td>31.958094</td>\n",
              "      <td>30.553010</td>\n",
              "      <td>31.945181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>38.199157</td>\n",
              "      <td>39.335907</td>\n",
              "      <td>38.415360</td>\n",
              "      <td>40.701389</td>\n",
              "      <td>37.806478</td>\n",
              "      <td>37.474301</td>\n",
              "      <td>32.679823</td>\n",
              "      <td>31.805116</td>\n",
              "      <td>37.843254</td>\n",
              "      <td>33.726096</td>\n",
              "      <td>36.371392</td>\n",
              "      <td>49.667397</td>\n",
              "      <td>39.193630</td>\n",
              "      <td>38.588050</td>\n",
              "      <td>34.526837</td>\n",
              "      <td>38.396522</td>\n",
              "      <td>35.274139</td>\n",
              "      <td>38.497335</td>\n",
              "      <td>38.434505</td>\n",
              "      <td>34.112072</td>\n",
              "      <td>35.426679</td>\n",
              "      <td>35.021561</td>\n",
              "      <td>28.289860</td>\n",
              "      <td>35.640907</td>\n",
              "      <td>36.847824</td>\n",
              "      <td>37.365493</td>\n",
              "      <td>46.835411</td>\n",
              "      <td>31.393817</td>\n",
              "      <td>38.262957</td>\n",
              "      <td>42.541334</td>\n",
              "      <td>36.452386</td>\n",
              "      <td>44.501454</td>\n",
              "      <td>43.832183</td>\n",
              "      <td>44.443870</td>\n",
              "      <td>36.340073</td>\n",
              "      <td>42.409110</td>\n",
              "      <td>40.077686</td>\n",
              "      <td>37.977579</td>\n",
              "      <td>36.893642</td>\n",
              "      <td>...</td>\n",
              "      <td>37.632969</td>\n",
              "      <td>40.077686</td>\n",
              "      <td>37.977579</td>\n",
              "      <td>36.893642</td>\n",
              "      <td>42.594829</td>\n",
              "      <td>39.264897</td>\n",
              "      <td>37.870255</td>\n",
              "      <td>35.099649</td>\n",
              "      <td>38.703468</td>\n",
              "      <td>34.652242</td>\n",
              "      <td>31.834236</td>\n",
              "      <td>34.224910</td>\n",
              "      <td>31.262583</td>\n",
              "      <td>33.991134</td>\n",
              "      <td>38.869512</td>\n",
              "      <td>35.793000</td>\n",
              "      <td>35.120636</td>\n",
              "      <td>26.139495</td>\n",
              "      <td>35.731488</td>\n",
              "      <td>29.872346</td>\n",
              "      <td>44.848314</td>\n",
              "      <td>51.827860</td>\n",
              "      <td>44.909871</td>\n",
              "      <td>31.455088</td>\n",
              "      <td>40.449962</td>\n",
              "      <td>38.877404</td>\n",
              "      <td>52.941495</td>\n",
              "      <td>43.271992</td>\n",
              "      <td>35.293564</td>\n",
              "      <td>37.773979</td>\n",
              "      <td>35.583228</td>\n",
              "      <td>44.036415</td>\n",
              "      <td>43.149778</td>\n",
              "      <td>50.892937</td>\n",
              "      <td>35.965312</td>\n",
              "      <td>31.347474</td>\n",
              "      <td>29.877606</td>\n",
              "      <td>39.098856</td>\n",
              "      <td>34.426931</td>\n",
              "      <td>37.632969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>53.196847</td>\n",
              "      <td>45.640141</td>\n",
              "      <td>45.546347</td>\n",
              "      <td>51.625419</td>\n",
              "      <td>50.128996</td>\n",
              "      <td>48.410195</td>\n",
              "      <td>42.230716</td>\n",
              "      <td>46.253222</td>\n",
              "      <td>51.311338</td>\n",
              "      <td>51.198155</td>\n",
              "      <td>48.310232</td>\n",
              "      <td>45.538834</td>\n",
              "      <td>44.979483</td>\n",
              "      <td>52.453923</td>\n",
              "      <td>44.837600</td>\n",
              "      <td>47.394177</td>\n",
              "      <td>48.088434</td>\n",
              "      <td>49.969494</td>\n",
              "      <td>49.401051</td>\n",
              "      <td>50.176543</td>\n",
              "      <td>47.796735</td>\n",
              "      <td>57.036519</td>\n",
              "      <td>50.078702</td>\n",
              "      <td>50.911272</td>\n",
              "      <td>49.306154</td>\n",
              "      <td>49.032882</td>\n",
              "      <td>48.545510</td>\n",
              "      <td>33.817515</td>\n",
              "      <td>41.229436</td>\n",
              "      <td>50.404090</td>\n",
              "      <td>50.643623</td>\n",
              "      <td>59.744704</td>\n",
              "      <td>54.123229</td>\n",
              "      <td>57.273388</td>\n",
              "      <td>48.106965</td>\n",
              "      <td>54.108298</td>\n",
              "      <td>49.421489</td>\n",
              "      <td>48.863503</td>\n",
              "      <td>51.081926</td>\n",
              "      <td>...</td>\n",
              "      <td>51.421803</td>\n",
              "      <td>49.421489</td>\n",
              "      <td>48.863503</td>\n",
              "      <td>51.081926</td>\n",
              "      <td>55.026782</td>\n",
              "      <td>44.446120</td>\n",
              "      <td>46.082148</td>\n",
              "      <td>45.929974</td>\n",
              "      <td>50.156689</td>\n",
              "      <td>40.987971</td>\n",
              "      <td>45.965067</td>\n",
              "      <td>46.292043</td>\n",
              "      <td>51.588768</td>\n",
              "      <td>49.585876</td>\n",
              "      <td>53.223592</td>\n",
              "      <td>49.383083</td>\n",
              "      <td>52.410209</td>\n",
              "      <td>49.659091</td>\n",
              "      <td>48.516831</td>\n",
              "      <td>47.656766</td>\n",
              "      <td>52.504253</td>\n",
              "      <td>47.339574</td>\n",
              "      <td>49.313083</td>\n",
              "      <td>48.411244</td>\n",
              "      <td>54.349107</td>\n",
              "      <td>48.708078</td>\n",
              "      <td>44.102505</td>\n",
              "      <td>56.852949</td>\n",
              "      <td>48.273543</td>\n",
              "      <td>50.966114</td>\n",
              "      <td>49.529347</td>\n",
              "      <td>57.750505</td>\n",
              "      <td>62.443388</td>\n",
              "      <td>64.850932</td>\n",
              "      <td>52.418566</td>\n",
              "      <td>45.366701</td>\n",
              "      <td>56.356877</td>\n",
              "      <td>51.327443</td>\n",
              "      <td>56.484932</td>\n",
              "      <td>51.421803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>56.886828</td>\n",
              "      <td>50.544816</td>\n",
              "      <td>47.587875</td>\n",
              "      <td>52.457392</td>\n",
              "      <td>50.793570</td>\n",
              "      <td>52.799886</td>\n",
              "      <td>45.932961</td>\n",
              "      <td>44.371003</td>\n",
              "      <td>51.916403</td>\n",
              "      <td>50.504851</td>\n",
              "      <td>44.726014</td>\n",
              "      <td>42.309937</td>\n",
              "      <td>45.024800</td>\n",
              "      <td>40.706378</td>\n",
              "      <td>42.950150</td>\n",
              "      <td>55.220819</td>\n",
              "      <td>48.409539</td>\n",
              "      <td>49.657461</td>\n",
              "      <td>49.004924</td>\n",
              "      <td>47.710246</td>\n",
              "      <td>47.885427</td>\n",
              "      <td>55.062169</td>\n",
              "      <td>52.543592</td>\n",
              "      <td>51.201683</td>\n",
              "      <td>50.496775</td>\n",
              "      <td>49.698067</td>\n",
              "      <td>47.475055</td>\n",
              "      <td>29.821983</td>\n",
              "      <td>40.268657</td>\n",
              "      <td>56.234378</td>\n",
              "      <td>50.509459</td>\n",
              "      <td>53.434712</td>\n",
              "      <td>52.482903</td>\n",
              "      <td>54.819530</td>\n",
              "      <td>47.122028</td>\n",
              "      <td>56.916833</td>\n",
              "      <td>47.124928</td>\n",
              "      <td>49.280134</td>\n",
              "      <td>51.028162</td>\n",
              "      <td>...</td>\n",
              "      <td>47.501767</td>\n",
              "      <td>47.124928</td>\n",
              "      <td>49.280134</td>\n",
              "      <td>51.028162</td>\n",
              "      <td>54.305077</td>\n",
              "      <td>45.320338</td>\n",
              "      <td>45.486036</td>\n",
              "      <td>45.827433</td>\n",
              "      <td>50.921273</td>\n",
              "      <td>45.166197</td>\n",
              "      <td>45.776716</td>\n",
              "      <td>43.373102</td>\n",
              "      <td>52.698910</td>\n",
              "      <td>50.443983</td>\n",
              "      <td>50.774556</td>\n",
              "      <td>50.571752</td>\n",
              "      <td>50.687742</td>\n",
              "      <td>45.854795</td>\n",
              "      <td>48.858061</td>\n",
              "      <td>47.505662</td>\n",
              "      <td>49.167371</td>\n",
              "      <td>44.990662</td>\n",
              "      <td>43.962091</td>\n",
              "      <td>37.034979</td>\n",
              "      <td>45.219013</td>\n",
              "      <td>47.632921</td>\n",
              "      <td>47.237745</td>\n",
              "      <td>51.599389</td>\n",
              "      <td>49.923894</td>\n",
              "      <td>52.648532</td>\n",
              "      <td>43.682286</td>\n",
              "      <td>51.910472</td>\n",
              "      <td>57.996839</td>\n",
              "      <td>63.871813</td>\n",
              "      <td>53.339827</td>\n",
              "      <td>41.465706</td>\n",
              "      <td>50.168627</td>\n",
              "      <td>47.388595</td>\n",
              "      <td>50.673580</td>\n",
              "      <td>47.501767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>56.605852</td>\n",
              "      <td>71.386600</td>\n",
              "      <td>74.264765</td>\n",
              "      <td>73.703772</td>\n",
              "      <td>72.917128</td>\n",
              "      <td>68.061024</td>\n",
              "      <td>74.160743</td>\n",
              "      <td>74.606669</td>\n",
              "      <td>42.933744</td>\n",
              "      <td>78.277564</td>\n",
              "      <td>73.981255</td>\n",
              "      <td>69.788361</td>\n",
              "      <td>79.573733</td>\n",
              "      <td>68.793005</td>\n",
              "      <td>71.677345</td>\n",
              "      <td>70.824075</td>\n",
              "      <td>70.887142</td>\n",
              "      <td>74.848467</td>\n",
              "      <td>73.488754</td>\n",
              "      <td>73.900068</td>\n",
              "      <td>71.458507</td>\n",
              "      <td>79.234850</td>\n",
              "      <td>59.871906</td>\n",
              "      <td>43.737605</td>\n",
              "      <td>69.913667</td>\n",
              "      <td>70.363796</td>\n",
              "      <td>72.958624</td>\n",
              "      <td>59.976119</td>\n",
              "      <td>71.317726</td>\n",
              "      <td>78.840834</td>\n",
              "      <td>68.769974</td>\n",
              "      <td>62.816906</td>\n",
              "      <td>66.310376</td>\n",
              "      <td>50.796282</td>\n",
              "      <td>63.409376</td>\n",
              "      <td>73.446184</td>\n",
              "      <td>73.985189</td>\n",
              "      <td>72.136509</td>\n",
              "      <td>41.176051</td>\n",
              "      <td>...</td>\n",
              "      <td>62.333030</td>\n",
              "      <td>73.985189</td>\n",
              "      <td>72.136509</td>\n",
              "      <td>41.176051</td>\n",
              "      <td>74.108410</td>\n",
              "      <td>71.727496</td>\n",
              "      <td>73.163122</td>\n",
              "      <td>71.883512</td>\n",
              "      <td>50.149459</td>\n",
              "      <td>42.128849</td>\n",
              "      <td>62.418151</td>\n",
              "      <td>72.725224</td>\n",
              "      <td>70.131874</td>\n",
              "      <td>40.971538</td>\n",
              "      <td>67.298412</td>\n",
              "      <td>70.631576</td>\n",
              "      <td>70.113695</td>\n",
              "      <td>67.158145</td>\n",
              "      <td>38.507593</td>\n",
              "      <td>71.599281</td>\n",
              "      <td>69.768119</td>\n",
              "      <td>72.111243</td>\n",
              "      <td>71.698058</td>\n",
              "      <td>59.377652</td>\n",
              "      <td>66.876441</td>\n",
              "      <td>71.785337</td>\n",
              "      <td>71.052480</td>\n",
              "      <td>54.430097</td>\n",
              "      <td>75.378466</td>\n",
              "      <td>68.461561</td>\n",
              "      <td>50.635380</td>\n",
              "      <td>58.496195</td>\n",
              "      <td>65.064138</td>\n",
              "      <td>62.762278</td>\n",
              "      <td>63.558018</td>\n",
              "      <td>65.622163</td>\n",
              "      <td>66.379267</td>\n",
              "      <td>69.048905</td>\n",
              "      <td>58.793271</td>\n",
              "      <td>62.333030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>69.049191</td>\n",
              "      <td>66.318005</td>\n",
              "      <td>73.155653</td>\n",
              "      <td>73.523390</td>\n",
              "      <td>72.985840</td>\n",
              "      <td>66.385049</td>\n",
              "      <td>68.927622</td>\n",
              "      <td>68.367136</td>\n",
              "      <td>53.513491</td>\n",
              "      <td>75.332546</td>\n",
              "      <td>74.130625</td>\n",
              "      <td>71.575391</td>\n",
              "      <td>88.524705</td>\n",
              "      <td>60.911018</td>\n",
              "      <td>71.346241</td>\n",
              "      <td>68.293542</td>\n",
              "      <td>72.224498</td>\n",
              "      <td>74.863398</td>\n",
              "      <td>72.767866</td>\n",
              "      <td>71.941185</td>\n",
              "      <td>73.264325</td>\n",
              "      <td>76.172227</td>\n",
              "      <td>64.452952</td>\n",
              "      <td>60.746992</td>\n",
              "      <td>71.590483</td>\n",
              "      <td>72.297430</td>\n",
              "      <td>71.659863</td>\n",
              "      <td>77.320302</td>\n",
              "      <td>67.448586</td>\n",
              "      <td>84.819227</td>\n",
              "      <td>68.363243</td>\n",
              "      <td>61.668277</td>\n",
              "      <td>61.990064</td>\n",
              "      <td>61.996752</td>\n",
              "      <td>69.304931</td>\n",
              "      <td>75.359941</td>\n",
              "      <td>75.762445</td>\n",
              "      <td>74.979699</td>\n",
              "      <td>58.212060</td>\n",
              "      <td>...</td>\n",
              "      <td>73.169208</td>\n",
              "      <td>75.762445</td>\n",
              "      <td>74.979699</td>\n",
              "      <td>58.212060</td>\n",
              "      <td>77.444780</td>\n",
              "      <td>72.709912</td>\n",
              "      <td>71.166813</td>\n",
              "      <td>73.550236</td>\n",
              "      <td>63.982975</td>\n",
              "      <td>61.108553</td>\n",
              "      <td>67.346680</td>\n",
              "      <td>71.876681</td>\n",
              "      <td>72.344667</td>\n",
              "      <td>52.216482</td>\n",
              "      <td>65.165257</td>\n",
              "      <td>71.095788</td>\n",
              "      <td>72.969925</td>\n",
              "      <td>64.384335</td>\n",
              "      <td>40.342388</td>\n",
              "      <td>66.356200</td>\n",
              "      <td>77.711433</td>\n",
              "      <td>72.259676</td>\n",
              "      <td>68.837053</td>\n",
              "      <td>56.474066</td>\n",
              "      <td>68.393230</td>\n",
              "      <td>70.054871</td>\n",
              "      <td>71.892542</td>\n",
              "      <td>64.663768</td>\n",
              "      <td>76.430416</td>\n",
              "      <td>68.551928</td>\n",
              "      <td>57.218838</td>\n",
              "      <td>69.687325</td>\n",
              "      <td>72.499788</td>\n",
              "      <td>58.394593</td>\n",
              "      <td>71.370292</td>\n",
              "      <td>65.477729</td>\n",
              "      <td>61.437380</td>\n",
              "      <td>67.572218</td>\n",
              "      <td>58.184642</td>\n",
              "      <td>73.169208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 115 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_CLAHE_B3_ver2_pretrained_4.1\n",
              "filename                    ...                                       \n",
              "img00085008_00_1R.jpg   61  ...                              59.452468\n",
              "img00085024_00_1R.jpg   29  ...                              33.086747\n",
              "img00241280_10_1R.jpg   51  ...                              50.764579\n",
              "img00265140_00_1R.jpg   29  ...                              33.655614\n",
              "img00265140_00_2L.jpg   29  ...                              31.945181\n",
              "...                    ...  ...                                    ...\n",
              "img76791392_10_1R.jpg   38  ...                              37.632969\n",
              "img76843122_10_1R.jpg   49  ...                              51.421803\n",
              "img76843122_11_1R.jpg   49  ...                              47.501767\n",
              "img76888512_00_1R.jpg   74  ...                              62.333030\n",
              "img76888512_00_2L.jpg   74  ...                              73.169208\n",
              "\n",
              "[1414 rows x 115 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mqY5TnHxuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb12a80-3370-44df-f7d1-3052e2c4f78c"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df.columns.values[1:].tolist()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cropped_2_A2_GaussianBlur_pretrained_0', 'cropped_2_A2_GaussianBlur_pretrained_1', 'cropped_2_A2_GaussianBlur_pretrained_2', 'cropped_2_A2_GaussianBlur_pretrained_3', 'cropped_2_A2_GaussianBlur_pretrained_4', 'disc_2_A2_GaussianBlur_pretrained_0', 'disc_2_A2_GaussianBlur_pretrained_1', 'disc_2_A2_GaussianBlur_pretrained_2', 'disc_2_A2_GaussianBlur_pretrained_3', 'disc_2_A2_GaussianBlur_pretrained_4', 'macula_2_A2_GaussianBlur_pretrained_0', 'macula_2_A2_GaussianBlur_pretrained_1', 'macula_2_A2_GaussianBlur_pretrained_2', 'macula_2_A2_GaussianBlur_pretrained_3', 'macula_2_A2_GaussianBlur_pretrained_4', 'cropped_2_B3_GaussianBlur_pretrained_0', 'cropped_2_B3_GaussianBlur_pretrained_1', 'cropped_2_B3_GaussianBlur_pretrained_2', 'cropped_2_B3_GaussianBlur_pretrained_3', 'cropped_2_B3_GaussianBlur_pretrained_4', 'disc_2_B3_GaussianBlur_pretrained_0', 'disc_2_B3_GaussianBlur_pretrained_1', 'disc_2_B3_GaussianBlur_pretrained_2', 'disc_2_B3_GaussianBlur_pretrained_3', 'disc_2_B3_GaussianBlur_pretrained_4', 'macula_2_B3_GaussianBlur_pretrained_0', 'macula_2_B3_GaussianBlur_pretrained_1', 'macula_2_B3_GaussianBlur_pretrained_2', 'macula_2_B3_GaussianBlur_pretrained_3', 'macula_2_B3_GaussianBlur_pretrained_4', 'vascular_2_RGB_B3_GaussianBlur_pretrained_0', 'vascular_2_RGB_B3_GaussianBlur_pretrained_1', 'vascular_2_RGB_B3_GaussianBlur_pretrained_2', 'vascular_2_RGB_B3_GaussianBlur_pretrained_3', 'vascular_2_RGB_B3_GaussianBlur_pretrained_4', 'cropped_CLAHE_A2_ver2_pretrained_0', 'cropped_CLAHE_A2_ver2_pretrained_1', 'cropped_CLAHE_A2_ver2_pretrained_2', 'cropped_CLAHE_A2_ver2_pretrained_3', 'cropped_CLAHE_A2_ver2_pretrained_4', 'cropped_CLAHE_B3_ver2_pretrained_0', 'cropped_CLAHE_B3_ver2_pretrained_1', 'cropped_CLAHE_B3_ver2_pretrained_2', 'cropped_CLAHE_B3_ver2_pretrained_3', 'cropped_CLAHE_B3_ver2_pretrained_4', 'disc_CLAHE_A2_ver2_pretrained_0', 'disc_CLAHE_A2_ver2_pretrained_1', 'disc_CLAHE_A2_ver2_pretrained_2', 'disc_CLAHE_A2_ver2_pretrained_3', 'disc_CLAHE_A2_ver2_pretrained_4', 'disc_CLAHE_B3_ver2_pretrained_0', 'disc_CLAHE_B3_ver2_pretrained_1', 'disc_CLAHE_B3_ver2_pretrained_2', 'disc_CLAHE_B3_ver2_pretrained_3', 'disc_CLAHE_B3_ver2_pretrained_4', 'macula_CLAHE_A2_ver2_pretrained_0', 'macula_CLAHE_A2_ver2_pretrained_1', 'macula_CLAHE_A2_ver2_pretrained_2', 'macula_CLAHE_A2_ver2_pretrained_3', 'macula_CLAHE_A2_ver2_pretrained_4', 'macula_CLAHE_B3_ver2_pretrained_0', 'macula_CLAHE_B3_ver2_pretrained_1', 'macula_CLAHE_B3_ver2_pretrained_2', 'macula_CLAHE_B3_ver2_pretrained_3', 'macula_CLAHE_B3_ver2_pretrained_4', 'vascular_CLAHE_A2_ver2_pretrained_0', 'vascular_CLAHE_A2_ver2_pretrained_1', 'vascular_CLAHE_A2_ver2_pretrained_2', 'vascular_CLAHE_A2_ver2_pretrained_3', 'vascular_CLAHE_A2_ver2_pretrained_4', 'vascular_CLAHE_B3_ver2_pretrained_0', 'vascular_CLAHE_B3_ver2_pretrained_1', 'vascular_CLAHE_B3_ver2_pretrained_2', 'vascular_CLAHE_B3_ver2_pretrained_3', 'vascular_CLAHE_B3_ver2_pretrained_4', 'cropped_CLAHE_A2_ver2_pretrained_1.1', 'cropped_CLAHE_A2_ver2_pretrained_2.1', 'cropped_CLAHE_A2_ver2_pretrained_3.1', 'cropped_CLAHE_A2_ver2_pretrained_4.1', 'cropped_CLAHE_B3_ver2_pretrained_0.1', 'cropped_CLAHE_B3_ver2_pretrained_1.1', 'cropped_CLAHE_B3_ver2_pretrained_2.1', 'cropped_CLAHE_B3_ver2_pretrained_3.1', 'cropped_CLAHE_B3_ver2_pretrained_4.1', 'disc_CLAHE_A2_ver2_pretrained_0.1', 'disc_CLAHE_A2_ver2_pretrained_1.1', 'disc_CLAHE_A2_ver2_pretrained_2.1', 'disc_CLAHE_A2_ver2_pretrained_3.1', 'disc_CLAHE_A2_ver2_pretrained_4.1', 'disc_CLAHE_B3_ver2_pretrained_0.1', 'disc_CLAHE_B3_ver2_pretrained_1.1', 'disc_CLAHE_B3_ver2_pretrained_2.1', 'disc_CLAHE_B3_ver2_pretrained_3.1', 'disc_CLAHE_B3_ver2_pretrained_4.1', 'macula_CLAHE_A2_ver2_pretrained_0.1', 'macula_CLAHE_A2_ver2_pretrained_1.1', 'macula_CLAHE_A2_ver2_pretrained_2.1', 'macula_CLAHE_A2_ver2_pretrained_3.1', 'macula_CLAHE_A2_ver2_pretrained_4.1', 'macula_CLAHE_B3_ver2_pretrained_0.1', 'macula_CLAHE_B3_ver2_pretrained_1.1', 'macula_CLAHE_B3_ver2_pretrained_2.1', 'macula_CLAHE_B3_ver2_pretrained_3.1', 'macula_CLAHE_B3_ver2_pretrained_4.1', 'vascular_CLAHE_A2_ver2_pretrained_0.1', 'vascular_CLAHE_A2_ver2_pretrained_1.1', 'vascular_CLAHE_A2_ver2_pretrained_2.1', 'vascular_CLAHE_A2_ver2_pretrained_3.1', 'vascular_CLAHE_A2_ver2_pretrained_4.1', 'vascular_CLAHE_B3_ver2_pretrained_0.1', 'vascular_CLAHE_B3_ver2_pretrained_1.1', 'vascular_CLAHE_B3_ver2_pretrained_2.1', 'vascular_CLAHE_B3_ver2_pretrained_3.1', 'vascular_CLAHE_B3_ver2_pretrained_4.1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzK-7A7RRXiu"
      },
      "source": [
        "#**Prediction accuracy for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZej9BelRsro",
        "outputId": "793bda59-abdb-49f2-97af-bf04a368d76e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "!pip install bayesian-optimization \n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"age\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"age\"]\n",
        "    print(str(i))\n",
        "    get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    print(\"\")\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "cropped_2_A2_GaussianBlur_pretrained_0\n",
            "adjusted_r2(train)     :0.9256822877449307\n",
            "adjusted_r2(test)      :0.9321064597013191\n",
            "MAE(test)              :2.722166435229682\n",
            "MedianAE(test)         :1.9584975200000017\n",
            "RMSE(test)             :3.9718674753786876\n",
            "RMSE(test) / MAE(test) :1.4590832595596097\n",
            "\n",
            "cropped_2_A2_GaussianBlur_pretrained_1\n",
            "adjusted_r2(train)     :0.9202927594344374\n",
            "adjusted_r2(test)      :0.9069199925240363\n",
            "MAE(test)              :3.2485457115547702\n",
            "MedianAE(test)         :2.3716549900000032\n",
            "RMSE(test)             :4.650597207303464\n",
            "RMSE(test) / MAE(test) :1.431593586866187\n",
            "\n",
            "cropped_2_A2_GaussianBlur_pretrained_2\n",
            "adjusted_r2(train)     :0.9389912075192437\n",
            "adjusted_r2(test)      :0.9393244316440625\n",
            "MAE(test)              :2.4302530536749116\n",
            "MedianAE(test)         :1.6872982999999984\n",
            "RMSE(test)             :3.7548055254457577\n",
            "RMSE(test) / MAE(test) :1.545026564113528\n",
            "\n",
            "cropped_2_A2_GaussianBlur_pretrained_3\n",
            "adjusted_r2(train)     :0.9292631588301103\n",
            "adjusted_r2(test)      :0.9373649164693224\n",
            "MAE(test)              :2.8338993109893993\n",
            "MedianAE(test)         :2.223580120000001\n",
            "RMSE(test)             :3.814954408623818\n",
            "RMSE(test) / MAE(test) :1.3461855874095623\n",
            "\n",
            "cropped_2_A2_GaussianBlur_pretrained_4\n",
            "adjusted_r2(train)     :0.9192829962843123\n",
            "adjusted_r2(test)      :0.9016889417837458\n",
            "MAE(test)              :3.0271323781978796\n",
            "MedianAE(test)         :2.011308909999997\n",
            "RMSE(test)             :4.779491649415037\n",
            "RMSE(test) / MAE(test) :1.5788842548935293\n",
            "\n",
            "disc_2_A2_GaussianBlur_pretrained_0\n",
            "adjusted_r2(train)     :0.8951946403284341\n",
            "adjusted_r2(test)      :0.8892811032463708\n",
            "MAE(test)              :3.8774521104240276\n",
            "MedianAE(test)         :3.1784236400000054\n",
            "RMSE(test)             :5.072141917986129\n",
            "RMSE(test) / MAE(test) :1.308112072964185\n",
            "\n",
            "disc_2_A2_GaussianBlur_pretrained_1\n",
            "adjusted_r2(train)     :0.8769525464324394\n",
            "adjusted_r2(test)      :0.8727372427888496\n",
            "MAE(test)              :3.932603958621908\n",
            "MedianAE(test)         :2.904799220000001\n",
            "RMSE(test)             :5.437899611171682\n",
            "RMSE(test) / MAE(test) :1.382773263819139\n",
            "\n",
            "disc_2_A2_GaussianBlur_pretrained_2\n",
            "adjusted_r2(train)     :0.9280186411967724\n",
            "adjusted_r2(test)      :0.9272949027295669\n",
            "MAE(test)              :3.0962689683038866\n",
            "MedianAE(test)         :2.537508729999999\n",
            "RMSE(test)             :4.110199968974648\n",
            "RMSE(test) / MAE(test) :1.3274686440520007\n",
            "\n",
            "disc_2_A2_GaussianBlur_pretrained_3\n",
            "adjusted_r2(train)     :0.8980050399492644\n",
            "adjusted_r2(test)      :0.8911532487731811\n",
            "MAE(test)              :2.7295737446996466\n",
            "MedianAE(test)         :1.3750319500000003\n",
            "RMSE(test)             :5.029076677329851\n",
            "RMSE(test) / MAE(test) :1.84244030303099\n",
            "\n",
            "disc_2_A2_GaussianBlur_pretrained_4\n",
            "adjusted_r2(train)     :0.9016166538318963\n",
            "adjusted_r2(test)      :0.8919745521998428\n",
            "MAE(test)              :3.6390766416254414\n",
            "MedianAE(test)         :2.718900919999996\n",
            "RMSE(test)             :5.01006729543306\n",
            "RMSE(test) / MAE(test) :1.3767413519477971\n",
            "\n",
            "macula_2_A2_GaussianBlur_pretrained_0\n",
            "adjusted_r2(train)     :0.8266420942299637\n",
            "adjusted_r2(test)      :0.8270441149943712\n",
            "MAE(test)              :4.571646814770318\n",
            "MedianAE(test)         :3.0744612200000034\n",
            "RMSE(test)             :6.339400557323988\n",
            "RMSE(test) / MAE(test) :1.386677670908942\n",
            "\n",
            "macula_2_A2_GaussianBlur_pretrained_1\n",
            "adjusted_r2(train)     :0.8608470305243012\n",
            "adjusted_r2(test)      :0.8417882001560782\n",
            "MAE(test)              :4.314240532367492\n",
            "MedianAE(test)         :3.2360651500000017\n",
            "RMSE(test)             :6.0631729611337954\n",
            "RMSE(test) / MAE(test) :1.4053859342438089\n",
            "\n",
            "macula_2_A2_GaussianBlur_pretrained_2\n",
            "adjusted_r2(train)     :0.873953655017728\n",
            "adjusted_r2(test)      :0.8914323293395972\n",
            "MAE(test)              :3.745207616501767\n",
            "MedianAE(test)         :3.083662269999998\n",
            "RMSE(test)             :5.022625320933323\n",
            "RMSE(test) / MAE(test) :1.3410806116069836\n",
            "\n",
            "macula_2_A2_GaussianBlur_pretrained_3\n",
            "adjusted_r2(train)     :0.8371849828261226\n",
            "adjusted_r2(test)      :0.8517344688323342\n",
            "MAE(test)              :4.3806763247703175\n",
            "MedianAE(test)         :3.45893049\n",
            "RMSE(test)             :5.869493427291991\n",
            "RMSE(test) / MAE(test) :1.3398601019900127\n",
            "\n",
            "macula_2_A2_GaussianBlur_pretrained_4\n",
            "adjusted_r2(train)     :0.7852281618170344\n",
            "adjusted_r2(test)      :0.7819391565026307\n",
            "MAE(test)              :5.500812240812722\n",
            "MedianAE(test)         :4.509468320000003\n",
            "RMSE(test)             :7.118186549543462\n",
            "RMSE(test) / MAE(test) :1.294024634531387\n",
            "\n",
            "cropped_2_B3_GaussianBlur_pretrained_0\n",
            "adjusted_r2(train)     :0.9012463570921518\n",
            "adjusted_r2(test)      :0.9055255978267138\n",
            "MAE(test)              :3.25913364745583\n",
            "MedianAE(test)         :2.042769909999997\n",
            "RMSE(test)             :4.685302092125317\n",
            "RMSE(test) / MAE(test) :1.4375912739211518\n",
            "\n",
            "cropped_2_B3_GaussianBlur_pretrained_1\n",
            "adjusted_r2(train)     :0.9360987049238674\n",
            "adjusted_r2(test)      :0.9310990289523678\n",
            "MAE(test)              :2.540346176042403\n",
            "MedianAE(test)         :1.7185425799999976\n",
            "RMSE(test)             :4.0012270212990915\n",
            "RMSE(test) / MAE(test) :1.5750715627003995\n",
            "\n",
            "cropped_2_B3_GaussianBlur_pretrained_2\n",
            "adjusted_r2(train)     :0.9266946007504282\n",
            "adjusted_r2(test)      :0.9263021044229205\n",
            "MAE(test)              :2.394797793427561\n",
            "MedianAE(test)         :1.2826635799999977\n",
            "RMSE(test)             :4.138167496272642\n",
            "RMSE(test) / MAE(test) :1.7279820065099851\n",
            "\n",
            "cropped_2_B3_GaussianBlur_pretrained_3\n",
            "adjusted_r2(train)     :0.9208449491071644\n",
            "adjusted_r2(test)      :0.9034358925959226\n",
            "MAE(test)              :2.9619866975265015\n",
            "MedianAE(test)         :1.9503359799999984\n",
            "RMSE(test)             :4.736836416772891\n",
            "RMSE(test) / MAE(test) :1.5992092134406048\n",
            "\n",
            "cropped_2_B3_GaussianBlur_pretrained_4\n",
            "adjusted_r2(train)     :0.8934691696737992\n",
            "adjusted_r2(test)      :0.873320020380905\n",
            "MAE(test)              :3.7452959061837454\n",
            "MedianAE(test)         :2.526716950000001\n",
            "RMSE(test)             :5.425434367958274\n",
            "RMSE(test) / MAE(test) :1.4485996577735025\n",
            "\n",
            "disc_2_B3_GaussianBlur_pretrained_0\n",
            "adjusted_r2(train)     :0.9491009161231933\n",
            "adjusted_r2(test)      :0.9289428810323379\n",
            "MAE(test)              :2.6301272739929322\n",
            "MedianAE(test)         :1.8987197900000012\n",
            "RMSE(test)             :4.06335081336911\n",
            "RMSE(test) / MAE(test) :1.5449255454472082\n",
            "\n",
            "disc_2_B3_GaussianBlur_pretrained_1\n",
            "adjusted_r2(train)     :0.8234719665015453\n",
            "adjusted_r2(test)      :0.8256411693568864\n",
            "MAE(test)              :5.03451036713781\n",
            "MedianAE(test)         :3.9836699999999965\n",
            "RMSE(test)             :6.365059907893017\n",
            "RMSE(test) / MAE(test) :1.2642857882347838\n",
            "\n",
            "disc_2_B3_GaussianBlur_pretrained_2\n",
            "adjusted_r2(train)     :0.8517748698646863\n",
            "adjusted_r2(test)      :0.8320838730636645\n",
            "MAE(test)              :5.020731737632509\n",
            "MedianAE(test)         :4.393662450000001\n",
            "RMSE(test)             :6.246355906909851\n",
            "RMSE(test) / MAE(test) :1.2441126579400308\n",
            "\n",
            "disc_2_B3_GaussianBlur_pretrained_3\n",
            "adjusted_r2(train)     :0.8795598778642898\n",
            "adjusted_r2(test)      :0.8787760897267215\n",
            "MAE(test)              :2.893629013816254\n",
            "MedianAE(test)         :1.2902711600000032\n",
            "RMSE(test)             :5.307312573670577\n",
            "RMSE(test) / MAE(test) :1.8341371849430843\n",
            "\n",
            "disc_2_B3_GaussianBlur_pretrained_4\n",
            "adjusted_r2(train)     :0.9358295561462777\n",
            "adjusted_r2(test)      :0.9201070586212178\n",
            "MAE(test)              :2.1279643166431095\n",
            "MedianAE(test)         :1.0233166200000028\n",
            "RMSE(test)             :4.30858561417092\n",
            "RMSE(test) / MAE(test) :2.0247452367846885\n",
            "\n",
            "macula_2_B3_GaussianBlur_pretrained_0\n",
            "adjusted_r2(train)     :0.9220482465310076\n",
            "adjusted_r2(test)      :0.9224662896603881\n",
            "MAE(test)              :2.752013007067138\n",
            "MedianAE(test)         :1.7364387499999978\n",
            "RMSE(test)             :4.244492841292769\n",
            "RMSE(test) / MAE(test) :1.5423229579195157\n",
            "\n",
            "macula_2_B3_GaussianBlur_pretrained_1\n",
            "adjusted_r2(train)     :0.9024365831662693\n",
            "adjusted_r2(test)      :0.9129740049120999\n",
            "MAE(test)              :2.6533176407773853\n",
            "MedianAE(test)         :1.4913593500000033\n",
            "RMSE(test)             :4.496814996935572\n",
            "RMSE(test) / MAE(test) :1.6947895449178363\n",
            "\n",
            "macula_2_B3_GaussianBlur_pretrained_2\n",
            "adjusted_r2(train)     :0.37159430669406046\n",
            "adjusted_r2(test)      :0.4114381936657917\n",
            "MAE(test)              :9.873654043392227\n",
            "MedianAE(test)         :9.049461010000002\n",
            "RMSE(test)             :11.694362709630422\n",
            "RMSE(test) / MAE(test) :1.1844006948427237\n",
            "\n",
            "macula_2_B3_GaussianBlur_pretrained_3\n",
            "adjusted_r2(train)     :0.9057367454750991\n",
            "adjusted_r2(test)      :0.9076890781354714\n",
            "MAE(test)              :2.7874222539222617\n",
            "MedianAE(test)         :1.4414246099999986\n",
            "RMSE(test)             :4.6313442741139585\n",
            "RMSE(test) / MAE(test) :1.6615151391566387\n",
            "\n",
            "macula_2_B3_GaussianBlur_pretrained_4\n",
            "adjusted_r2(train)     :0.8559608048818592\n",
            "adjusted_r2(test)      :0.8766710992319298\n",
            "MAE(test)              :4.064743658021201\n",
            "MedianAE(test)         :3.1852443200000025\n",
            "RMSE(test)             :5.353193624438071\n",
            "RMSE(test) / MAE(test) :1.316981850472734\n",
            "\n",
            "vascular_2_RGB_B3_GaussianBlur_pretrained_0\n",
            "adjusted_r2(train)     :0.8604984989958253\n",
            "adjusted_r2(test)      :0.8641732564580354\n",
            "MAE(test)              :3.809492051519435\n",
            "MedianAE(test)         :2.5962821200000015\n",
            "RMSE(test)             :5.617889155089053\n",
            "RMSE(test) / MAE(test) :1.474708197080587\n",
            "\n",
            "vascular_2_RGB_B3_GaussianBlur_pretrained_1\n",
            "adjusted_r2(train)     :0.7697255006980191\n",
            "adjusted_r2(test)      :0.8144548796885972\n",
            "MAE(test)              :4.921585341130742\n",
            "MedianAE(test)         :4.018328189999998\n",
            "RMSE(test)             :6.566066703681157\n",
            "RMSE(test) / MAE(test) :1.3341365126409843\n",
            "\n",
            "vascular_2_RGB_B3_GaussianBlur_pretrained_2\n",
            "adjusted_r2(train)     :0.7317296320334394\n",
            "adjusted_r2(test)      :0.7691916447668528\n",
            "MAE(test)              :5.935264764028268\n",
            "MedianAE(test)         :5.357258559999998\n",
            "RMSE(test)             :7.323290883810464\n",
            "RMSE(test) / MAE(test) :1.233860859619031\n",
            "\n",
            "vascular_2_RGB_B3_GaussianBlur_pretrained_3\n",
            "adjusted_r2(train)     :0.752416095276173\n",
            "adjusted_r2(test)      :0.7783164713372167\n",
            "MAE(test)              :5.403692875512368\n",
            "MedianAE(test)         :3.9855839000000017\n",
            "RMSE(test)             :7.177070868430823\n",
            "RMSE(test) / MAE(test) :1.3281789016831025\n",
            "\n",
            "vascular_2_RGB_B3_GaussianBlur_pretrained_4\n",
            "adjusted_r2(train)     :0.874058328923641\n",
            "adjusted_r2(test)      :0.8606844839813677\n",
            "MAE(test)              :3.525482974558304\n",
            "MedianAE(test)         :2.1603407899999993\n",
            "RMSE(test)             :5.689580751349387\n",
            "RMSE(test) / MAE(test) :1.6138443420116686\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.8682180618573578\n",
            "adjusted_r2(test)      :0.8719281975835622\n",
            "MAE(test)              :4.326070116961131\n",
            "MedianAE(test)         :3.8662657699999983\n",
            "RMSE(test)             :5.455157356546638\n",
            "RMSE(test) / MAE(test) :1.2609960562494626\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.867833395261413\n",
            "adjusted_r2(test)      :0.8759052511960701\n",
            "MAE(test)              :4.177580339823321\n",
            "MedianAE(test)         :3.753598689999997\n",
            "RMSE(test)             :5.3697890365857175\n",
            "RMSE(test) / MAE(test) :1.2853825898684732\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.9310528438724953\n",
            "adjusted_r2(test)      :0.9313001107404242\n",
            "MAE(test)              :2.9422822742402825\n",
            "MedianAE(test)         :2.131381509999997\n",
            "RMSE(test)             :3.995384130042535\n",
            "RMSE(test) / MAE(test) :1.3579200626065595\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.8722931254295883\n",
            "adjusted_r2(test)      :0.8538693973292665\n",
            "MAE(test)              :3.797707654805654\n",
            "MedianAE(test)         :2.3788545099999965\n",
            "RMSE(test)             :5.827081729129868\n",
            "RMSE(test) / MAE(test) :1.5343681659530126\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.9182558545693867\n",
            "adjusted_r2(test)      :0.915562674817055\n",
            "MAE(test)              :3.2304754556537096\n",
            "MedianAE(test)         :2.60572243\n",
            "RMSE(test)             :4.429429108448544\n",
            "RMSE(test) / MAE(test) :1.3711384498206063\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.9510502216687122\n",
            "adjusted_r2(test)      :0.9422340711842766\n",
            "MAE(test)              :2.1698860134275617\n",
            "MedianAE(test)         :1.4057776900000007\n",
            "RMSE(test)             :3.663670453967568\n",
            "RMSE(test) / MAE(test) :1.6884160878941368\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.9250480295041816\n",
            "adjusted_r2(test)      :0.928908898010816\n",
            "MAE(test)              :2.7483117092579508\n",
            "MedianAE(test)         :1.8112196900000015\n",
            "RMSE(test)             :4.064322344683186\n",
            "RMSE(test) / MAE(test) :1.4788432953191326\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.932726518474439\n",
            "adjusted_r2(test)      :0.9148858847093162\n",
            "MAE(test)              :2.8762985570671376\n",
            "MedianAE(test)         :1.7870788600000012\n",
            "RMSE(test)             :4.4471452707056285\n",
            "RMSE(test) / MAE(test) :1.5461347918069497\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.9248780181518566\n",
            "adjusted_r2(test)      :0.9003795462854263\n",
            "MAE(test)              :2.5629801530035334\n",
            "MedianAE(test)         :1.4213562000000124\n",
            "RMSE(test)             :4.8112151622633865\n",
            "RMSE(test) / MAE(test) :1.8771956375179755\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.7623876354307848\n",
            "adjusted_r2(test)      :0.7594013900787779\n",
            "MAE(test)              :6.01996874024735\n",
            "MedianAE(test)         :5.126405949999999\n",
            "RMSE(test)             :7.476994800672362\n",
            "RMSE(test) / MAE(test) :1.2420321638356455\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.8971848028515567\n",
            "adjusted_r2(test)      :0.8780162241386347\n",
            "MAE(test)              :3.861221156819788\n",
            "MedianAE(test)         :2.897475959999994\n",
            "RMSE(test)             :5.3239204530897375\n",
            "RMSE(test) / MAE(test) :1.3788177980135876\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.8830722666865641\n",
            "adjusted_r2(test)      :0.8784289176085814\n",
            "MAE(test)              :3.6701021257597173\n",
            "MedianAE(test)         :2.6973524100000006\n",
            "RMSE(test)             :5.314906923716228\n",
            "RMSE(test) / MAE(test) :1.448163223146286\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.908176994976926\n",
            "adjusted_r2(test)      :0.9084739959107655\n",
            "MAE(test)              :3.1200995460424026\n",
            "MedianAE(test)         :2.087833169999996\n",
            "RMSE(test)             :4.6116121288884075\n",
            "RMSE(test) / MAE(test) :1.4780336527204299\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.8776329670156295\n",
            "adjusted_r2(test)      :0.8677679662953532\n",
            "MAE(test)              :3.4497409537809185\n",
            "MedianAE(test)         :2.0488952400000002\n",
            "RMSE(test)             :5.543050821061629\n",
            "RMSE(test) / MAE(test) :1.6068020455235752\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.919792569832502\n",
            "adjusted_r2(test)      :0.9186753390140586\n",
            "MAE(test)              :2.7048680172791517\n",
            "MedianAE(test)         :1.6840598599999979\n",
            "RMSE(test)             :4.347020141902756\n",
            "RMSE(test) / MAE(test) :1.607109890069778\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.9541681493139124\n",
            "adjusted_r2(test)      :0.9426237197403308\n",
            "MAE(test)              :2.2132657907067137\n",
            "MedianAE(test)         :1.4670522199999994\n",
            "RMSE(test)             :3.6512932673790277\n",
            "RMSE(test) / MAE(test) :1.6497310366926785\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.9371156565687793\n",
            "adjusted_r2(test)      :0.9246988169578695\n",
            "MAE(test)              :2.459159973922261\n",
            "MedianAE(test)         :1.467107299999988\n",
            "RMSE(test)             :4.182937941729707\n",
            "RMSE(test) / MAE(test) :1.7009621114880498\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.8307273601347134\n",
            "adjusted_r2(test)      :0.835530573845059\n",
            "MAE(test)              :4.818363239116608\n",
            "MedianAE(test)         :4.022190330000001\n",
            "RMSE(test)             :6.181916152807489\n",
            "RMSE(test) / MAE(test) :1.2829908925548072\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.886113384659065\n",
            "adjusted_r2(test)      :0.8865787038332159\n",
            "MAE(test)              :2.7786681456183744\n",
            "MedianAE(test)         :1.3246402700000033\n",
            "RMSE(test)             :5.13366854158649\n",
            "RMSE(test) / MAE(test) :1.8475284821908902\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8864505947124529\n",
            "adjusted_r2(test)      :0.876930091094532\n",
            "MAE(test)              :3.778208590777385\n",
            "MedianAE(test)         :2.8297777200000027\n",
            "RMSE(test)             :5.347569791641249\n",
            "RMSE(test) / MAE(test) :1.4153717729335213\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.8512420567170065\n",
            "adjusted_r2(test)      :0.8527384751912985\n",
            "MAE(test)              :4.095689412720848\n",
            "MedianAE(test)         :2.8649733099999963\n",
            "RMSE(test)             :5.849586511000929\n",
            "RMSE(test) / MAE(test) :1.4282300051445875\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.8841947869432407\n",
            "adjusted_r2(test)      :0.8850501469436327\n",
            "MAE(test)              :3.570526441448763\n",
            "MedianAE(test)         :2.5845224899999977\n",
            "RMSE(test)             :5.168145499933406\n",
            "RMSE(test) / MAE(test) :1.4474463597128269\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.8449430641793431\n",
            "adjusted_r2(test)      :0.862311140615909\n",
            "MAE(test)              :3.7460399755830385\n",
            "MedianAE(test)         :2.449175359999998\n",
            "RMSE(test)             :5.656267273812603\n",
            "RMSE(test) / MAE(test) :1.5099324381695245\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.7776826923458116\n",
            "adjusted_r2(test)      :0.7670724921848632\n",
            "MAE(test)              :5.793042839964665\n",
            "MedianAE(test)         :4.905557160000001\n",
            "RMSE(test)             :7.35683323822878\n",
            "RMSE(test) / MAE(test) :1.2699428334062957\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.7667492793837841\n",
            "adjusted_r2(test)      :0.7495021464663719\n",
            "MAE(test)              :5.964571831872791\n",
            "MedianAE(test)         :4.928456310000001\n",
            "RMSE(test)             :7.629261941839845\n",
            "RMSE(test) / MAE(test) :1.2790963302799834\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.888949654392104\n",
            "adjusted_r2(test)      :0.8849337450944252\n",
            "MAE(test)              :3.564604021413428\n",
            "MedianAE(test)         :2.539118530000003\n",
            "RMSE(test)             :5.1707615514510135\n",
            "RMSE(test) / MAE(test) :1.4505851198026523\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.8976055990170648\n",
            "adjusted_r2(test)      :0.88870049962605\n",
            "MAE(test)              :3.075618706855124\n",
            "MedianAE(test)         :1.7334969000000058\n",
            "RMSE(test)             :5.085423541127656\n",
            "RMSE(test) / MAE(test) :1.6534635876004258\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.795229923415489\n",
            "adjusted_r2(test)      :0.811217222793396\n",
            "MAE(test)              :4.6806341502826845\n",
            "MedianAE(test)         :3.064993379999997\n",
            "RMSE(test)             :6.623106019951369\n",
            "RMSE(test) / MAE(test) :1.415001858145946\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.8259224430926069\n",
            "adjusted_r2(test)      :0.8479424821241291\n",
            "MAE(test)              :4.576684652544169\n",
            "MedianAE(test)         :3.7830636500000026\n",
            "RMSE(test)             :5.944077595935653\n",
            "RMSE(test) / MAE(test) :1.2987736860199344\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8473683265646387\n",
            "adjusted_r2(test)      :0.8625330241560869\n",
            "MAE(test)              :4.235821627208481\n",
            "MedianAE(test)         :3.341442349999994\n",
            "RMSE(test)             :5.65170794113709\n",
            "RMSE(test) / MAE(test) :1.3342648578102934\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.7299851319216435\n",
            "adjusted_r2(test)      :0.7686972588612858\n",
            "MAE(test)              :5.633387902508835\n",
            "MedianAE(test)         :4.3931870499999945\n",
            "RMSE(test)             :7.331129844173153\n",
            "RMSE(test) / MAE(test) :1.3013713898359862\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.6662082475472144\n",
            "adjusted_r2(test)      :0.7299273209309471\n",
            "MAE(test)              :6.3383639049116605\n",
            "MedianAE(test)         :5.1174550100000005\n",
            "RMSE(test)             :7.921744810439268\n",
            "RMSE(test) / MAE(test) :1.249809087846886\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.7128865575920947\n",
            "adjusted_r2(test)      :0.7567633881527909\n",
            "MAE(test)              :5.911970653816255\n",
            "MedianAE(test)         :4.723615879999997\n",
            "RMSE(test)             :7.517873164600553\n",
            "RMSE(test) / MAE(test) :1.2716357378647791\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.4251423960813878\n",
            "adjusted_r2(test)      :0.4631194360950881\n",
            "MAE(test)              :8.97016783696113\n",
            "MedianAE(test)         :7.853443859999999\n",
            "RMSE(test)             :11.169130434459547\n",
            "RMSE(test) / MAE(test) :1.2451417451118028\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8212252032347921\n",
            "adjusted_r2(test)      :0.7903189010563639\n",
            "MAE(test)              :4.959725722438162\n",
            "MedianAE(test)         :3.6669139899999976\n",
            "RMSE(test)             :6.980076200426876\n",
            "RMSE(test) / MAE(test) :1.4073512510678767\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.7938931140498457\n",
            "adjusted_r2(test)      :0.8117660905991081\n",
            "MAE(test)              :4.917520021413427\n",
            "MedianAE(test)         :3.7382364300000006\n",
            "RMSE(test)             :6.613470989081903\n",
            "RMSE(test) / MAE(test) :1.3448793213415355\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.7571502012463014\n",
            "adjusted_r2(test)      :0.7973909073055134\n",
            "MAE(test)              :5.064087617314487\n",
            "MedianAE(test)         :3.8486008599999977\n",
            "RMSE(test)             :6.861356543639612\n",
            "RMSE(test) / MAE(test) :1.354904784858013\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.8674162081505432\n",
            "adjusted_r2(test)      :0.9136219512899821\n",
            "MAE(test)              :2.972066336749117\n",
            "MedianAE(test)         :2.1246814699999987\n",
            "RMSE(test)             :4.480043348980076\n",
            "RMSE(test) / MAE(test) :1.5073833627416282\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.877027694385178\n",
            "adjusted_r2(test)      :0.8940807069029152\n",
            "MAE(test)              :3.0945192010954066\n",
            "MedianAE(test)         :1.9289002399999973\n",
            "RMSE(test)             :4.960986652214584\n",
            "RMSE(test) / MAE(test) :1.6031526482235043\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8791126169411625\n",
            "adjusted_r2(test)      :0.8788958040111969\n",
            "MAE(test)              :3.397420600636042\n",
            "MedianAE(test)         :2.2262697199999977\n",
            "RMSE(test)             :5.304691316587194\n",
            "RMSE(test) / MAE(test) :1.561387870431493\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.867833395261413\n",
            "adjusted_r2(test)      :0.8759052511960701\n",
            "MAE(test)              :4.177580339823321\n",
            "MedianAE(test)         :3.753598689999997\n",
            "RMSE(test)             :5.3697890365857175\n",
            "RMSE(test) / MAE(test) :1.2853825898684732\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.9310528438724953\n",
            "adjusted_r2(test)      :0.9313001107404242\n",
            "MAE(test)              :2.9422822742402825\n",
            "MedianAE(test)         :2.131381509999997\n",
            "RMSE(test)             :3.995384130042535\n",
            "RMSE(test) / MAE(test) :1.3579200626065595\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.8722931254295883\n",
            "adjusted_r2(test)      :0.8538693973292665\n",
            "MAE(test)              :3.797707654805654\n",
            "MedianAE(test)         :2.3788545099999965\n",
            "RMSE(test)             :5.827081729129868\n",
            "RMSE(test) / MAE(test) :1.5343681659530126\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.9182558545693867\n",
            "adjusted_r2(test)      :0.915562674817055\n",
            "MAE(test)              :3.2304754556537096\n",
            "MedianAE(test)         :2.60572243\n",
            "RMSE(test)             :4.429429108448544\n",
            "RMSE(test) / MAE(test) :1.3711384498206063\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_0.1\n",
            "adjusted_r2(train)     :0.9510502216687122\n",
            "adjusted_r2(test)      :0.9422340711842766\n",
            "MAE(test)              :2.1698860134275617\n",
            "MedianAE(test)         :1.4057776900000007\n",
            "RMSE(test)             :3.663670453967568\n",
            "RMSE(test) / MAE(test) :1.6884160878941368\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.9250480295041816\n",
            "adjusted_r2(test)      :0.928908898010816\n",
            "MAE(test)              :2.7483117092579508\n",
            "MedianAE(test)         :1.8112196900000015\n",
            "RMSE(test)             :4.064322344683186\n",
            "RMSE(test) / MAE(test) :1.4788432953191326\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.932726518474439\n",
            "adjusted_r2(test)      :0.9148858847093162\n",
            "MAE(test)              :2.8762985570671376\n",
            "MedianAE(test)         :1.7870788600000012\n",
            "RMSE(test)             :4.4471452707056285\n",
            "RMSE(test) / MAE(test) :1.5461347918069497\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.9248780181518566\n",
            "adjusted_r2(test)      :0.9003795462854263\n",
            "MAE(test)              :2.5629801530035334\n",
            "MedianAE(test)         :1.4213562000000124\n",
            "RMSE(test)             :4.8112151622633865\n",
            "RMSE(test) / MAE(test) :1.8771956375179755\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.7623876354307848\n",
            "adjusted_r2(test)      :0.7594013900787779\n",
            "MAE(test)              :6.01996874024735\n",
            "MedianAE(test)         :5.126405949999999\n",
            "RMSE(test)             :7.476994800672362\n",
            "RMSE(test) / MAE(test) :1.2420321638356455\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_0.1\n",
            "adjusted_r2(train)     :0.8971848028515567\n",
            "adjusted_r2(test)      :0.8780162241386347\n",
            "MAE(test)              :3.861221156819788\n",
            "MedianAE(test)         :2.897475959999994\n",
            "RMSE(test)             :5.3239204530897375\n",
            "RMSE(test) / MAE(test) :1.3788177980135876\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.8830722666865641\n",
            "adjusted_r2(test)      :0.8784289176085814\n",
            "MAE(test)              :3.6701021257597173\n",
            "MedianAE(test)         :2.6973524100000006\n",
            "RMSE(test)             :5.314906923716228\n",
            "RMSE(test) / MAE(test) :1.448163223146286\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.908176994976926\n",
            "adjusted_r2(test)      :0.9084739959107655\n",
            "MAE(test)              :3.1200995460424026\n",
            "MedianAE(test)         :2.087833169999996\n",
            "RMSE(test)             :4.6116121288884075\n",
            "RMSE(test) / MAE(test) :1.4780336527204299\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.8776329670156295\n",
            "adjusted_r2(test)      :0.8677679662953532\n",
            "MAE(test)              :3.4497409537809185\n",
            "MedianAE(test)         :2.0488952400000002\n",
            "RMSE(test)             :5.543050821061629\n",
            "RMSE(test) / MAE(test) :1.6068020455235752\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.919792569832502\n",
            "adjusted_r2(test)      :0.9186753390140586\n",
            "MAE(test)              :2.7048680172791517\n",
            "MedianAE(test)         :1.6840598599999979\n",
            "RMSE(test)             :4.347020141902756\n",
            "RMSE(test) / MAE(test) :1.607109890069778\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_0.1\n",
            "adjusted_r2(train)     :0.9541681493139124\n",
            "adjusted_r2(test)      :0.9426237197403308\n",
            "MAE(test)              :2.2132657907067137\n",
            "MedianAE(test)         :1.4670522199999994\n",
            "RMSE(test)             :3.6512932673790277\n",
            "RMSE(test) / MAE(test) :1.6497310366926785\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.9371156565687793\n",
            "adjusted_r2(test)      :0.9246988169578695\n",
            "MAE(test)              :2.459159973922261\n",
            "MedianAE(test)         :1.467107299999988\n",
            "RMSE(test)             :4.182937941729707\n",
            "RMSE(test) / MAE(test) :1.7009621114880498\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.8307273601347134\n",
            "adjusted_r2(test)      :0.835530573845059\n",
            "MAE(test)              :4.818363239116608\n",
            "MedianAE(test)         :4.022190330000001\n",
            "RMSE(test)             :6.181916152807489\n",
            "RMSE(test) / MAE(test) :1.2829908925548072\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.886113384659065\n",
            "adjusted_r2(test)      :0.8865787038332159\n",
            "MAE(test)              :2.7786681456183744\n",
            "MedianAE(test)         :1.3246402700000033\n",
            "RMSE(test)             :5.13366854158649\n",
            "RMSE(test) / MAE(test) :1.8475284821908902\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.8864505947124529\n",
            "adjusted_r2(test)      :0.876930091094532\n",
            "MAE(test)              :3.778208590777385\n",
            "MedianAE(test)         :2.8297777200000027\n",
            "RMSE(test)             :5.347569791641249\n",
            "RMSE(test) / MAE(test) :1.4153717729335213\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_0.1\n",
            "adjusted_r2(train)     :0.8512420567170065\n",
            "adjusted_r2(test)      :0.8527384751912985\n",
            "MAE(test)              :4.095689412720848\n",
            "MedianAE(test)         :2.8649733099999963\n",
            "RMSE(test)             :5.849586511000929\n",
            "RMSE(test) / MAE(test) :1.4282300051445875\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.8841947869432407\n",
            "adjusted_r2(test)      :0.8850501469436327\n",
            "MAE(test)              :3.570526441448763\n",
            "MedianAE(test)         :2.5845224899999977\n",
            "RMSE(test)             :5.168145499933406\n",
            "RMSE(test) / MAE(test) :1.4474463597128269\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.8449430641793431\n",
            "adjusted_r2(test)      :0.862311140615909\n",
            "MAE(test)              :3.7460399755830385\n",
            "MedianAE(test)         :2.449175359999998\n",
            "RMSE(test)             :5.656267273812603\n",
            "RMSE(test) / MAE(test) :1.5099324381695245\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.7776826923458116\n",
            "adjusted_r2(test)      :0.7670724921848632\n",
            "MAE(test)              :5.793042839964665\n",
            "MedianAE(test)         :4.905557160000001\n",
            "RMSE(test)             :7.35683323822878\n",
            "RMSE(test) / MAE(test) :1.2699428334062957\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.7667492793837841\n",
            "adjusted_r2(test)      :0.7495021464663719\n",
            "MAE(test)              :5.964571831872791\n",
            "MedianAE(test)         :4.928456310000001\n",
            "RMSE(test)             :7.629261941839845\n",
            "RMSE(test) / MAE(test) :1.2790963302799834\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_0.1\n",
            "adjusted_r2(train)     :0.888949654392104\n",
            "adjusted_r2(test)      :0.8849337450944252\n",
            "MAE(test)              :3.564604021413428\n",
            "MedianAE(test)         :2.539118530000003\n",
            "RMSE(test)             :5.1707615514510135\n",
            "RMSE(test) / MAE(test) :1.4505851198026523\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.8976055990170648\n",
            "adjusted_r2(test)      :0.88870049962605\n",
            "MAE(test)              :3.075618706855124\n",
            "MedianAE(test)         :1.7334969000000058\n",
            "RMSE(test)             :5.085423541127656\n",
            "RMSE(test) / MAE(test) :1.6534635876004258\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.795229923415489\n",
            "adjusted_r2(test)      :0.811217222793396\n",
            "MAE(test)              :4.6806341502826845\n",
            "MedianAE(test)         :3.064993379999997\n",
            "RMSE(test)             :6.623106019951369\n",
            "RMSE(test) / MAE(test) :1.415001858145946\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.8259224430926069\n",
            "adjusted_r2(test)      :0.8479424821241291\n",
            "MAE(test)              :4.576684652544169\n",
            "MedianAE(test)         :3.7830636500000026\n",
            "RMSE(test)             :5.944077595935653\n",
            "RMSE(test) / MAE(test) :1.2987736860199344\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.8473683265646387\n",
            "adjusted_r2(test)      :0.8625330241560869\n",
            "MAE(test)              :4.235821627208481\n",
            "MedianAE(test)         :3.341442349999994\n",
            "RMSE(test)             :5.65170794113709\n",
            "RMSE(test) / MAE(test) :1.3342648578102934\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_0.1\n",
            "adjusted_r2(train)     :0.7299851319216435\n",
            "adjusted_r2(test)      :0.7686972588612858\n",
            "MAE(test)              :5.633387902508835\n",
            "MedianAE(test)         :4.3931870499999945\n",
            "RMSE(test)             :7.331129844173153\n",
            "RMSE(test) / MAE(test) :1.3013713898359862\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.6662082475472144\n",
            "adjusted_r2(test)      :0.7299273209309471\n",
            "MAE(test)              :6.3383639049116605\n",
            "MedianAE(test)         :5.1174550100000005\n",
            "RMSE(test)             :7.921744810439268\n",
            "RMSE(test) / MAE(test) :1.249809087846886\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.7128865575920947\n",
            "adjusted_r2(test)      :0.7567633881527909\n",
            "MAE(test)              :5.911970653816255\n",
            "MedianAE(test)         :4.723615879999997\n",
            "RMSE(test)             :7.517873164600553\n",
            "RMSE(test) / MAE(test) :1.2716357378647791\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.4251423960813878\n",
            "adjusted_r2(test)      :0.4631194360950881\n",
            "MAE(test)              :8.97016783696113\n",
            "MedianAE(test)         :7.853443859999999\n",
            "RMSE(test)             :11.169130434459547\n",
            "RMSE(test) / MAE(test) :1.2451417451118028\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.8212252032347921\n",
            "adjusted_r2(test)      :0.7903189010563639\n",
            "MAE(test)              :4.959725722438162\n",
            "MedianAE(test)         :3.6669139899999976\n",
            "RMSE(test)             :6.980076200426876\n",
            "RMSE(test) / MAE(test) :1.4073512510678767\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_0.1\n",
            "adjusted_r2(train)     :0.7938931140498457\n",
            "adjusted_r2(test)      :0.8117660905991081\n",
            "MAE(test)              :4.917520021413427\n",
            "MedianAE(test)         :3.7382364300000006\n",
            "RMSE(test)             :6.613470989081903\n",
            "RMSE(test) / MAE(test) :1.3448793213415355\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_1.1\n",
            "adjusted_r2(train)     :0.7571502012463014\n",
            "adjusted_r2(test)      :0.7973909073055134\n",
            "MAE(test)              :5.064087617314487\n",
            "MedianAE(test)         :3.8486008599999977\n",
            "RMSE(test)             :6.861356543639612\n",
            "RMSE(test) / MAE(test) :1.354904784858013\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_2.1\n",
            "adjusted_r2(train)     :0.8674162081505432\n",
            "adjusted_r2(test)      :0.9136219512899821\n",
            "MAE(test)              :2.972066336749117\n",
            "MedianAE(test)         :2.1246814699999987\n",
            "RMSE(test)             :4.480043348980076\n",
            "RMSE(test) / MAE(test) :1.5073833627416282\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_3.1\n",
            "adjusted_r2(train)     :0.877027694385178\n",
            "adjusted_r2(test)      :0.8940807069029152\n",
            "MAE(test)              :3.0945192010954066\n",
            "MedianAE(test)         :1.9289002399999973\n",
            "RMSE(test)             :4.960986652214584\n",
            "RMSE(test) / MAE(test) :1.6031526482235043\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_4.1\n",
            "adjusted_r2(train)     :0.8791126169411625\n",
            "adjusted_r2(test)      :0.8788958040111969\n",
            "MAE(test)              :3.397420600636042\n",
            "MedianAE(test)         :2.2262697199999977\n",
            "RMSE(test)             :5.304691316587194\n",
            "RMSE(test) / MAE(test) :1.561387870431493\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpy4m8XyRKtV"
      },
      "source": [
        "#**Analysis using XGBoost**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/12/07/000022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d966OQgNzX9"
      },
      "source": [
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20JJ1H4Nmva"
      },
      "source": [
        "# Grid Search用のパラメータ作成。\n",
        "# あまり組み合わせが多いと時間がかかる(time consuming)\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "params = {\n",
        "        'eta': [0.01],             # default = 0.3      \n",
        "        'gamma': [1,2,3],            # default = 0\n",
        "        'max_depth': [7,8,9],      # default = 6\n",
        "        'min_child_weight': [1],   # default = 1\n",
        "        'subsample': [0.8,1.0],        # default = 1\n",
        "        'colsample_bytree': [0.8,1.0], # default = 1\n",
        "        }\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 1)\n",
        "\n",
        "#最適解探索\n",
        "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error', n_jobs=2, cv=kf.split(X_train,Y_train), verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train,Y_train)\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "QeZYNf5nX7-k",
        "outputId": "d329b2f7-2d1b-4a13-889d-6e2bc74f5c8f"
      },
      "source": [
        "#Bayesian Optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# BaysianOptimizationで最適化する関数を定義する\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# BaysianOptimizationで最適化する関数を定義する\n",
        "def xgb_regressor(max_depth, min_child_weight, gamma, subsample, colsample_bytree,reg_alpha, n_estimators, reg_lambda,learning_rate):\n",
        "\n",
        "    params = {'max_depth':int(max_depth),\n",
        "                'min_child_weight':int(min_child_weight),\n",
        "                'gamma':gamma,\n",
        "                'subsample':subsample,\n",
        "                'colsample_bytree':colsample_bytree,\n",
        "                'reg_alpha':reg_alpha,\n",
        "                'n_estimators':int(n_estimators),\n",
        "                'reg_lambda':reg_lambda,\n",
        "                'learning_rate':learning_rate\n",
        "                }\n",
        "    model = xgb.XGBRegressor(**params,\n",
        "                            early_stopping_rounds=50,\n",
        "                            eval_set=[(X_test, Y_test)],\n",
        "                            eval_metric='rmse',\n",
        "                            silent=False,\n",
        "                            n_jobs=-1\n",
        "                            )\n",
        "\n",
        "    Y_pred_cv = cross_val_predict(model,X_train,Y_train,cv=5, n_jobs=-1)\n",
        "    rmse_cv = np.sqrt(mean_squared_error(Y_train, Y_pred_cv))\n",
        "\n",
        "    return -rmse_cv\n",
        "\n",
        "#ベイズ最適化で探索するパラメータ空間を定義する\n",
        "xgb_bo = BayesianOptimization(xgb_regressor,\n",
        "                            {'max_depth':(3,8),\n",
        "                            'min_child_weight':(1,5),\n",
        "                            'gamma':(0,0.5),\n",
        "                            'subsample':(0.6,1),\n",
        "                            'colsample_bytree':(0.6,1),\n",
        "                            'reg_alpha':(1e-5,100),\n",
        "                            'n_estimators':(1000,2000),\n",
        "                            'reg_lambda':(1e-5,1),\n",
        "                            'learning_rate':(0.1,0.3)\n",
        "                            })\n",
        "\n",
        "#ベイズ最適化を実行（scoreが最大となるようにパラメータを探索していく）\n",
        "#init_point：初期に探索する点数\n",
        "#acq:獲得関数。EIは(expected improvement)\n",
        "xgb_bo.maximize(init_points=5, n_iter=200, acq='ei')\n",
        "\n",
        "#最もスコアのよかったパラメータの値を取得する。\n",
        "optimized_params = xgb_bo.max['params']\n",
        "\n",
        "#整数のパラメータは変換\n",
        "optimized_params['max_depth'] = int(optimized_params['max_depth'])\n",
        "optimized_params['min_child_weight'] = int(optimized_params['min_child_weight'])\n",
        "optimized_params['n_estimators'] = int(optimized_params['n_estimators'])\n",
        "\n",
        "#調整したパラメータで精度検証する\n",
        "opt_model = xgb.XGBRegressor()\n",
        "opt_model.set_params(**optimized_params)\n",
        "opt_model.fit(X_train, Y_train)\n",
        "#y_pred_train = opt_model.predict(X_train)\n",
        "#y_pred_test = opt_model.predict(X_test)\n",
        "bestmodel = opt_model\n",
        "print(bestmodel)\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)\n",
        "\n",
        "\"\"\"\n",
        "# 学習モデルの評価（RMSEを計算）\n",
        "print('RMSE(train data):',round(np.sqrt(mean_squared_error(Y_train, Y_pred_train)),3))\n",
        "print('RMSE(test data):',round(np.sqrt(mean_squared_error(Y_test, Y_pred_test)),3))\n",
        "#output\n",
        "#RMSE(train data): 0.426\n",
        "#RMSE(test data): 2.266\n",
        "#CPU times: user 32.1 s, sys: 4.64 s, total: 36.7 s\n",
        "#Wall time: 11min 42s\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: (0.9821902131584132, 0.2397132568638637, 0.14248950399833235, 5.787573269138166, 4.493794169209977, 1629.9379411388213, 46.623524538309795, 0.6311341380983069, 0.7589027604650508)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-eba308ba90d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#init_point：初期に探索する点数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#acq:獲得関数。EIは(expected improvement)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mxgb_bo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ei'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#最もスコアのよかったパラメータの値を取得する。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-106-eba308ba90d8>\u001b[0m in \u001b[0;36mxgb_regressor\u001b[0;34m(max_depth, min_child_weight, gamma, subsample, colsample_bytree, reg_alpha, n_estimators, reg_lambda, learning_rate)\u001b[0m\n\u001b[1;32m     33\u001b[0m                             )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mY_pred_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mrmse_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    753\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    754\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 755\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nASsIwGt10r",
        "outputId": "c7a746e1-4eee-43c5-d8bd-0554ba309434"
      },
      "source": [
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9992863321132477',\n",
              " 'adjusted_r2(test)      :0.9867920261248598',\n",
              " '平均誤差率(test)       :0.016491223324835196',\n",
              " 'MAE(test)              :0.8800020858171551',\n",
              " 'MedianAE(test)         :0.5713386535644531',\n",
              " 'RMSE(test)             :1.6257476892070504',\n",
              " 'RMSE(test) / MAE(test) :1.8474361770374765')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndXsi0Q0qnIc"
      },
      "source": [
        "\"\"\"\n",
        "#Optuna\n",
        "import optuna\n",
        "start = time.time()\n",
        "# ベイズ最適化時の評価指標算出メソッド\n",
        "def bayes_objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 8),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 4),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 0.1, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 0.1, log=True),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0001, 0.1, log=True),\n",
        "    }\n",
        "    # モデルにパラメータ適用\n",
        "    model.set_params(**params)\n",
        "    # cross_val_scoreでクロスバリデーション\n",
        "    scores = cross_val_score(model, X, y, cv=cv,\n",
        "                             scoring=scoring, fit_params=fit_params, n_jobs=-1)\n",
        "    val = scores.mean()\n",
        "    return val\n",
        "\n",
        "# ベイズ最適化を実行\n",
        "study = optuna.create_study(direction='maximize',\n",
        "                            sampler=optuna.samplers.TPESampler(seed=seed))\n",
        "study.optimize(bayes_objective, n_trials=5)\n",
        "\n",
        "# 最適パラメータの表示と保持\n",
        "best_params = study.best_trial.params\n",
        "best_score = study.best_trial.value\n",
        "print(f'最適パラメータ {best_params}\\nスコア {best_score}')\n",
        "print(f'所要時間{time.time() - start}秒')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wq2xWzPPEln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "30872407-455d-48b7-95fc-9227a1ba56e4"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=bestmodel.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f532d863b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AseFYOzD8mV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a1120d5-afaa-48bd-e8f6-b911a97d8860"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = bestmodel.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>importances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.199111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.180634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_3</td>\n",
              "      <td>0.138292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.108535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.0727489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.0626713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.0584339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.0566448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.0455917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.0315897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.0135196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.00995686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.00552086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.00390254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.00325253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.00185907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.000903961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.000876649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.000814386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.000665286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.00063649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.000572339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.000559753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_3</td>\n",
              "      <td>0.000265526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.000210225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.000207145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.000201426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.000197778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.000183194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.000181234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.000167985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.000166071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.000163658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.000153301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.000131075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.000129506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.000117796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_3</td>\n",
              "      <td>0.000116908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.000114406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               features  importances\n",
              "0    cropped_CLAHE_A2_ver2_pretrained_0     0.199111\n",
              "1    cropped_CLAHE_B3_ver2_pretrained_0     0.180634\n",
              "2       disc_CLAHE_B3_ver2_pretrained_3     0.138292\n",
              "3       disc_CLAHE_A2_ver2_pretrained_3     0.108535\n",
              "4    cropped_CLAHE_B3_ver2_pretrained_1    0.0727489\n",
              "5    cropped_CLAHE_B3_ver2_pretrained_2    0.0626713\n",
              "6       disc_CLAHE_B3_ver2_pretrained_0    0.0584339\n",
              "7       disc_CLAHE_A2_ver2_pretrained_4    0.0566448\n",
              "8    cropped_CLAHE_A2_ver2_pretrained_4    0.0455917\n",
              "9       disc_CLAHE_B3_ver2_pretrained_1    0.0315897\n",
              "10    macula_CLAHE_A2_ver2_pretrained_1    0.0135196\n",
              "11    macula_CLAHE_A2_ver2_pretrained_2   0.00995686\n",
              "12      disc_CLAHE_A2_ver2_pretrained_2   0.00552086\n",
              "13    macula_CLAHE_B3_ver2_pretrained_0   0.00390254\n",
              "14      disc_CLAHE_A2_ver2_pretrained_1   0.00325253\n",
              "15   cropped_CLAHE_A2_ver2_pretrained_3   0.00185907\n",
              "16   cropped_CLAHE_A2_ver2_pretrained_2  0.000903961\n",
              "17  vascular_CLAHE_B3_ver2_pretrained_4  0.000876649\n",
              "18    macula_CLAHE_B3_ver2_pretrained_1  0.000814386\n",
              "19  vascular_CLAHE_B3_ver2_pretrained_2  0.000665286\n",
              "20    macula_CLAHE_B3_ver2_pretrained_2   0.00063649\n",
              "21      disc_CLAHE_B3_ver2_pretrained_4  0.000572339\n",
              "22    macula_CLAHE_B3_ver2_pretrained_4  0.000559753\n",
              "23  vascular_CLAHE_B3_ver2_pretrained_3  0.000265526\n",
              "24      disc_CLAHE_A2_ver2_pretrained_0  0.000210225\n",
              "25  vascular_CLAHE_A2_ver2_pretrained_4  0.000207145\n",
              "26    macula_CLAHE_A2_ver2_pretrained_3  0.000201426\n",
              "27    macula_CLAHE_A2_ver2_pretrained_4  0.000197778\n",
              "28      disc_CLAHE_B3_ver2_pretrained_2  0.000183194\n",
              "29   cropped_CLAHE_A2_ver2_pretrained_1  0.000181234\n",
              "30   cropped_CLAHE_B3_ver2_pretrained_4  0.000167985\n",
              "31  vascular_CLAHE_A2_ver2_pretrained_0  0.000166071\n",
              "32  vascular_CLAHE_B3_ver2_pretrained_0  0.000163658\n",
              "33  vascular_CLAHE_A2_ver2_pretrained_3  0.000153301\n",
              "34  vascular_CLAHE_A2_ver2_pretrained_1  0.000131075\n",
              "35  vascular_CLAHE_B3_ver2_pretrained_1  0.000129506\n",
              "36  vascular_CLAHE_A2_ver2_pretrained_2  0.000117796\n",
              "37    macula_CLAHE_B3_ver2_pretrained_3  0.000116908\n",
              "38    macula_CLAHE_A2_ver2_pretrained_0  0.000114406"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIobiMOEPGKc"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='gain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnbP5EF_6pc9"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpEpFczPHkK"
      },
      "source": [
        "xgb.to_graphviz(bestmodel, num_trees=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-Kj_RHRQ-9"
      },
      "source": [
        "#**Analysis using RandomForest**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/11/14/200857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSyqmEyGRfHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602e77c0-476e-4e83-e7b9-b4772210ff91"
      },
      "source": [
        "#Create model\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=10)\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\"\"\"\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "           oob_score=False, random_state=2525, verbose=0, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_result(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9986845416179527',\n",
              " 'adjusted_r2(test)      :0.9716478339245996',\n",
              " '平均誤差率(test)       :0.019483058812510973',\n",
              " 'MAE(test)              :1.0077738515901062',\n",
              " 'MedianAE(test)         :0.6000000000000014',\n",
              " 'RMSE(test)             :2.381925461594808',\n",
              " 'RMSE(test) / MAE(test) :2.3635515625221966')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW6HVmKTUWsB"
      },
      "source": [
        "#Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(X_train,Y_train)\n",
        "\n",
        "\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkW5oubR4MJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rci5gcXQQ9XG"
      },
      "source": [
        "\"\"\"\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('Importances')\n",
        "plt.rcParams['font.size']=10\n",
        "sns.barplot(y='features', x='importances', data=df_s, palette='viridis')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DihmVVSbKI"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3Qw-hrjFi-"
      },
      "source": [
        "#**Analysis using neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwwcmwczMwfE"
      },
      "source": [
        "#正規化する\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#モデル作成\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "model = MLPRegressor(alpha=0.1, hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive', max_iter=500, random_state=42, solver=\"lbfgs\", early_stopping=True) \n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "初期設定：\n",
        "\n",
        "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "       verbose=False, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcqR8-Nj1E9"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlExOBk8fCoE"
      },
      "source": [
        "#**Predict age from test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zC8VftCfIcr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "4286e3a2-7f98-4213-a391-1c38c81380d6"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>60.885948</td>\n",
              "      <td>60.356665</td>\n",
              "      <td>50.935251</td>\n",
              "      <td>59.631753</td>\n",
              "      <td>58.965695</td>\n",
              "      <td>45.052648</td>\n",
              "      <td>60.332221</td>\n",
              "      <td>61.809397</td>\n",
              "      <td>59.062302</td>\n",
              "      <td>68.153375</td>\n",
              "      <td>51.562381</td>\n",
              "      <td>58.757454</td>\n",
              "      <td>68.297571</td>\n",
              "      <td>59.610933</td>\n",
              "      <td>55.720055</td>\n",
              "      <td>58.482534</td>\n",
              "      <td>59.504211</td>\n",
              "      <td>45.093548</td>\n",
              "      <td>58.708310</td>\n",
              "      <td>57.960665</td>\n",
              "      <td>44.306228</td>\n",
              "      <td>62.429917</td>\n",
              "      <td>47.746590</td>\n",
              "      <td>60.145330</td>\n",
              "      <td>59.885645</td>\n",
              "      <td>63.356745</td>\n",
              "      <td>62.210029</td>\n",
              "      <td>52.995640</td>\n",
              "      <td>60.519272</td>\n",
              "      <td>57.649809</td>\n",
              "      <td>63.051468</td>\n",
              "      <td>61.155617</td>\n",
              "      <td>60.746276</td>\n",
              "      <td>38.692406</td>\n",
              "      <td>57.933575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>29.766262</td>\n",
              "      <td>30.331397</td>\n",
              "      <td>29.118884</td>\n",
              "      <td>31.672752</td>\n",
              "      <td>30.989829</td>\n",
              "      <td>26.809660</td>\n",
              "      <td>32.241669</td>\n",
              "      <td>30.086446</td>\n",
              "      <td>30.817971</td>\n",
              "      <td>32.113385</td>\n",
              "      <td>26.403788</td>\n",
              "      <td>27.999404</td>\n",
              "      <td>31.571031</td>\n",
              "      <td>26.205668</td>\n",
              "      <td>21.942243</td>\n",
              "      <td>28.228927</td>\n",
              "      <td>28.847709</td>\n",
              "      <td>27.994281</td>\n",
              "      <td>28.715485</td>\n",
              "      <td>28.885067</td>\n",
              "      <td>26.357773</td>\n",
              "      <td>28.899875</td>\n",
              "      <td>26.704368</td>\n",
              "      <td>28.894490</td>\n",
              "      <td>28.859845</td>\n",
              "      <td>28.657392</td>\n",
              "      <td>28.822759</td>\n",
              "      <td>22.991714</td>\n",
              "      <td>28.690979</td>\n",
              "      <td>25.721887</td>\n",
              "      <td>34.075314</td>\n",
              "      <td>31.509855</td>\n",
              "      <td>33.798274</td>\n",
              "      <td>38.365373</td>\n",
              "      <td>29.952043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>58.364809</td>\n",
              "      <td>50.553083</td>\n",
              "      <td>63.250524</td>\n",
              "      <td>54.238850</td>\n",
              "      <td>50.851762</td>\n",
              "      <td>63.289428</td>\n",
              "      <td>54.653805</td>\n",
              "      <td>49.245375</td>\n",
              "      <td>50.571257</td>\n",
              "      <td>57.794720</td>\n",
              "      <td>49.765614</td>\n",
              "      <td>49.845201</td>\n",
              "      <td>54.795003</td>\n",
              "      <td>59.864140</td>\n",
              "      <td>54.611915</td>\n",
              "      <td>57.051009</td>\n",
              "      <td>54.708534</td>\n",
              "      <td>57.299381</td>\n",
              "      <td>49.541694</td>\n",
              "      <td>54.624343</td>\n",
              "      <td>52.290088</td>\n",
              "      <td>56.760901</td>\n",
              "      <td>47.204936</td>\n",
              "      <td>52.778614</td>\n",
              "      <td>52.187645</td>\n",
              "      <td>51.639259</td>\n",
              "      <td>53.236330</td>\n",
              "      <td>44.357553</td>\n",
              "      <td>52.916056</td>\n",
              "      <td>56.503397</td>\n",
              "      <td>47.425610</td>\n",
              "      <td>57.344145</td>\n",
              "      <td>51.043272</td>\n",
              "      <td>55.263293</td>\n",
              "      <td>48.160061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.213056</td>\n",
              "      <td>31.123018</td>\n",
              "      <td>29.923308</td>\n",
              "      <td>31.866950</td>\n",
              "      <td>31.424466</td>\n",
              "      <td>33.026874</td>\n",
              "      <td>27.775347</td>\n",
              "      <td>31.257206</td>\n",
              "      <td>30.184183</td>\n",
              "      <td>31.335768</td>\n",
              "      <td>28.773826</td>\n",
              "      <td>28.549322</td>\n",
              "      <td>29.491693</td>\n",
              "      <td>27.227801</td>\n",
              "      <td>29.133636</td>\n",
              "      <td>28.235692</td>\n",
              "      <td>31.660154</td>\n",
              "      <td>30.401087</td>\n",
              "      <td>29.131159</td>\n",
              "      <td>27.815926</td>\n",
              "      <td>33.806103</td>\n",
              "      <td>34.369171</td>\n",
              "      <td>30.322504</td>\n",
              "      <td>30.721486</td>\n",
              "      <td>30.021170</td>\n",
              "      <td>27.490881</td>\n",
              "      <td>30.023479</td>\n",
              "      <td>23.335579</td>\n",
              "      <td>29.751483</td>\n",
              "      <td>28.661990</td>\n",
              "      <td>33.212128</td>\n",
              "      <td>37.661710</td>\n",
              "      <td>37.906623</td>\n",
              "      <td>35.059234</td>\n",
              "      <td>30.629086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.485062</td>\n",
              "      <td>31.811762</td>\n",
              "      <td>30.549696</td>\n",
              "      <td>32.765386</td>\n",
              "      <td>31.352851</td>\n",
              "      <td>35.573980</td>\n",
              "      <td>32.451853</td>\n",
              "      <td>30.288148</td>\n",
              "      <td>31.099230</td>\n",
              "      <td>30.537629</td>\n",
              "      <td>29.595745</td>\n",
              "      <td>27.726558</td>\n",
              "      <td>31.044161</td>\n",
              "      <td>32.806641</td>\n",
              "      <td>29.797870</td>\n",
              "      <td>29.842737</td>\n",
              "      <td>28.483209</td>\n",
              "      <td>29.473320</td>\n",
              "      <td>28.350401</td>\n",
              "      <td>31.485087</td>\n",
              "      <td>32.985473</td>\n",
              "      <td>37.007666</td>\n",
              "      <td>28.809839</td>\n",
              "      <td>28.963286</td>\n",
              "      <td>29.689914</td>\n",
              "      <td>26.915285</td>\n",
              "      <td>28.129721</td>\n",
              "      <td>24.725600</td>\n",
              "      <td>28.009915</td>\n",
              "      <td>28.578359</td>\n",
              "      <td>31.528470</td>\n",
              "      <td>32.324287</td>\n",
              "      <td>38.401335</td>\n",
              "      <td>32.143921</td>\n",
              "      <td>30.726725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>38.199157</td>\n",
              "      <td>39.335907</td>\n",
              "      <td>38.415360</td>\n",
              "      <td>40.701389</td>\n",
              "      <td>37.806478</td>\n",
              "      <td>37.474301</td>\n",
              "      <td>32.679823</td>\n",
              "      <td>31.805116</td>\n",
              "      <td>37.843254</td>\n",
              "      <td>33.726096</td>\n",
              "      <td>36.371392</td>\n",
              "      <td>49.667397</td>\n",
              "      <td>39.193630</td>\n",
              "      <td>38.588050</td>\n",
              "      <td>34.526837</td>\n",
              "      <td>38.396522</td>\n",
              "      <td>35.274139</td>\n",
              "      <td>38.497335</td>\n",
              "      <td>38.434505</td>\n",
              "      <td>34.112072</td>\n",
              "      <td>35.426679</td>\n",
              "      <td>35.021561</td>\n",
              "      <td>28.289860</td>\n",
              "      <td>35.640907</td>\n",
              "      <td>36.847824</td>\n",
              "      <td>37.365493</td>\n",
              "      <td>46.835411</td>\n",
              "      <td>31.393817</td>\n",
              "      <td>38.262957</td>\n",
              "      <td>42.541334</td>\n",
              "      <td>36.452386</td>\n",
              "      <td>44.501454</td>\n",
              "      <td>43.832183</td>\n",
              "      <td>44.443870</td>\n",
              "      <td>36.340073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>53.196847</td>\n",
              "      <td>45.640141</td>\n",
              "      <td>45.546347</td>\n",
              "      <td>51.625419</td>\n",
              "      <td>50.128996</td>\n",
              "      <td>48.410195</td>\n",
              "      <td>42.230716</td>\n",
              "      <td>46.253222</td>\n",
              "      <td>51.311338</td>\n",
              "      <td>51.198155</td>\n",
              "      <td>48.310232</td>\n",
              "      <td>45.538834</td>\n",
              "      <td>44.979483</td>\n",
              "      <td>52.453923</td>\n",
              "      <td>44.837600</td>\n",
              "      <td>47.394177</td>\n",
              "      <td>48.088434</td>\n",
              "      <td>49.969494</td>\n",
              "      <td>49.401051</td>\n",
              "      <td>50.176543</td>\n",
              "      <td>47.796735</td>\n",
              "      <td>57.036519</td>\n",
              "      <td>50.078702</td>\n",
              "      <td>50.911272</td>\n",
              "      <td>49.306154</td>\n",
              "      <td>49.032882</td>\n",
              "      <td>48.545510</td>\n",
              "      <td>33.817515</td>\n",
              "      <td>41.229436</td>\n",
              "      <td>50.404090</td>\n",
              "      <td>50.643623</td>\n",
              "      <td>59.744704</td>\n",
              "      <td>54.123229</td>\n",
              "      <td>57.273388</td>\n",
              "      <td>48.106965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>56.886828</td>\n",
              "      <td>50.544816</td>\n",
              "      <td>47.587875</td>\n",
              "      <td>52.457392</td>\n",
              "      <td>50.793570</td>\n",
              "      <td>52.799886</td>\n",
              "      <td>45.932961</td>\n",
              "      <td>44.371003</td>\n",
              "      <td>51.916403</td>\n",
              "      <td>50.504851</td>\n",
              "      <td>44.726014</td>\n",
              "      <td>42.309937</td>\n",
              "      <td>45.024800</td>\n",
              "      <td>40.706378</td>\n",
              "      <td>42.950150</td>\n",
              "      <td>55.220819</td>\n",
              "      <td>48.409539</td>\n",
              "      <td>49.657461</td>\n",
              "      <td>49.004924</td>\n",
              "      <td>47.710246</td>\n",
              "      <td>47.885427</td>\n",
              "      <td>55.062169</td>\n",
              "      <td>52.543592</td>\n",
              "      <td>51.201683</td>\n",
              "      <td>50.496775</td>\n",
              "      <td>49.698067</td>\n",
              "      <td>47.475055</td>\n",
              "      <td>29.821983</td>\n",
              "      <td>40.268657</td>\n",
              "      <td>56.234378</td>\n",
              "      <td>50.509459</td>\n",
              "      <td>53.434712</td>\n",
              "      <td>52.482903</td>\n",
              "      <td>54.819530</td>\n",
              "      <td>47.122028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>56.605852</td>\n",
              "      <td>71.386600</td>\n",
              "      <td>74.264765</td>\n",
              "      <td>73.703772</td>\n",
              "      <td>72.917128</td>\n",
              "      <td>68.061024</td>\n",
              "      <td>74.160743</td>\n",
              "      <td>74.606669</td>\n",
              "      <td>42.933744</td>\n",
              "      <td>78.277564</td>\n",
              "      <td>73.981255</td>\n",
              "      <td>69.788361</td>\n",
              "      <td>79.573733</td>\n",
              "      <td>68.793005</td>\n",
              "      <td>71.677345</td>\n",
              "      <td>70.824075</td>\n",
              "      <td>70.887142</td>\n",
              "      <td>74.848467</td>\n",
              "      <td>73.488754</td>\n",
              "      <td>73.900068</td>\n",
              "      <td>71.458507</td>\n",
              "      <td>79.234850</td>\n",
              "      <td>59.871906</td>\n",
              "      <td>43.737605</td>\n",
              "      <td>69.913667</td>\n",
              "      <td>70.363796</td>\n",
              "      <td>72.958624</td>\n",
              "      <td>59.976119</td>\n",
              "      <td>71.317726</td>\n",
              "      <td>78.840834</td>\n",
              "      <td>68.769974</td>\n",
              "      <td>62.816906</td>\n",
              "      <td>66.310376</td>\n",
              "      <td>50.796282</td>\n",
              "      <td>63.409376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>69.049191</td>\n",
              "      <td>66.318005</td>\n",
              "      <td>73.155653</td>\n",
              "      <td>73.523390</td>\n",
              "      <td>72.985840</td>\n",
              "      <td>66.385049</td>\n",
              "      <td>68.927622</td>\n",
              "      <td>68.367136</td>\n",
              "      <td>53.513491</td>\n",
              "      <td>75.332546</td>\n",
              "      <td>74.130625</td>\n",
              "      <td>71.575391</td>\n",
              "      <td>88.524705</td>\n",
              "      <td>60.911018</td>\n",
              "      <td>71.346241</td>\n",
              "      <td>68.293542</td>\n",
              "      <td>72.224498</td>\n",
              "      <td>74.863398</td>\n",
              "      <td>72.767866</td>\n",
              "      <td>71.941185</td>\n",
              "      <td>73.264325</td>\n",
              "      <td>76.172227</td>\n",
              "      <td>64.452952</td>\n",
              "      <td>60.746992</td>\n",
              "      <td>71.590483</td>\n",
              "      <td>72.297430</td>\n",
              "      <td>71.659863</td>\n",
              "      <td>77.320302</td>\n",
              "      <td>67.448586</td>\n",
              "      <td>84.819227</td>\n",
              "      <td>68.363243</td>\n",
              "      <td>61.668277</td>\n",
              "      <td>61.990064</td>\n",
              "      <td>61.996752</td>\n",
              "      <td>69.304931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_2_RGB_B3_GaussianBlur_pretrained_4\n",
              "filename                    ...                                             \n",
              "img00085008_00_1R.jpg   61  ...                                    57.933575\n",
              "img00085024_00_1R.jpg   29  ...                                    29.952043\n",
              "img00241280_10_1R.jpg   51  ...                                    48.160061\n",
              "img00265140_00_1R.jpg   29  ...                                    30.629086\n",
              "img00265140_00_2L.jpg   29  ...                                    30.726725\n",
              "...                    ...  ...                                          ...\n",
              "img76791392_10_1R.jpg   38  ...                                    36.340073\n",
              "img76843122_10_1R.jpg   49  ...                                    48.106965\n",
              "img76843122_11_1R.jpg   49  ...                                    47.122028\n",
              "img76888512_00_1R.jpg   74  ...                                    63.409376\n",
              "img76888512_00_2L.jpg   74  ...                                    69.304931\n",
              "\n",
              "[1414 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8L_f0Qdq17-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "36bad807-a5ed-4ba1-d758-dc5a3fd166b0"
      },
      "source": [
        "import sys\n",
        "\n",
        "#評価用ファイルの呼び出し\n",
        "df_dst = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv\", index_col=0, sep=\",\")\n",
        "df_dst\n",
        "\n",
        "index = df_dst.iloc[7:408,0] #画像名リスト\n",
        "cols = df.columns #modelリスト\n",
        "\n",
        "df_temp = pd.DataFrame(index=index, columns=cols)\n",
        "df_temp\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>...</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img76901008_06_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_06_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img77009741_01_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962800_00_1L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962810_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962820_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962830_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962840_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 155 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   age  ... vascular_2_RGB_B3_GB_L1Loss_pretrained_4\n",
              "Unnamed: 1              ...                                         \n",
              "img76901008_06_1R  NaN  ...                                      NaN\n",
              "img76901008_06_2L  NaN  ...                                      NaN\n",
              "img76901008_07_1R  NaN  ...                                      NaN\n",
              "img76901008_07_2L  NaN  ...                                      NaN\n",
              "img77009741_01_1R  NaN  ...                                      NaN\n",
              "...                ...  ...                                      ...\n",
              "img99962800_00_1L  NaN  ...                                      NaN\n",
              "img99962810_00_1R  NaN  ...                                      NaN\n",
              "img99962820_00_1R  NaN  ...                                      NaN\n",
              "img99962830_00_1R  NaN  ...                                      NaN\n",
              "img99962840_00_1R  NaN  ...                                      NaN\n",
              "\n",
              "[401 rows x 155 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGbfrHokrOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b34143e-aeb4-489a-dbd1-a34a9a09169e"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "#!pip install adabelief-pytorch==0.1.0\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "\"\"\"\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\"\"\"\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入##########改変要\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df_temp.loc[df_temp.index.str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "class Select_dataset:\n",
        "    \"\"\"\n",
        "    「name = cropped_CLAHE_A2_pretrained_2」\n",
        "    からモデルのダウンロードとdatasetの選択を行う\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.preprocess = \"\"\n",
        "        self.part = \"\"\n",
        "        self.DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "        self.dst_path = \"\"\n",
        "\n",
        "    def select_preprocess(self):\n",
        "        if \"CLAHE\" in self.name:\n",
        "            self.preprocess = \"_CLAHE\"\n",
        "        else:\n",
        "            self.preprocess = \"\"\n",
        "    \n",
        "    def select_part(self):\n",
        "        if \"disc\" in self.name:\n",
        "            self.part = \"disc\"\n",
        "        elif \"macula\" in self.name:\n",
        "            self.part = \"macula\"\n",
        "        else:\n",
        "            self.part = \"cropped\"\n",
        "\n",
        "    def output_dataset(self):\n",
        "        self.dst_path = self.DATASET_PATH + \"/test_\"+ self.part + self.preprocess +\"_img\"\n",
        "        return self.dst_path\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.2.0-py3-none-any.whl (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.2.0\n",
            "Collecting ranger-adabelief==0.1.0\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger-adabelief==0.1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (3.7.4.3)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-bfcb7f3b-6f77-3bbe-7f1e-fd007ab67df9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmiqljhz02F"
      },
      "source": [
        "import glob\n",
        "\n",
        "model_size = \"\"\n",
        "preprocess = \"\"\n",
        "for i in cols[1:]: #modelごとに結果を出す\n",
        "    print(i)\n",
        "    \n",
        "    if \"A2\" in i:\n",
        "        model_size_temp = \"A2\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    elif \"B3\" in i:\n",
        "        model_size_temp = \"B3\"\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    else:\n",
        "        print(\"A2あるいはB3で指定して下さい\")\n",
        "        sys.exit(1)\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/FundusPhoto/model/'+str(i)+\".pth\"))\n",
        "    model_ft.to(device)\n",
        "    \n",
        "    select_dataset = Select_dataset(i)\n",
        "    select_dataset.select_preprocess()\n",
        "    select_dataset.select_part()\n",
        "    data_path = select_dataset.output_dataset()\n",
        "\n",
        "    data_path = glob.glob(data_path+\"/*\")\n",
        "    print(data_path)\n",
        "\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        print(j)\n",
        "        #print(os.path.splitext(os.path.basename(m))[0])\n",
        "        #image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "        image_name = os.path.splitext(os.path.basename(j))[0]\n",
        "        image_tensor = image_transform(j)  #予測のための画像下処理\n",
        "        pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "        write_result(df_temp, image_name, pred, str(i))\n",
        "        #print(str(k)+\"/\"+str(len(df_temp)) + \" images processed! pred: \"+str(pred))\n",
        "        k+=1\n",
        "df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3Jw9LPgEgu"
      },
      "source": [
        "#save CSV file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_5_GB.csv'\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-eMHoKHnIsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedd28b6-9180-48dc-a206-b9293c019a6a"
      },
      "source": [
        "#load csv file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_concat.csv'\n",
        "df_temp = pd.read_csv(temp_path, index_col=0, sep=\",\")\n",
        "print(df_temp)\n",
        "\n",
        "dst_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv'\n",
        "df_dst = pd.read_csv(dst_path, index_col=0, sep=\",\")\n",
        "#df_dst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   age  ...  vascular_2_RGB_B3_GB_L1Loss_pretrained_4\n",
            "Unnamed: 1              ...                                          \n",
            "img76901008_06_1R   70  ...                                 53.131670\n",
            "img76901008_06_2L   68  ...                                 55.750787\n",
            "img76901008_07_1R   69  ...                                 52.608454\n",
            "img76901008_07_2L   66  ...                                 54.159564\n",
            "img77009741_01_1R   44  ...                                 50.823110\n",
            "...                ...  ...                                       ...\n",
            "img99962800_00_1L   29  ...                                 52.267468\n",
            "img99962810_00_1R   30  ...                                 51.456147\n",
            "img99962820_00_1R   30  ...                                 52.083141\n",
            "img99962830_00_1R   29  ...                                 51.914799\n",
            "img99962840_00_1R   30  ...                                 51.695716\n",
            "\n",
            "[401 rows x 155 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Jp4BqEhnKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76367153-8561-467b-b7c5-8d39a9cb0c60"
      },
      "source": [
        "from decimal import *\n",
        "\n",
        "#XGBoostのベストモデルを用いて予測をする\n",
        "def get_model_predicts(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "def my_round(x):\n",
        "    y = Decimal(x).quantize(Decimal('0'), rounding=ROUND_HALF_UP) \n",
        "    return int(y)\n",
        "\n",
        "FEATURE_COLS=df_temp.columns.values[1:].tolist()\n",
        "X_test = df_temp[FEATURE_COLS]\n",
        "#Y_test = df_temp[\"age\"]\n",
        "\n",
        "predictive_results = get_model_predicts(X_test, bestmodel)\n",
        "#print(predictive_results)\n",
        "\n",
        "predictive_results = [my_round(float(predictive_results[n])) for n in range(len(predictive_results))] \n",
        "print(predictive_results)\n",
        "\n",
        "df_temp.loc[:, \"age\"] = predictive_results\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[70, 70, 71, 69, 44, 34, 42, 57, 41, 39, 67, 63, 40, 67, 70, 61, 58, 59, 59, 59, 60, 61, 60, 62, 61, 63, 60, 62, 57, 61, 49, 59, 32, 70, 69, 47, 48, 65, 63, 60, 65, 61, 59, 59, 61, 58, 58, 50, 44, 60, 34, 30, 35, 31, 62, 49, 49, 59, 55, 60, 48, 54, 57, 34, 51, 60, 56, 61, 38, 36, 36, 37, 61, 61, 62, 62, 55, 46, 38, 41, 42, 59, 44, 51, 53, 48, 48, 37, 32, 33, 68, 45, 47, 35, 36, 33, 62, 72, 29, 66, 67, 35, 52, 59, 43, 69, 63, 31, 33, 31, 32, 33, 29, 30, 60, 60, 60, 60, 49, 45, 70, 61, 59, 30, 31, 34, 32, 30, 33, 71, 61, 64, 67, 63, 65, 61, 47, 55, 31, 58, 58, 65, 31, 50, 48, 59, 61, 61, 61, 63, 65, 67, 56, 65, 66, 44, 46, 60, 62, 60, 61, 71, 72, 60, 60, 58, 58, 61, 60, 53, 71, 72, 58, 60, 60, 60, 50, 33, 65, 66, 66, 61, 38, 36, 45, 62, 63, 59, 68, 57, 60, 63, 61, 57, 60, 49, 61, 54, 62, 50, 61, 60, 57, 57, 47, 31, 61, 61, 59, 60, 59, 60, 69, 64, 66, 66, 67, 42, 60, 60, 57, 67, 44, 56, 54, 59, 57, 61, 33, 58, 61, 65, 71, 71, 71, 71, 70, 38, 38, 31, 31, 34, 32, 31, 62, 46, 42, 59, 63, 61, 62, 57, 47, 56, 51, 57, 59, 42, 43, 29, 44, 60, 58, 60, 59, 30, 35, 34, 42, 60, 62, 62, 65, 61, 60, 62, 68, 31, 35, 51, 42, 40, 61, 38, 62, 60, 63, 60, 70, 68, 70, 68, 63, 61, 61, 58, 60, 63, 68, 57, 53, 61, 61, 61, 61, 67, 61, 66, 62, 64, 62, 60, 61, 61, 46, 62, 69, 59, 64, 66, 44, 46, 61, 60, 42, 43, 38, 39, 38, 38, 38, 35, 61, 62, 61, 47, 58, 44, 62, 60, 59, 29, 31, 35, 35, 35, 35, 29, 30, 61, 30, 30, 31, 30, 31, 30, 31, 32, 31, 32, 62, 63, 64, 58, 60, 60, 48, 62, 61, 61, 62, 59, 61, 41, 67, 67, 67, 68, 61, 61, 58, 51, 58, 60, 61, 68, 68, 55, 51, 65, 70, 60, 61, 29, 37, 29, 30, 29, 30, 29, 31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnvIk_wZy-PD"
      },
      "source": [
        "import os\n",
        "#目的のCSVに記載\n",
        "df_dst.iloc[3,1] = \"7_60004\"\n",
        "df_dst.iloc[4,1] = \"北口善之\"\n",
        "df_dst.iloc[7:408, 1] = predictive_results\n",
        "\n",
        "df_dst.to_csv(os.path.splitext(dst_path)[0]+\"20211028GB_concat\"+\".csv\", encoding='utf_8_sig')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp69lCxaTN8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}