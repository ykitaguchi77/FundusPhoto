{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled90.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/FundusPhoto_sample_Pytorch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4vbMuKXy9W6",
        "outputId": "330f9815-41a5-4d3d-fc5f-b477733dba30"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu102)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM3zE1Ft0exa"
      },
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "os.chdir(DATASET_PATH)\n",
        "\n",
        "TRAIN_FOLDER_NAME = 'cropped_img_trainval/train' #TRAINイメージのフォルダ\n",
        "VAL_FOLDER_NAME = 'cropped_img_trainval/val' #VALイメージのフォルダ\n",
        "TEST_FOLDER_NAME = 'cropped_img_trainval/test' #TESTイメージのフォルダ\n",
        "\n",
        "FILENAME_LABELCSV = 'name_age.csv' #年齢の値のcsv\n",
        "FILENAME_RESULTCSV = 'result.csv' #年齢推定結果を書き出すcsv\n",
        "imagesize_process = (128,128)  #処理時の画像サイズ→小さすぎるような気がする？\n",
        "\n",
        "NET_NAME = \"RepVGG-A2-train\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth\"\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "LOG_PATH = \"./log_multi.txt\"\n",
        "ROC_PATH = \"./roc_multi.png\"\n",
        "CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "PATIENCE = 20 #early stopping patience; how long to wait after last time validation loss improved.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "\n",
        "# transforms param\n",
        "PX = 224\n",
        "TRAIN_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "TRAIN_CROP_SCALE =(0.75,1.0)\n",
        "TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "TRAIN_CONTRAST_PARAM = 0.1\n",
        "TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZKmxPlVMuzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822e43ad-7eae-4c1f-a673-45513bc7a36f"
      },
      "source": [
        "#csvファイルを開く\n",
        "df_labelcsv = pd.read_csv(FILENAME_LABELCSV)\n",
        "\n",
        "#csvファイルを表示\n",
        "print(df_labelcsv)\n",
        "\n",
        "#ID,ageの列の値をリストとして取り出す\n",
        "df_filename = df_labelcsv['filename'].values\n",
        "df_age = df_labelcsv['age'].values\n",
        "\n",
        "#CSVファイル内の画像数\n",
        "print(len(df_labelcsv))\n",
        "\n",
        "#画像フォルダ内の画像数\n",
        "print(len(os.listdir(DATASET_PATH +\"/\"+ TRAIN_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_PATH +\"/\"+ VAL_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_PATH +\"/\"+ TEST_FOLDER_NAME)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   filename  age\n",
            "0     img00085008_00_1R.jpg   61\n",
            "1     img00085024_00_1R.jpg   29\n",
            "2     img00241280_10_1R.jpg   51\n",
            "3     img00265140_00_1R.jpg   29\n",
            "4     img00265140_00_2L.jpg   29\n",
            "...                     ...  ...\n",
            "1409  img76791392_10_1R.jpg   38\n",
            "1410  img76843122_10_1R.jpg   49\n",
            "1411  img76843122_11_1R.jpg   49\n",
            "1412  img76888512_00_1R.jpg   74\n",
            "1413  img76888512_00_2L.jpg   74\n",
            "\n",
            "[1414 rows x 2 columns]\n",
            "1414\n",
            "1414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuvpokR8L08T"
      },
      "source": [
        "'''\n",
        "folder_path = DATASET_PATH +\"/\" + TRAIN_FOLDER_NAME\n",
        "img_name = os.listdir(folder_path)[1000]\n",
        "print(img_name)\n",
        "\n",
        "age_temp = df_labelcsv[df_labelcsv['filename'] == img_name].iloc[0,1]\n",
        "print(age_temp)\n",
        "\n",
        "image_path = os.path.join(folder_path, img_name)\n",
        "print(image_path)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tvnfgq1MOdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d084333-24ac-42c1-9068-3acd5c15db31"
      },
      "source": [
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, folder_path, csv_path, transform):\n",
        "        self.transform = transform\n",
        "        self.folder_path = folder_path\n",
        "        self.item_paths = []\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "\n",
        "        for i in range(len(os.listdir(folder_path))):\n",
        "              img_name = os.listdir(self.folder_path)[i]\n",
        "              age_temp = df_labelcsv[df_labelcsv['filename'] == img_name].iloc[0,1] #age\n",
        "              self.age.append(float(age_temp)/100)\n",
        "\n",
        "              img_path = os.path.join(self.folder_path, img_name)\n",
        "              self.item_paths.append(img_path)\n",
        "              #self.item_dict[image_path] = self.age\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.item_paths[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor([self.age[idx]])      \n",
        "        return tensor_image, target\n",
        "\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(TRAIN_NORMALIZE_PARAM[0], TRAIN_NORMALIZE_PARAM[1])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(VAL_NORMALIZE_PARAM[0], VAL_NORMALIZE_PARAM[1])]) \n",
        "\n",
        "train_dataset = SimpleImageDataset(os.path.join(DATASET_PATH, TRAIN_FOLDER_NAME), os.path.join(DATASET_PATH, FILENAME_LABELCSV), train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(os.path.join(DATASET_PATH, VAL_FOLDER_NAME), os.path.join(DATASET_PATH, FILENAME_LABELCSV),  val_data_transforms)\n",
        "test_dataset = SimpleImageDataset(os.path.join(DATASET_PATH, TEST_FOLDER_NAME), os.path.join(DATASET_PATH, FILENAME_LABELCSV),  val_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 1, shuffle = False)\n",
        "\n",
        "\n",
        "print(TRAIN_FOLDER_NAME + \"_dataset_size：\" + str(len(train_dataset)))\n",
        "print(VAL_FOLDER_NAME + \"_dataset_size：\" + str(len(val_dataset)))\n",
        "print(TEST_FOLDER_NAME + \"_dataset_size：\" + str(len(test_dataset)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cropped_img_trainval/train_dataset_size：989\n",
            "cropped_img_trainval/val_dataset_size：282\n",
            "cropped_img_trainval/test_dataset_size：143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsX2CbQib1aH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb80ca2-0fb6-4a86-fe67-1f52fdffd2b5"
      },
      "source": [
        "print(train_dataset[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "         ...,\n",
            "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "         ...,\n",
            "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "         ...,\n",
            "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]), tensor([0.3700]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnhcy_3eC29V"
      },
      "source": [
        "# ディレクトリ内の画像を読み込む\n",
        "# inputpath: ディレクトリのパス, imagesize: 画像サイズ, type_color: ColorかGray\n",
        "\n",
        "\n",
        "def load_images(inputpath, imagesize, type_color):\n",
        "    imglist = []\n",
        "    filenamelist = []\n",
        "\n",
        "    for root, dirs, files in os.walk(inputpath):\n",
        "        t=1\n",
        "        for fn in sorted(files):\n",
        "            bn, ext = os.path.splitext(fn)\n",
        "            if ext not in [\".bmp\", \".BMP\", \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\", \".PNG\"]:\n",
        "                continue\n",
        "            # if 'R.jpg' not in fn:\n",
        "            #     continue\n",
        "\n",
        "            filename = os.path.join(root, fn)\n",
        "            \n",
        "            if type_color == 'Color':\n",
        "                # カラー画像の場合\n",
        "                testimage = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
        "                # サイズ変更\n",
        "                height, width = testimage.shape[:2]\n",
        "                testimage = cv2.resize(testimage, imagesize, interpolation = cv2.INTER_AREA)  #主に縮小するのでINTER_AREA使用\n",
        "                testimage = np.asarray(testimage, dtype=np.float32)\n",
        "                # 色チャンネル，高さ，幅に入れ替え．data_format=\"channels_first\"を使うとき必要\n",
        "                #testimage = testimage.transpose(2, 0, 1)\n",
        "                # チャンネルをbgrからrgbの順に変更\n",
        "                #testimage = testimage[:,:,::-1]\n",
        "\n",
        "                #cv2_imshow(testimage)\n",
        "                print(str(t))\n",
        "                t+=1\n",
        "\n",
        "            \n",
        "            elif type_color == 'Gray':\n",
        "                # グレースケール画像の場合\n",
        "                testimage = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "                # サイズ変更\n",
        "                height, width = testimage.shape[:2]\n",
        "                testimage = cv2.resize(testimage, imagesize, interpolation = cv2.INTER_AREA)  #主に縮小するのでINTER_AREA使用\n",
        "                # チャンネルの次元がないので1次元追加する\n",
        "                testimage = np.asarray(testimage, dtype=np.float32).reshape((imagesize[1], imagesize[0], 1))\n",
        "                # チャンネル，高さ，幅に入れ替え．data_format=\"channels_first\"を使うとき必要\n",
        "                #testimage = testimage.transpose(2, 0, 1)\n",
        "\n",
        "            imglist.append(testimage)\n",
        "            filenamelist.append(fn)\n",
        "    imgsdata = np.asarray(imglist, dtype=np.float32)\n",
        "\n",
        "    return imgsdata, filenamelist  # 画像リストとファイル名のリストを返す\n",
        "\n",
        "\n",
        "\n",
        "#読み込んだ画像ファイル名リストに対して正解年齢リストを作成して返す\n",
        "#読み込んだ画像ファイル名リスト，csvのファイル名リスト，csvの年齢リストを受け取り，ファイル名が一致したら年齢を割り当てる\n",
        "def get_label(image_filenames, label_filename, label_age):\n",
        "    labels = []\n",
        "    for i in range(len(image_filenames)):\n",
        "        labelfound = False\n",
        "        for j in range(len(label_filename)):\n",
        "            if image_filenames[i] == label_filename[j]:\n",
        "                labels.append(label_age[j])\n",
        "                labelfound = True\n",
        "                break\n",
        "        \n",
        "        #csv中に画像に該当するageがなかった\n",
        "        if labelfound == False:\n",
        "            labels.append(-1)    #目印としてラベルを-1にする\n",
        "            print('Age data is not found for %s'%(image_filenames[i]))\n",
        "            \n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdNnaNyrUnek"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_duLR4O1VJ9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "3b5fcf2d-2d4f-4782-d80c-980203073a41"
      },
      "source": [
        "os.listdir(\"./crop_img\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-34ef60302746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./crop_img\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './crop_img'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "I7uACCBKVAJS",
        "outputId": "54d9631b-6a45-4d36-e299-d70ab485e7ff"
      },
      "source": [
        "#trainデータをtrainとtestデータに分割（8:2）\n",
        "image_train, image_test, label_train, label_test = train_test_split(image, label, test_size=0.2)\n",
        "\n",
        "print('Data load finished')\n",
        "print('Data numbers for train: ' + repr(len(image_train)) + ', test: ' + repr(len(image_test)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ce1f403ffe44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#trainデータをtrainとtestデータに分割（8:2）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data load finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data numbers for train: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', test: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g83veOZjrYqE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "c42c6677-a950-48b2-a4fb-dfa2ca8dfcdb"
      },
      "source": [
        "#trainデータをtrainとtestデータに分割（8:2）\n",
        "image_train, image_test, label_train, label_test = train_test_split(image, label, test_size=0.2)\n",
        "\n",
        "print('Data load finished')\n",
        "print('Data numbers for train: ' + repr(len(image_train)) + ', test: ' + repr(len(image_test)))\n",
        "\n",
        "\n",
        "#値の正規化\n",
        "image_train /= 255.0\n",
        "image_test /= 255.0\n",
        "\n",
        "label_train /= 100.0 #年齢は100で割る\n",
        "label_test /= 100.0\n",
        "\n",
        "\n",
        "#%%\n",
        "#年齢推定モデル\n",
        "def model_cnn1():\n",
        "    input_img = Input(shape=(imagesize_process[1], imagesize_process[0], 3))\n",
        "    \n",
        "    x = Conv2D(16, kernel_size=3, strides=1, activation='relu', padding='same')(input_img)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(16, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
        "    \n",
        "    x = Conv2D(32, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(32, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
        "    \n",
        "    x = Conv2D(64, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
        "    \n",
        "    x = Conv2D(128, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
        "    \n",
        "    x = Conv2D(256, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    x = Dense(64, activation='linear')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(8, activation='linear')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    \n",
        "    x = Dense(1, activation='linear')(x)\n",
        "    \n",
        "    model = Model(inputs=input_img, outputs=x)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = model_cnn1()\n",
        "\n",
        "#モデル構造表示\n",
        "#print(model.summary())\n",
        "\n",
        "\n",
        "#学習の設定\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(lr=0.00001)\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "#学習\n",
        "training = model.fit(image_train, label_train,\n",
        "                    epochs=50, batch_size=6, shuffle=True, validation_data=(image_test, label_test), verbose=1)\n",
        "\n",
        "\n",
        "#学習済みモデルをファイルに保存\n",
        "#モデル\n",
        "json_string = model.to_json()\n",
        "open('model.json', 'w').write(json_string)\n",
        "#重み\n",
        "model.save_weights('weight.hdf5')\n",
        "\n",
        "\n",
        "#学習履歴表示\n",
        "def plot_history(history):\n",
        "    plt.plot(history.history['mae'])\n",
        "    plt.plot(history.history['val_mae'])\n",
        "    plt.title('mean absolute error')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('mae')\n",
        "    plt.yscale('log')\n",
        "    plt.legend(['mae', 'val_mae'], loc='lower right')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.yscale('log')\n",
        "    plt.legend(['loss', 'val_loss'], loc='lower right')\n",
        "    plt.show()\n",
        "    \n",
        "plot_history(training)\n",
        "\n",
        "\n",
        "#testデータを用いた推定\n",
        "result = model.predict(image_test, verbose=1)\n",
        "\n",
        "#値の範囲を元に戻す\n",
        "label_test = label_test*100.0\n",
        "result = result*100.0\n",
        "\n",
        "result_mse = mean_squared_error(label_test, result)\n",
        "print('MSE : %.2f'%(result_mse ** 0.5))\n",
        "\n",
        "\n",
        "#推定結果をcsvファイルに書き出し\n",
        "f = open(FILENAME_RESULTCSV, 'w')\n",
        "writer = csv.writer(f, lineterminator='\\n')\n",
        "\n",
        "savedata = ['true_age', 'estimate_age']\n",
        "writer.writerow(savedata)\n",
        "\n",
        "for i in range(len(label_test)):\n",
        "    savedata = [label_test[i], result[i][0]]\n",
        "    writer.writerow(savedata)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5c9482ab9ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#データ準備\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#画像読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mimage_org\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_org_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./img_train/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Color'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#画像clippingし左右の黒帯部分を除く\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-5c9482ab9ac3>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(inputpath, imagesize, type_color)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_color\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Color'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# カラー画像の場合\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mtestimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# サイズ変更\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}