{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled90.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/FundusPhoto_crossvalidation1.4s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjtHca50fine"
      },
      "source": [
        "#変更点\n",
        "・CLAHE処理を行い画像ごとのヒストグラムの平坦化を行った<br>\n",
        "・平均と標準偏差による標準化は行っていない<br>\n",
        "・回転の前に250px切り抜きを入れ、回転により画像が切れないようにした<br>\n",
        "・Gaussian blurを入れた![スクリーンショット 2021-10-13 220246.jpg](data:image/jpeg;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4vbMuKXy9W6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0cacca2-6d34-4a1e-d552-4c7ecb7c36db"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-27fdc045-488a-714f-6421-8ab5ecb2e293)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV9UyGl4BL3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "d0e266de-d9b3-4a98-e37f-88e3285396ab"
      },
      "source": [
        "name = \"cropped_CLAHE\"\n",
        "model = \"A2\"\n",
        "version = \"GaussianBlur\"\n",
        "if version is not \"\":\n",
        "    version = \"_\"+str(version)\n",
        "\n",
        "MODEL_NAME = name +\"_\"+model+version+\"_pretrained\"\n",
        "DATASET_NAME = name+'_img_trainval'\n",
        "DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "NET_NAME = \"RepVGG_\" +model  #RepVGG_A2 or RepVGG_B3\n",
        "PRETRAINED = True\n",
        "\n",
        "os.chdir(DATASET_PATH)\n",
        "\n",
        "TRAIN_FOLDER_NAME = 'train' #TRAINイメージのフォルダ\n",
        "VAL_FOLDER_NAME = 'val' #VALイメージのフォルダ\n",
        "\n",
        "FILENAME_LABELCSV = 'name_age.csv' #年齢の値のcsv\n",
        "FILENAME_RESULTCSV = 'result_3.csv' #年齢推定結果を書き出すcsv\n",
        "FILENAME_RESULT_ANALYSISCSV = 'result_analysis_3.csv' #推定結果の解析結果を書き出すcsv\n",
        "\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto/model'\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "LOG_PATH = \"./log_multi.txt\"\n",
        "ROC_PATH = \"./roc_multi.png\"\n",
        "CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "PATIENCE = 20 #early stopping patience; how long to wait after last time validation loss improved.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "\n",
        "# transforms param\n",
        "PX = 224 #画像のサイズ\n",
        "\n",
        "#cropped_CLAHE_img\n",
        "NORMALIZE_AVE = [0.543, 0.353, 0.228]\n",
        "NORMALIZE_STD = [0.135, 0.11,  0.072]\n",
        "\n",
        "TRAIN_CROP_SCALE =(0.85,1.0)\n",
        "TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "TRAIN_CONTRAST_PARAM = 0.1\n",
        "TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "\n",
        "\n",
        "#csvファイルを開く\n",
        "df_labelcsv = pd.read_csv(FILENAME_LABELCSV)\n",
        "\n",
        "#csvファイルを表示\n",
        "print(df_labelcsv)\n",
        "\n",
        "#ID,ageの列の値をリストとして取り出す\n",
        "df_filename = df_labelcsv['filename'].values\n",
        "df_age = df_labelcsv['age'].values\n",
        "\n",
        "#CSVファイル内の画像数\n",
        "print(len(df_labelcsv))\n",
        "\n",
        "\"\"\"\n",
        "#画像フォルダ内の画像数\n",
        "print(len(os.listdir(DATASET_NAME +\"/\"+ TRAIN_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_NAME +\"/\"+ VAL_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_NAME +\"/\"+ TEST_FOLDER_NAME)))\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   filename  age\n",
            "0     img00085008_00_1R.jpg   61\n",
            "1     img00085024_00_1R.jpg   29\n",
            "2     img00241280_10_1R.jpg   51\n",
            "3     img00265140_00_1R.jpg   29\n",
            "4     img00265140_00_2L.jpg   29\n",
            "...                     ...  ...\n",
            "1409  img76791392_10_1R.jpg   38\n",
            "1410  img76843122_10_1R.jpg   49\n",
            "1411  img76843122_11_1R.jpg   49\n",
            "1412  img76888512_00_1R.jpg   74\n",
            "1413  img76888512_00_2L.jpg   74\n",
            "\n",
            "[1414 rows x 2 columns]\n",
            "1414\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#画像フォルダ内の画像数\\nprint(len(os.listdir(DATASET_NAME +\"/\"+ TRAIN_FOLDER_NAME))\\n+len(os.listdir(DATASET_NAME +\"/\"+ VAL_FOLDER_NAME))\\n+len(os.listdir(DATASET_NAME +\"/\"+ TEST_FOLDER_NAME)))\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ejg4rneA3qI"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srdzPaN3A1nr"
      },
      "source": [
        "####################################\n",
        "#Test with early-stopping\n",
        "####################################\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    #Optimize GPU computation\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=True):\n",
        "                output = model(image_tensor)\n",
        "                loss = loss_func(output, target)       \n",
        "                # calculate the loss\n",
        "                loss = loss_func(output, target)\n",
        "\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            scaler.scale(loss).backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            scaler.update()\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor)\n",
        "            # calculate the loss\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df.loc[df_result.iloc[:,0].str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "\n",
        "#水増し後の画像を可視化する関数\n",
        "def show_img(dataset):\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(5):\n",
        "        image, label = dataset[i]\n",
        "        #image = image.permute(1, 2, 0)\n",
        "        image = image.numpy().transpose((1,2,0))\n",
        "        image = np.clip(image, 0, 1)\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
        "        plt.tick_params(bottom=False, left=False, right=False, top=False)\n",
        "        plt.imshow(image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####################################\n",
        "##### Datasets and Dataloader ############\n",
        "#####################################\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, folder_path, csv_path, transform):\n",
        "        self.transform = transform\n",
        "        self.folder_path = folder_path\n",
        "        self.item_paths = []\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "\n",
        "        for i in range(len(os.listdir(folder_path))):\n",
        "              img_name = os.listdir(self.folder_path)[i]\n",
        "              name = os.path.splitext(img_name)[0] #拡張子を削除したもの\n",
        "              age_temp = df_labelcsv[df_labelcsv['filename'].str.contains(name)].iloc[0,1] #age\n",
        "              self.age.append(float(age_temp)/100)\n",
        "\n",
        "              img_path = os.path.join(self.folder_path, img_name)\n",
        "              self.item_paths.append(img_path)\n",
        "              #self.item_dict[image_path] = self.age\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.item_paths[idx]\n",
        "        pilr_image = read_image(image_path)\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor([self.age[idx]])      \n",
        "        return tensor_image, target\n",
        "\n",
        "\n",
        "train_data_transforms = nn.Sequential(\n",
        "                transforms.RandomResizedCrop(250, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomRotation(degrees=10),\n",
        "                transforms.CenterCrop(PX),\n",
        "                transforms.GaussianBlur(3, sigma=(0.01, 2.0)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),        \n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                #transforms.Normalize(NORMALIZE_AVE, NORMALIZE_STD)\n",
        "                )\n",
        "val_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                #transforms.Normalize(NORMALIZE_AVE, NORMALIZE_STD)\n",
        "                ) \n",
        "test_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                #transforms.Normalize(NORMALIZE_AVE, NORMALIZE_STD)\n",
        "                ) \n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "#画像の可視化\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, \"1\", TRAIN_FOLDER_NAME), FILENAME_LABELCSV, train_data_transforms)\n",
        "show_img(train_dataset)\n",
        "\n",
        "#print(train_dataset[1])\n",
        "\n",
        "elapsed_time = round(time.time() - start_time, 2)\n",
        "print(str(elapsed_time)+\" second\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKFWkJs5zGgb"
      },
      "source": [
        "#**Data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM3zE1Ft0exa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109d7c73-329d-4fb9-e57c-3bc5dfc90c45"
      },
      "source": [
        "#ここからがメイン\n",
        "start_time = time.time()\n",
        "\n",
        "process = [0,1,2,3,4]\n",
        "for i in process:\n",
        "    print(\"Start \"+ str(i) + \" th analysis!\")\n",
        "\n",
        "    train_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, str(i), TRAIN_FOLDER_NAME), FILENAME_LABELCSV, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, str(i), VAL_FOLDER_NAME), FILENAME_LABELCSV,  val_data_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "    #print(TRAIN_FOLDER_NAME + \"_dataset_size：\" + str(len(train_dataset)))\n",
        "    #print(VAL_FOLDER_NAME + \"_dataset_size：\" + str(len(val_dataset)))\n",
        "\n",
        "    ####################################\n",
        "    #ConvNetの調整\n",
        "    ####################################\n",
        "\n",
        "    if NET_NAME == \"RepVGG_A2\":\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        if PRETRAINED == True:\n",
        "            model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))\n",
        "            print(\"Pretrained model downloaded\")\n",
        "        elif PRETRAINED == False:\n",
        "            pass\n",
        "        else:\n",
        "            print(\"TrueあるいはFalseで指定して下さい\")\n",
        "            sys.exit(1)\n",
        "\n",
        "    elif NET_NAME == \"RepVGG_B3\":\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        if PRETRAINED == True:\n",
        "            model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-B3-200epochs-train.pth'))\n",
        "            print(\"Pretrained model downloaded\")\n",
        "        elif PRETRAINED == False:\n",
        "            pass\n",
        "        else:\n",
        "            print(\"TrueあるいはFalseで指定して下さい\")\n",
        "            sys.exit(1)\n",
        "    else:\n",
        "        print(\"RepVGG_A2あるいはRepVGG_B3を指定して下さい\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    #model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "    model_ft = mod_RepVGG()\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    loss_func = nn.MSELoss()\n",
        "\n",
        "    #Optimizer\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "    ####################################\n",
        "    # Train and Save network\n",
        "    ####################################\n",
        "\n",
        "    model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n",
        "\n",
        "    #ネットワークの保存\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    torch.save(model_ft.state_dict(), PATH)\n",
        "\n",
        "    ####################################\n",
        "    # Result Analysis\n",
        "    ####################################\n",
        "\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append((output[0]*100).item())      \n",
        "          targets.append((target[0]*100).item())\n",
        "          #print('estimate R:'+str(my_round(output[0,0].item()))+'mm, L:'+str(my_round(output[0,1].item()))+'mm / target R:'+str(target[0,0].item())+'mm, L:'+str(target[0,1].item())+'mm')\n",
        "\n",
        "          errors.append((output[0]*100).item()-(target[0]*100).item())\n",
        "    \n",
        "    AbsError = [abs(i) for i in errors]\n",
        "    MeanError = str(statistics.mean(errors))\n",
        "    StdError = str(statistics.stdev(errors))\n",
        "    MeanAbsError = str(statistics.mean(AbsError))\n",
        "    StdAbsError = str(statistics.stdev(AbsError))\n",
        "\n",
        "    print('MeanError: '+MeanError)\n",
        "    print('StdError: '+StdError)\n",
        "    print('MeanAbsError: '+MeanAbsError)\n",
        "    print('StdAbsError: '+StdAbsError)\n",
        "\n",
        "    \n",
        "    #result_analysis.csv作成（ファイルがなければ）\n",
        "    if os.path.exists(FILENAME_RESULT_ANALYSISCSV) == False:\n",
        "        columns = []\n",
        "        index = [\"AveError\", \"StdError\", \"AveAbsError\", \"StdAbsError\"]\n",
        "        df_result_analysis = pd.DataFrame(index=index, columns=columns)\n",
        "        df_result_analysis.to_csv(FILENAME_RESULT_ANALYSISCSV)\n",
        "    else:\n",
        "        print(FILENAME_RESULT_ANALYSISCSV + \" already exists!\")\n",
        "\n",
        "    df_result_analysis = pd.read_csv(FILENAME_RESULT_ANALYSISCSV, index_col=0)\n",
        "    df_result_analysis[MODEL_NAME+\"_\"+str(i)] = [MeanError, StdError, MeanAbsError, StdAbsError]\n",
        "\n",
        "\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'.csv'\n",
        "    df_result_analysis.to_csv(FILENAME_RESULT_ANALYSISCSV, index=True)\n",
        "    \n",
        "\n",
        "\n",
        "    #result.csv作成（ファイルがなければ）\n",
        "    if os.path.exists(FILENAME_RESULTCSV) == False:\n",
        "        df_result = df_labelcsv.copy()\n",
        "        df_result.to_csv(FILENAME_RESULTCSV, index=False)\n",
        "    else:\n",
        "        print(FILENAME_RESULTCSV + \" already exists!\")\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    #print(df_result)\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    #valフォルダ内のファイル名を取得\n",
        "    train_data_path = glob.glob(DATASET_NAME + \"/\" +str(i) + \"/\" + TRAIN_FOLDER_NAME+\"/*\")\n",
        "    val_data_path = glob.glob(DATASET_NAME + \"/\" + str(i) + \"/\" + VAL_FOLDER_NAME+\"/*\")\n",
        "\n",
        "    data_path = [train_data_path, val_data_path]\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        for m in j:\n",
        "              #print(m)\n",
        "              #print(os.path.splitext(os.path.basename(m))[0])\n",
        "              image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "              image_tensor = image_transform(m)  #予測のための画像下処理\n",
        "              pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "              write_result(df_result, image_name, pred, MODEL_NAME+\"_\"+str(i))\n",
        "              #print(str(k)+\"/\"+str(len(df_result)) + \" images processed! label: \"+str(label)+ \" , pred: \"+str(pred))\n",
        "              k+=1\n",
        "    #print(df_result)\n",
        "\n",
        "    #Resultファイルを書き出し\n",
        "    df_result.to_csv(FILENAME_RESULTCSV, index=False)\n",
        "\n",
        "\n",
        "    # calculate elapsed time\n",
        "    elapsed_time = int(time.time() - start_time)\n",
        "\n",
        "    # convert second to hour, minute and seconds\n",
        "    elapsed_hour = elapsed_time // 3600\n",
        "    elapsed_minute = (elapsed_time % 3600) // 60\n",
        "    elapsed_second = (elapsed_time % 3600 % 60)\n",
        "\n",
        "    # print as 00:00:00\n",
        "    print(str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start 0 th analysis!\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Pretrained model downloaded\n",
            "Epoch: [  1/100] \n",
            "train_loss: 0.10192 \n",
            "valid_loss: 0.02641 \n",
            "Validation loss decreased (inf --> 0.026412).  Saving model ...\n",
            "\n",
            "Epoch: [  2/100] \n",
            "train_loss: 0.02584 \n",
            "valid_loss: 0.04546 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  3/100] \n",
            "train_loss: 0.01402 \n",
            "valid_loss: 0.02702 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [  4/100] \n",
            "train_loss: 0.01269 \n",
            "valid_loss: 0.02634 \n",
            "Validation loss decreased (0.026412 --> 0.026341).  Saving model ...\n",
            "\n",
            "Epoch: [  5/100] \n",
            "train_loss: 0.01142 \n",
            "valid_loss: 0.00578 \n",
            "Validation loss decreased (0.026341 --> 0.005782).  Saving model ...\n",
            "\n",
            "Epoch: [  6/100] \n",
            "train_loss: 0.00996 \n",
            "valid_loss: 0.00937 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [  7/100] \n",
            "train_loss: 0.00756 \n",
            "valid_loss: 0.00604 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [  8/100] \n",
            "train_loss: 0.00973 \n",
            "valid_loss: 0.00753 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [  9/100] \n",
            "train_loss: 0.01039 \n",
            "valid_loss: 0.00608 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [ 10/100] \n",
            "train_loss: 0.00809 \n",
            "valid_loss: 0.00383 \n",
            "Validation loss decreased (0.005782 --> 0.003830).  Saving model ...\n",
            "\n",
            "Epoch: [ 11/100] \n",
            "train_loss: 0.00577 \n",
            "valid_loss: 0.00300 \n",
            "Validation loss decreased (0.003830 --> 0.003003).  Saving model ...\n",
            "\n",
            "Epoch: [ 12/100] \n",
            "train_loss: 0.00536 \n",
            "valid_loss: 0.00524 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 13/100] \n",
            "train_loss: 0.00676 \n",
            "valid_loss: 0.00339 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 14/100] \n",
            "train_loss: 0.00591 \n",
            "valid_loss: 0.00279 \n",
            "Validation loss decreased (0.003003 --> 0.002786).  Saving model ...\n",
            "\n",
            "Epoch: [ 15/100] \n",
            "train_loss: 0.00503 \n",
            "valid_loss: 0.00251 \n",
            "Validation loss decreased (0.002786 --> 0.002512).  Saving model ...\n",
            "\n",
            "Epoch: [ 16/100] \n",
            "train_loss: 0.00497 \n",
            "valid_loss: 0.00300 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 17/100] \n",
            "train_loss: 0.00516 \n",
            "valid_loss: 0.00369 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 18/100] \n",
            "train_loss: 0.00446 \n",
            "valid_loss: 0.00303 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 19/100] \n",
            "train_loss: 0.00465 \n",
            "valid_loss: 0.00201 \n",
            "Validation loss decreased (0.002512 --> 0.002011).  Saving model ...\n",
            "\n",
            "Epoch: [ 20/100] \n",
            "train_loss: 0.00430 \n",
            "valid_loss: 0.00666 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 21/100] \n",
            "train_loss: 0.00372 \n",
            "valid_loss: 0.00627 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 22/100] \n",
            "train_loss: 0.00379 \n",
            "valid_loss: 0.00582 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 23/100] \n",
            "train_loss: 0.00327 \n",
            "valid_loss: 0.00310 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "Epoch: [ 24/100] \n",
            "train_loss: 0.00408 \n",
            "valid_loss: 0.00126 \n",
            "Validation loss decreased (0.002011 --> 0.001263).  Saving model ...\n",
            "\n",
            "Epoch: [ 25/100] \n",
            "train_loss: 0.00297 \n",
            "valid_loss: 0.00178 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "Epoch: [ 26/100] \n",
            "train_loss: 0.00304 \n",
            "valid_loss: 0.00195 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "Epoch: [ 27/100] \n",
            "train_loss: 0.00294 \n",
            "valid_loss: 0.00141 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "Epoch: [ 28/100] \n",
            "train_loss: 0.00367 \n",
            "valid_loss: 0.00659 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg_lhEMldF5v"
      },
      "source": [
        "#**Load network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rVSslGCJNPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed575fe8-4639-4774-9a36-0768cbf84415"
      },
      "source": [
        "name = \"macula_2\"\n",
        "model = \"A2\"  #A2 or B3\n",
        "\n",
        "MODEL_NAME = name +\"_\"+model+\"_pretrained\"\n",
        "DATASET_NAME = name+'_img_trainval'\n",
        "DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "NET_NAME = \"RepVGG_\" +model  #RepVGG_A2 or RepVGG_B3\n",
        "PRETRAINED = True\n",
        "\n",
        "TRAIN_FOLDER_NAME = 'train' #TRAINイメージのフォルダ\n",
        "VAL_FOLDER_NAME = 'val' #VALイメージのフォルダ\n",
        "\n",
        "FILENAME_LABELCSV = 'name_age.csv' #年齢の値のcsv\n",
        "FILENAME_RESULTCSV = 'result_2.csv' #年齢推定結果を書き出すcsv\n",
        "FILENAME_RESULT_ANALYSISCSV = 'result_analysis_2.csv' #推定結果の解析結果を書き出すcsv\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto/model'\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "\n",
        "if NET_NAME == \"RepVGG_A2\":\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "elif NET_NAME == \"RepVGG_B3\":\n",
        "    model_ft = create_RepVGG_B3(deploy=False)\n",
        "\n",
        "else:\n",
        "    print(\"RepVGG_A2あるいはRepVGG_B3を指定して下さい\")\n",
        "    sys.exit(1)\n",
        "\n",
        "#model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7Jlr21roBg"
      },
      "source": [
        "#ここからがメイン\n",
        "process = [0,1,2,3,4]\n",
        "for i in process:\n",
        "    print(\"Start \"+ str(i) + \" th analysis!\")\n",
        "\n",
        "    #トレーニングしたパラメーターを適用\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    model_ft.load_state_dict(torch.load(PATH))\n",
        "    model_ft.eval()\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    print(PATH)\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    #valフォルダ内のファイル名を取得\n",
        "    train_data_path = glob.glob(DATASET_NAME + \"/\" +str(i) + \"/\" + TRAIN_FOLDER_NAME+\"/*\")\n",
        "    val_data_path = glob.glob(DATASET_NAME + \"/\" + str(i) + \"/\" + VAL_FOLDER_NAME+\"/*\")\n",
        "\n",
        "    data_path = [train_data_path, val_data_path]\n",
        "    preds,targets,errors =[], [], []\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        for m in j:\n",
        "              image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前とラベルを取得\n",
        "              image_tensor = image_transform(m)  #予測のための画像下処理\n",
        "              pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "              write_result(df_result, image_name, pred, MODEL_NAME+\"_\"+str(i))\n",
        "              print(str(k)+\"/\"+str(len(df_result))+\" th image: \"+str(image_name)+\", pred: \"+str(my_round(pred, d=1))+\", label: \"+str(label))\n",
        "\n",
        "              preds.append(pred)      \n",
        "              targets.append(label)\n",
        "              errors.append(pred-label)\n",
        "\n",
        "              k+=1\n",
        "    print(df_result)\n",
        "\n",
        "    AbsError = [abs(i) for i in errors]\n",
        "    MeanError = str(statistics.mean(errors))\n",
        "    StdError = str(statistics.stdev(errors))\n",
        "    MeanAbsError = str(statistics.mean(AbsError))\n",
        "    StdAbsError = str(statistics.stdev(AbsError))\n",
        "    print('MeanError: '+MeanError)\n",
        "    print('StdError: '+StdError)\n",
        "    print('MeanAbsError: '+MeanAbsError)\n",
        "    print('StdAbsError: '+StdAbsError)\n",
        "    print()\n",
        "\n",
        "    #Resultファイルを書き出し\n",
        "    df_result.to_csv(FILENAME_RESULTCSV, index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdMWm5gkEsXa",
        "outputId": "642f43dc-b323-470b-93f7-3f30f9a70175"
      },
      "source": [
        "#######################\n",
        "##1枚の画像のみを判定\n",
        "#######################\n",
        "\n",
        "print(MODEL_PATH)\n",
        "print(MODEL_NAME)\n",
        "\n",
        "#ファイル名を取得\n",
        "img_name = \"img00085008_00_1R.png\"\n",
        "img_path1 = \"/content/drive/MyDrive/Deep_learning/FundusPhoto/\"+name+\"_img_trainval/0/train/\"+img_name\n",
        "img_path2 = \"/content/drive/MyDrive/Deep_learning/FundusPhoto/\"+name+\"_img_trainval/0/val/\"+img_name\n",
        "\n",
        "for i in [img_path1, img_path2]:\n",
        "    is_file = os.path.isfile(i)\n",
        "    if is_file:\n",
        "        img_path = i\n",
        "        print(\"aaa\")\n",
        "    else:\n",
        "        pass # パスが存在しないかファイルではない\n",
        "        print(\"bbb\")\n",
        "\n",
        "\n",
        "outputs = []\n",
        "for i in range(5):\n",
        "    #トレーニングしたパラメーターを適用\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    model_ft.load_state_dict(torch.load(PATH))\n",
        "    model_ft.eval()\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    print(MODEL_NAME+'_'+str(i)+'.pth')\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    image_tensor = image_transform(img_path)  #予測のための画像下処理\n",
        "    pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "\n",
        "    outputs.append(pred)\n",
        "\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/model\n",
            "macula_2_A2_pretrained\n",
            "aaa\n",
            "bbb\n",
            "macula_2_A2_pretrained_0.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_1.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_2.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_3.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_4.pth\n",
            "Calculating prediction results!\n",
            "[44.820716977119446, 68.22026371955872, 54.96704578399658, 54.79089617729187, 50.11647343635559]\n"
          ]
        }
      ]
    }
  ]
}