{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled69.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1JnO8G8KM3eaL7zL7IrR7NU-Q2MllCCtk",
      "authorship_tag": "ABX9TyMLBnljitWPGjd/NzP9vrFt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/RandomForest_and_XGBoost_1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOmIegf1c6s",
        "outputId": "5a2c8c0f-b485-4365-c964-c6befd739bda"
      },
      "source": [
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNbbDfQ5lid"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/result_5_GaussianBlur.csv\", index_col=0, sep=\",\")\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mqY5TnHxuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9470c83-94ca-46c1-d7c1-e751d78886f3"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df.columns.values[1:].tolist()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cropped_2_A2_GaussianBlur_pretrained_0', 'cropped_2_A2_GaussianBlur_pretrained_1', 'cropped_2_A2_GaussianBlur_pretrained_2', 'cropped_2_A2_GaussianBlur_pretrained_3', 'cropped_2_A2_GaussianBlur_pretrained_4', 'disc_2_A2_GaussianBlur_pretrained_0', 'disc_2_A2_GaussianBlur_pretrained_1', 'disc_2_A2_GaussianBlur_pretrained_2', 'disc_2_A2_GaussianBlur_pretrained_3', 'disc_2_A2_GaussianBlur_pretrained_4', 'macula_2_A2_GaussianBlur_pretrained_0', 'macula_2_A2_GaussianBlur_pretrained_1', 'macula_2_A2_GaussianBlur_pretrained_2', 'macula_2_A2_GaussianBlur_pretrained_3', 'macula_2_A2_GaussianBlur_pretrained_4', 'cropped_2_B3_GaussianBlur_pretrained_0', 'cropped_2_B3_GaussianBlur_pretrained_1', 'cropped_2_B3_GaussianBlur_pretrained_2', 'cropped_2_B3_GaussianBlur_pretrained_3', 'cropped_2_B3_GaussianBlur_pretrained_4', 'disc_2_B3_GaussianBlur_pretrained_0', 'disc_2_B3_GaussianBlur_pretrained_1', 'disc_2_B3_GaussianBlur_pretrained_2', 'disc_2_B3_GaussianBlur_pretrained_3', 'disc_2_B3_GaussianBlur_pretrained_4', 'macula_2_B3_GaussianBlur_pretrained_0', 'macula_2_B3_GaussianBlur_pretrained_1', 'macula_2_B3_GaussianBlur_pretrained_2', 'macula_2_B3_GaussianBlur_pretrained_3', 'macula_2_B3_GaussianBlur_pretrained_4', 'vascular_2_RGB_B3_GaussianBlur_pretrained_0', 'vascular_2_RGB_B3_GaussianBlur_pretrained_1', 'vascular_2_RGB_B3_GaussianBlur_pretrained_2', 'vascular_2_RGB_B3_GaussianBlur_pretrained_3', 'vascular_2_RGB_B3_GaussianBlur_pretrained_4', 'cropped_CLAHE_A2_ver2_pretrained_0', 'cropped_CLAHE_A2_ver2_pretrained_1', 'cropped_CLAHE_A2_ver2_pretrained_2', 'cropped_CLAHE_A2_ver2_pretrained_3', 'cropped_CLAHE_A2_ver2_pretrained_4', 'cropped_CLAHE_B3_ver2_pretrained_0', 'cropped_CLAHE_B3_ver2_pretrained_1', 'cropped_CLAHE_B3_ver2_pretrained_2', 'cropped_CLAHE_B3_ver2_pretrained_3', 'cropped_CLAHE_B3_ver2_pretrained_4', 'disc_CLAHE_A2_ver2_pretrained_0', 'disc_CLAHE_A2_ver2_pretrained_1', 'disc_CLAHE_A2_ver2_pretrained_2', 'disc_CLAHE_A2_ver2_pretrained_3', 'disc_CLAHE_A2_ver2_pretrained_4', 'disc_CLAHE_B3_ver2_pretrained_0', 'disc_CLAHE_B3_ver2_pretrained_1', 'disc_CLAHE_B3_ver2_pretrained_2', 'disc_CLAHE_B3_ver2_pretrained_3', 'disc_CLAHE_B3_ver2_pretrained_4', 'macula_CLAHE_A2_ver2_pretrained_0', 'macula_CLAHE_A2_ver2_pretrained_1', 'macula_CLAHE_A2_ver2_pretrained_2', 'macula_CLAHE_A2_ver2_pretrained_3', 'macula_CLAHE_A2_ver2_pretrained_4', 'macula_CLAHE_B3_ver2_pretrained_0', 'macula_CLAHE_B3_ver2_pretrained_1', 'macula_CLAHE_B3_ver2_pretrained_2', 'macula_CLAHE_B3_ver2_pretrained_3', 'macula_CLAHE_B3_ver2_pretrained_4', 'vascular_CLAHE_A2_ver2_pretrained_0', 'vascular_CLAHE_A2_ver2_pretrained_1', 'vascular_CLAHE_A2_ver2_pretrained_2', 'vascular_CLAHE_A2_ver2_pretrained_3', 'vascular_CLAHE_A2_ver2_pretrained_4', 'vascular_CLAHE_B3_ver2_pretrained_0', 'vascular_CLAHE_B3_ver2_pretrained_1', 'vascular_CLAHE_B3_ver2_pretrained_2', 'vascular_CLAHE_B3_ver2_pretrained_3', 'vascular_CLAHE_B3_ver2_pretrained_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzK-7A7RRXiu"
      },
      "source": [
        "#**Prediction accuracy for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZej9BelRsro"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"age\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"age\"]\n",
        "    print(str(i))\n",
        "    get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    print(\"\")\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpy4m8XyRKtV"
      },
      "source": [
        "#**Analysis using XGBoost**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/12/07/000022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20JJ1H4Nmva"
      },
      "source": [
        "# Grid Search用のパラメータ作成。\n",
        "# あまり組み合わせが多いと時間がかかる(time consuming)\n",
        "params = {\n",
        "        'eta': [0.01],             # default = 0.3      \n",
        "        'gamma': [1,2,3],            # default = 0\n",
        "        'max_depth': [7,8,9],      # default = 6\n",
        "        'min_child_weight': [1],   # default = 1\n",
        "        'subsample': [0.8,1.0],        # default = 1\n",
        "        'colsample_bytree': [0.8,1.0], # default = 1\n",
        "        }\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 1)\n",
        "\n",
        "#最適解探索\n",
        "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error', n_jobs=2, cv=kf.split(X_train,Y_train), verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXBzlSIrNu3u"
      },
      "source": [
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d966OQgNzX9",
        "outputId": "c714e855-2b5f-447d-ec39-09734996510a"
      },
      "source": [
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9996140059420859',\n",
              " 'adjusted_r2(test)      :0.9840444881494275',\n",
              " '平均誤差率(test)       :0.017274756476184355',\n",
              " 'MAE(test)              :0.9026960905364882',\n",
              " 'MedianAE(test)         :0.5393524169921875',\n",
              " 'RMSE(test)             :1.6526005955769107',\n",
              " 'RMSE(test) / MAE(test) :1.830738620563584')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wq2xWzPPEln"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=bestmodel.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AseFYOzD8mV7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = bestmodel.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIobiMOEPGKc"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='gain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnbP5EF_6pc9"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpEpFczPHkK"
      },
      "source": [
        "xgb.to_graphviz(bestmodel, num_trees=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-Kj_RHRQ-9"
      },
      "source": [
        "#**Analysis using RandomForest**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/11/14/200857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSyqmEyGRfHU"
      },
      "source": [
        "#Create model\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=10)\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\"\"\"\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "           oob_score=False, random_state=2525, verbose=0, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_result(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW6HVmKTUWsB"
      },
      "source": [
        "#Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(X_train,Y_train)\n",
        "\n",
        "\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkW5oubR4MJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rci5gcXQQ9XG"
      },
      "source": [
        "\"\"\"\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('Importances')\n",
        "plt.rcParams['font.size']=10\n",
        "sns.barplot(y='features', x='importances', data=df_s, palette='viridis')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DihmVVSbKI"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3Qw-hrjFi-"
      },
      "source": [
        "#**Analysis using neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwwcmwczMwfE"
      },
      "source": [
        "#正規化する\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#モデル作成\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "model = MLPRegressor(alpha=0.1, hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive', max_iter=500, random_state=42, solver=\"lbfgs\", early_stopping=True) \n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "初期設定：\n",
        "\n",
        "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "       verbose=False, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcqR8-Nj1E9"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlExOBk8fCoE"
      },
      "source": [
        "#**Predict age from test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zC8VftCfIcr",
        "outputId": "4b412827-5010-405a-b260-848d7874a3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>60.885948</td>\n",
              "      <td>60.356665</td>\n",
              "      <td>50.935251</td>\n",
              "      <td>59.631753</td>\n",
              "      <td>58.965695</td>\n",
              "      <td>45.052648</td>\n",
              "      <td>60.332221</td>\n",
              "      <td>61.809397</td>\n",
              "      <td>59.062302</td>\n",
              "      <td>68.153375</td>\n",
              "      <td>51.562381</td>\n",
              "      <td>58.757454</td>\n",
              "      <td>68.297571</td>\n",
              "      <td>59.610933</td>\n",
              "      <td>55.720055</td>\n",
              "      <td>58.482534</td>\n",
              "      <td>59.504211</td>\n",
              "      <td>45.093548</td>\n",
              "      <td>58.708310</td>\n",
              "      <td>57.960665</td>\n",
              "      <td>44.306228</td>\n",
              "      <td>62.429917</td>\n",
              "      <td>47.746590</td>\n",
              "      <td>60.145330</td>\n",
              "      <td>59.885645</td>\n",
              "      <td>63.356745</td>\n",
              "      <td>62.210029</td>\n",
              "      <td>52.995640</td>\n",
              "      <td>60.519272</td>\n",
              "      <td>57.649809</td>\n",
              "      <td>63.051468</td>\n",
              "      <td>61.155617</td>\n",
              "      <td>60.746276</td>\n",
              "      <td>38.692406</td>\n",
              "      <td>57.933575</td>\n",
              "      <td>51.513016</td>\n",
              "      <td>60.443723</td>\n",
              "      <td>59.180284</td>\n",
              "      <td>57.925946</td>\n",
              "      <td>61.356062</td>\n",
              "      <td>50.794721</td>\n",
              "      <td>59.937066</td>\n",
              "      <td>57.612771</td>\n",
              "      <td>61.397052</td>\n",
              "      <td>46.190515</td>\n",
              "      <td>45.208085</td>\n",
              "      <td>57.761061</td>\n",
              "      <td>63.372260</td>\n",
              "      <td>58.118635</td>\n",
              "      <td>59.059167</td>\n",
              "      <td>45.416451</td>\n",
              "      <td>62.391269</td>\n",
              "      <td>46.070179</td>\n",
              "      <td>60.394639</td>\n",
              "      <td>58.396441</td>\n",
              "      <td>63.028634</td>\n",
              "      <td>60.167629</td>\n",
              "      <td>63.968349</td>\n",
              "      <td>55.218077</td>\n",
              "      <td>53.921479</td>\n",
              "      <td>61.277235</td>\n",
              "      <td>61.864400</td>\n",
              "      <td>64.423221</td>\n",
              "      <td>47.498825</td>\n",
              "      <td>39.615372</td>\n",
              "      <td>66.959667</td>\n",
              "      <td>66.500616</td>\n",
              "      <td>62.237757</td>\n",
              "      <td>48.370329</td>\n",
              "      <td>61.953497</td>\n",
              "      <td>54.935169</td>\n",
              "      <td>56.899101</td>\n",
              "      <td>60.968000</td>\n",
              "      <td>32.802081</td>\n",
              "      <td>59.452468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>29.766262</td>\n",
              "      <td>30.331397</td>\n",
              "      <td>29.118884</td>\n",
              "      <td>31.672752</td>\n",
              "      <td>30.989829</td>\n",
              "      <td>26.809660</td>\n",
              "      <td>32.241669</td>\n",
              "      <td>30.086446</td>\n",
              "      <td>30.817971</td>\n",
              "      <td>32.113385</td>\n",
              "      <td>26.403788</td>\n",
              "      <td>27.999404</td>\n",
              "      <td>31.571031</td>\n",
              "      <td>26.205668</td>\n",
              "      <td>21.942243</td>\n",
              "      <td>28.228927</td>\n",
              "      <td>28.847709</td>\n",
              "      <td>27.994281</td>\n",
              "      <td>28.715485</td>\n",
              "      <td>28.885067</td>\n",
              "      <td>26.357773</td>\n",
              "      <td>28.899875</td>\n",
              "      <td>26.704368</td>\n",
              "      <td>28.894490</td>\n",
              "      <td>28.859845</td>\n",
              "      <td>28.657392</td>\n",
              "      <td>28.822759</td>\n",
              "      <td>22.991714</td>\n",
              "      <td>28.690979</td>\n",
              "      <td>25.721887</td>\n",
              "      <td>34.075314</td>\n",
              "      <td>31.509855</td>\n",
              "      <td>33.798274</td>\n",
              "      <td>38.365373</td>\n",
              "      <td>29.952043</td>\n",
              "      <td>33.798340</td>\n",
              "      <td>32.601157</td>\n",
              "      <td>31.196275</td>\n",
              "      <td>27.557728</td>\n",
              "      <td>33.944768</td>\n",
              "      <td>30.446360</td>\n",
              "      <td>29.304698</td>\n",
              "      <td>26.477981</td>\n",
              "      <td>29.368344</td>\n",
              "      <td>27.883038</td>\n",
              "      <td>24.574579</td>\n",
              "      <td>28.125578</td>\n",
              "      <td>30.332983</td>\n",
              "      <td>27.869955</td>\n",
              "      <td>30.062532</td>\n",
              "      <td>28.621274</td>\n",
              "      <td>26.432323</td>\n",
              "      <td>25.892881</td>\n",
              "      <td>28.595570</td>\n",
              "      <td>27.253726</td>\n",
              "      <td>27.305934</td>\n",
              "      <td>29.994479</td>\n",
              "      <td>28.159496</td>\n",
              "      <td>25.735974</td>\n",
              "      <td>21.707861</td>\n",
              "      <td>27.959991</td>\n",
              "      <td>28.589666</td>\n",
              "      <td>28.499722</td>\n",
              "      <td>21.598046</td>\n",
              "      <td>26.380828</td>\n",
              "      <td>35.283571</td>\n",
              "      <td>41.595712</td>\n",
              "      <td>40.237117</td>\n",
              "      <td>50.527757</td>\n",
              "      <td>33.700836</td>\n",
              "      <td>30.545381</td>\n",
              "      <td>32.332805</td>\n",
              "      <td>29.989961</td>\n",
              "      <td>32.775521</td>\n",
              "      <td>33.086747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>58.364809</td>\n",
              "      <td>50.553083</td>\n",
              "      <td>63.250524</td>\n",
              "      <td>54.238850</td>\n",
              "      <td>50.851762</td>\n",
              "      <td>63.289428</td>\n",
              "      <td>54.653805</td>\n",
              "      <td>49.245375</td>\n",
              "      <td>50.571257</td>\n",
              "      <td>57.794720</td>\n",
              "      <td>49.765614</td>\n",
              "      <td>49.845201</td>\n",
              "      <td>54.795003</td>\n",
              "      <td>59.864140</td>\n",
              "      <td>54.611915</td>\n",
              "      <td>57.051009</td>\n",
              "      <td>54.708534</td>\n",
              "      <td>57.299381</td>\n",
              "      <td>49.541694</td>\n",
              "      <td>54.624343</td>\n",
              "      <td>52.290088</td>\n",
              "      <td>56.760901</td>\n",
              "      <td>47.204936</td>\n",
              "      <td>52.778614</td>\n",
              "      <td>52.187645</td>\n",
              "      <td>51.639259</td>\n",
              "      <td>53.236330</td>\n",
              "      <td>44.357553</td>\n",
              "      <td>52.916056</td>\n",
              "      <td>56.503397</td>\n",
              "      <td>47.425610</td>\n",
              "      <td>57.344145</td>\n",
              "      <td>51.043272</td>\n",
              "      <td>55.263293</td>\n",
              "      <td>48.160061</td>\n",
              "      <td>59.604460</td>\n",
              "      <td>67.162800</td>\n",
              "      <td>52.348655</td>\n",
              "      <td>52.609223</td>\n",
              "      <td>58.175653</td>\n",
              "      <td>49.676123</td>\n",
              "      <td>60.613930</td>\n",
              "      <td>48.423052</td>\n",
              "      <td>51.381540</td>\n",
              "      <td>53.468233</td>\n",
              "      <td>63.071638</td>\n",
              "      <td>48.292780</td>\n",
              "      <td>52.528238</td>\n",
              "      <td>50.668210</td>\n",
              "      <td>50.591427</td>\n",
              "      <td>58.855903</td>\n",
              "      <td>51.447606</td>\n",
              "      <td>50.004244</td>\n",
              "      <td>49.102244</td>\n",
              "      <td>52.055264</td>\n",
              "      <td>51.907486</td>\n",
              "      <td>50.094593</td>\n",
              "      <td>50.960755</td>\n",
              "      <td>52.623403</td>\n",
              "      <td>58.816636</td>\n",
              "      <td>49.755388</td>\n",
              "      <td>53.065294</td>\n",
              "      <td>58.409935</td>\n",
              "      <td>55.093735</td>\n",
              "      <td>55.827039</td>\n",
              "      <td>53.996080</td>\n",
              "      <td>54.605067</td>\n",
              "      <td>49.949187</td>\n",
              "      <td>61.310375</td>\n",
              "      <td>54.841155</td>\n",
              "      <td>50.700021</td>\n",
              "      <td>48.117417</td>\n",
              "      <td>53.539336</td>\n",
              "      <td>62.086725</td>\n",
              "      <td>50.764579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.213056</td>\n",
              "      <td>31.123018</td>\n",
              "      <td>29.923308</td>\n",
              "      <td>31.866950</td>\n",
              "      <td>31.424466</td>\n",
              "      <td>33.026874</td>\n",
              "      <td>27.775347</td>\n",
              "      <td>31.257206</td>\n",
              "      <td>30.184183</td>\n",
              "      <td>31.335768</td>\n",
              "      <td>28.773826</td>\n",
              "      <td>28.549322</td>\n",
              "      <td>29.491693</td>\n",
              "      <td>27.227801</td>\n",
              "      <td>29.133636</td>\n",
              "      <td>28.235692</td>\n",
              "      <td>31.660154</td>\n",
              "      <td>30.401087</td>\n",
              "      <td>29.131159</td>\n",
              "      <td>27.815926</td>\n",
              "      <td>33.806103</td>\n",
              "      <td>34.369171</td>\n",
              "      <td>30.322504</td>\n",
              "      <td>30.721486</td>\n",
              "      <td>30.021170</td>\n",
              "      <td>27.490881</td>\n",
              "      <td>30.023479</td>\n",
              "      <td>23.335579</td>\n",
              "      <td>29.751483</td>\n",
              "      <td>28.661990</td>\n",
              "      <td>33.212128</td>\n",
              "      <td>37.661710</td>\n",
              "      <td>37.906623</td>\n",
              "      <td>35.059234</td>\n",
              "      <td>30.629086</td>\n",
              "      <td>32.447189</td>\n",
              "      <td>34.168077</td>\n",
              "      <td>30.493429</td>\n",
              "      <td>29.301286</td>\n",
              "      <td>33.749220</td>\n",
              "      <td>31.672558</td>\n",
              "      <td>29.825637</td>\n",
              "      <td>29.177326</td>\n",
              "      <td>31.059107</td>\n",
              "      <td>28.019741</td>\n",
              "      <td>29.460776</td>\n",
              "      <td>28.995550</td>\n",
              "      <td>30.806449</td>\n",
              "      <td>31.359655</td>\n",
              "      <td>30.032742</td>\n",
              "      <td>31.992900</td>\n",
              "      <td>26.391345</td>\n",
              "      <td>27.324587</td>\n",
              "      <td>28.775471</td>\n",
              "      <td>32.848647</td>\n",
              "      <td>31.013748</td>\n",
              "      <td>26.702192</td>\n",
              "      <td>24.901672</td>\n",
              "      <td>27.801692</td>\n",
              "      <td>21.340437</td>\n",
              "      <td>28.522485</td>\n",
              "      <td>29.261309</td>\n",
              "      <td>28.128195</td>\n",
              "      <td>25.244799</td>\n",
              "      <td>26.992267</td>\n",
              "      <td>36.704639</td>\n",
              "      <td>38.350153</td>\n",
              "      <td>35.942692</td>\n",
              "      <td>47.493604</td>\n",
              "      <td>35.055676</td>\n",
              "      <td>27.620485</td>\n",
              "      <td>30.764979</td>\n",
              "      <td>30.090940</td>\n",
              "      <td>38.280925</td>\n",
              "      <td>33.655614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.485062</td>\n",
              "      <td>31.811762</td>\n",
              "      <td>30.549696</td>\n",
              "      <td>32.765386</td>\n",
              "      <td>31.352851</td>\n",
              "      <td>35.573980</td>\n",
              "      <td>32.451853</td>\n",
              "      <td>30.288148</td>\n",
              "      <td>31.099230</td>\n",
              "      <td>30.537629</td>\n",
              "      <td>29.595745</td>\n",
              "      <td>27.726558</td>\n",
              "      <td>31.044161</td>\n",
              "      <td>32.806641</td>\n",
              "      <td>29.797870</td>\n",
              "      <td>29.842737</td>\n",
              "      <td>28.483209</td>\n",
              "      <td>29.473320</td>\n",
              "      <td>28.350401</td>\n",
              "      <td>31.485087</td>\n",
              "      <td>32.985473</td>\n",
              "      <td>37.007666</td>\n",
              "      <td>28.809839</td>\n",
              "      <td>28.963286</td>\n",
              "      <td>29.689914</td>\n",
              "      <td>26.915285</td>\n",
              "      <td>28.129721</td>\n",
              "      <td>24.725600</td>\n",
              "      <td>28.009915</td>\n",
              "      <td>28.578359</td>\n",
              "      <td>31.528470</td>\n",
              "      <td>32.324287</td>\n",
              "      <td>38.401335</td>\n",
              "      <td>32.143921</td>\n",
              "      <td>30.726725</td>\n",
              "      <td>40.375280</td>\n",
              "      <td>33.965418</td>\n",
              "      <td>29.740995</td>\n",
              "      <td>29.303265</td>\n",
              "      <td>34.901044</td>\n",
              "      <td>28.703645</td>\n",
              "      <td>28.300020</td>\n",
              "      <td>27.297571</td>\n",
              "      <td>30.610925</td>\n",
              "      <td>27.929401</td>\n",
              "      <td>31.178254</td>\n",
              "      <td>29.032320</td>\n",
              "      <td>29.705697</td>\n",
              "      <td>27.765700</td>\n",
              "      <td>33.182472</td>\n",
              "      <td>31.730193</td>\n",
              "      <td>27.523825</td>\n",
              "      <td>26.797888</td>\n",
              "      <td>29.070142</td>\n",
              "      <td>31.052959</td>\n",
              "      <td>28.335732</td>\n",
              "      <td>27.585560</td>\n",
              "      <td>29.050910</td>\n",
              "      <td>27.625880</td>\n",
              "      <td>24.823041</td>\n",
              "      <td>30.414790</td>\n",
              "      <td>29.290730</td>\n",
              "      <td>30.451465</td>\n",
              "      <td>22.950853</td>\n",
              "      <td>27.947775</td>\n",
              "      <td>41.916993</td>\n",
              "      <td>34.301230</td>\n",
              "      <td>36.889029</td>\n",
              "      <td>42.366844</td>\n",
              "      <td>34.267986</td>\n",
              "      <td>29.653075</td>\n",
              "      <td>34.019947</td>\n",
              "      <td>31.958094</td>\n",
              "      <td>30.553010</td>\n",
              "      <td>31.945181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>38.199157</td>\n",
              "      <td>39.335907</td>\n",
              "      <td>38.415360</td>\n",
              "      <td>40.701389</td>\n",
              "      <td>37.806478</td>\n",
              "      <td>37.474301</td>\n",
              "      <td>32.679823</td>\n",
              "      <td>31.805116</td>\n",
              "      <td>37.843254</td>\n",
              "      <td>33.726096</td>\n",
              "      <td>36.371392</td>\n",
              "      <td>49.667397</td>\n",
              "      <td>39.193630</td>\n",
              "      <td>38.588050</td>\n",
              "      <td>34.526837</td>\n",
              "      <td>38.396522</td>\n",
              "      <td>35.274139</td>\n",
              "      <td>38.497335</td>\n",
              "      <td>38.434505</td>\n",
              "      <td>34.112072</td>\n",
              "      <td>35.426679</td>\n",
              "      <td>35.021561</td>\n",
              "      <td>28.289860</td>\n",
              "      <td>35.640907</td>\n",
              "      <td>36.847824</td>\n",
              "      <td>37.365493</td>\n",
              "      <td>46.835411</td>\n",
              "      <td>31.393817</td>\n",
              "      <td>38.262957</td>\n",
              "      <td>42.541334</td>\n",
              "      <td>36.452386</td>\n",
              "      <td>44.501454</td>\n",
              "      <td>43.832183</td>\n",
              "      <td>44.443870</td>\n",
              "      <td>36.340073</td>\n",
              "      <td>42.409110</td>\n",
              "      <td>40.077686</td>\n",
              "      <td>37.977579</td>\n",
              "      <td>36.893642</td>\n",
              "      <td>42.594829</td>\n",
              "      <td>39.264897</td>\n",
              "      <td>37.870255</td>\n",
              "      <td>35.099649</td>\n",
              "      <td>38.703468</td>\n",
              "      <td>34.652242</td>\n",
              "      <td>31.834236</td>\n",
              "      <td>34.224910</td>\n",
              "      <td>31.262583</td>\n",
              "      <td>33.991134</td>\n",
              "      <td>38.869512</td>\n",
              "      <td>35.793000</td>\n",
              "      <td>35.120636</td>\n",
              "      <td>26.139495</td>\n",
              "      <td>35.731488</td>\n",
              "      <td>29.872346</td>\n",
              "      <td>44.848314</td>\n",
              "      <td>51.827860</td>\n",
              "      <td>44.909871</td>\n",
              "      <td>31.455088</td>\n",
              "      <td>40.449962</td>\n",
              "      <td>38.877404</td>\n",
              "      <td>52.941495</td>\n",
              "      <td>43.271992</td>\n",
              "      <td>35.293564</td>\n",
              "      <td>37.773979</td>\n",
              "      <td>35.583228</td>\n",
              "      <td>44.036415</td>\n",
              "      <td>43.149778</td>\n",
              "      <td>50.892937</td>\n",
              "      <td>35.965312</td>\n",
              "      <td>31.347474</td>\n",
              "      <td>29.877606</td>\n",
              "      <td>39.098856</td>\n",
              "      <td>34.426931</td>\n",
              "      <td>37.632969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>53.196847</td>\n",
              "      <td>45.640141</td>\n",
              "      <td>45.546347</td>\n",
              "      <td>51.625419</td>\n",
              "      <td>50.128996</td>\n",
              "      <td>48.410195</td>\n",
              "      <td>42.230716</td>\n",
              "      <td>46.253222</td>\n",
              "      <td>51.311338</td>\n",
              "      <td>51.198155</td>\n",
              "      <td>48.310232</td>\n",
              "      <td>45.538834</td>\n",
              "      <td>44.979483</td>\n",
              "      <td>52.453923</td>\n",
              "      <td>44.837600</td>\n",
              "      <td>47.394177</td>\n",
              "      <td>48.088434</td>\n",
              "      <td>49.969494</td>\n",
              "      <td>49.401051</td>\n",
              "      <td>50.176543</td>\n",
              "      <td>47.796735</td>\n",
              "      <td>57.036519</td>\n",
              "      <td>50.078702</td>\n",
              "      <td>50.911272</td>\n",
              "      <td>49.306154</td>\n",
              "      <td>49.032882</td>\n",
              "      <td>48.545510</td>\n",
              "      <td>33.817515</td>\n",
              "      <td>41.229436</td>\n",
              "      <td>50.404090</td>\n",
              "      <td>50.643623</td>\n",
              "      <td>59.744704</td>\n",
              "      <td>54.123229</td>\n",
              "      <td>57.273388</td>\n",
              "      <td>48.106965</td>\n",
              "      <td>54.108298</td>\n",
              "      <td>49.421489</td>\n",
              "      <td>48.863503</td>\n",
              "      <td>51.081926</td>\n",
              "      <td>55.026782</td>\n",
              "      <td>44.446120</td>\n",
              "      <td>46.082148</td>\n",
              "      <td>45.929974</td>\n",
              "      <td>50.156689</td>\n",
              "      <td>40.987971</td>\n",
              "      <td>45.965067</td>\n",
              "      <td>46.292043</td>\n",
              "      <td>51.588768</td>\n",
              "      <td>49.585876</td>\n",
              "      <td>53.223592</td>\n",
              "      <td>49.383083</td>\n",
              "      <td>52.410209</td>\n",
              "      <td>49.659091</td>\n",
              "      <td>48.516831</td>\n",
              "      <td>47.656766</td>\n",
              "      <td>52.504253</td>\n",
              "      <td>47.339574</td>\n",
              "      <td>49.313083</td>\n",
              "      <td>48.411244</td>\n",
              "      <td>54.349107</td>\n",
              "      <td>48.708078</td>\n",
              "      <td>44.102505</td>\n",
              "      <td>56.852949</td>\n",
              "      <td>48.273543</td>\n",
              "      <td>50.966114</td>\n",
              "      <td>49.529347</td>\n",
              "      <td>57.750505</td>\n",
              "      <td>62.443388</td>\n",
              "      <td>64.850932</td>\n",
              "      <td>52.418566</td>\n",
              "      <td>45.366701</td>\n",
              "      <td>56.356877</td>\n",
              "      <td>51.327443</td>\n",
              "      <td>56.484932</td>\n",
              "      <td>51.421803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>56.886828</td>\n",
              "      <td>50.544816</td>\n",
              "      <td>47.587875</td>\n",
              "      <td>52.457392</td>\n",
              "      <td>50.793570</td>\n",
              "      <td>52.799886</td>\n",
              "      <td>45.932961</td>\n",
              "      <td>44.371003</td>\n",
              "      <td>51.916403</td>\n",
              "      <td>50.504851</td>\n",
              "      <td>44.726014</td>\n",
              "      <td>42.309937</td>\n",
              "      <td>45.024800</td>\n",
              "      <td>40.706378</td>\n",
              "      <td>42.950150</td>\n",
              "      <td>55.220819</td>\n",
              "      <td>48.409539</td>\n",
              "      <td>49.657461</td>\n",
              "      <td>49.004924</td>\n",
              "      <td>47.710246</td>\n",
              "      <td>47.885427</td>\n",
              "      <td>55.062169</td>\n",
              "      <td>52.543592</td>\n",
              "      <td>51.201683</td>\n",
              "      <td>50.496775</td>\n",
              "      <td>49.698067</td>\n",
              "      <td>47.475055</td>\n",
              "      <td>29.821983</td>\n",
              "      <td>40.268657</td>\n",
              "      <td>56.234378</td>\n",
              "      <td>50.509459</td>\n",
              "      <td>53.434712</td>\n",
              "      <td>52.482903</td>\n",
              "      <td>54.819530</td>\n",
              "      <td>47.122028</td>\n",
              "      <td>56.916833</td>\n",
              "      <td>47.124928</td>\n",
              "      <td>49.280134</td>\n",
              "      <td>51.028162</td>\n",
              "      <td>54.305077</td>\n",
              "      <td>45.320338</td>\n",
              "      <td>45.486036</td>\n",
              "      <td>45.827433</td>\n",
              "      <td>50.921273</td>\n",
              "      <td>45.166197</td>\n",
              "      <td>45.776716</td>\n",
              "      <td>43.373102</td>\n",
              "      <td>52.698910</td>\n",
              "      <td>50.443983</td>\n",
              "      <td>50.774556</td>\n",
              "      <td>50.571752</td>\n",
              "      <td>50.687742</td>\n",
              "      <td>45.854795</td>\n",
              "      <td>48.858061</td>\n",
              "      <td>47.505662</td>\n",
              "      <td>49.167371</td>\n",
              "      <td>44.990662</td>\n",
              "      <td>43.962091</td>\n",
              "      <td>37.034979</td>\n",
              "      <td>45.219013</td>\n",
              "      <td>47.632921</td>\n",
              "      <td>47.237745</td>\n",
              "      <td>51.599389</td>\n",
              "      <td>49.923894</td>\n",
              "      <td>52.648532</td>\n",
              "      <td>43.682286</td>\n",
              "      <td>51.910472</td>\n",
              "      <td>57.996839</td>\n",
              "      <td>63.871813</td>\n",
              "      <td>53.339827</td>\n",
              "      <td>41.465706</td>\n",
              "      <td>50.168628</td>\n",
              "      <td>47.388595</td>\n",
              "      <td>50.673580</td>\n",
              "      <td>47.501767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>56.605852</td>\n",
              "      <td>71.386600</td>\n",
              "      <td>74.264765</td>\n",
              "      <td>73.703772</td>\n",
              "      <td>72.917128</td>\n",
              "      <td>68.061024</td>\n",
              "      <td>74.160743</td>\n",
              "      <td>74.606669</td>\n",
              "      <td>42.933744</td>\n",
              "      <td>78.277564</td>\n",
              "      <td>73.981255</td>\n",
              "      <td>69.788361</td>\n",
              "      <td>79.573733</td>\n",
              "      <td>68.793005</td>\n",
              "      <td>71.677345</td>\n",
              "      <td>70.824075</td>\n",
              "      <td>70.887142</td>\n",
              "      <td>74.848467</td>\n",
              "      <td>73.488754</td>\n",
              "      <td>73.900068</td>\n",
              "      <td>71.458507</td>\n",
              "      <td>79.234850</td>\n",
              "      <td>59.871906</td>\n",
              "      <td>43.737605</td>\n",
              "      <td>69.913667</td>\n",
              "      <td>70.363796</td>\n",
              "      <td>72.958624</td>\n",
              "      <td>59.976119</td>\n",
              "      <td>71.317726</td>\n",
              "      <td>78.840834</td>\n",
              "      <td>68.769974</td>\n",
              "      <td>62.816906</td>\n",
              "      <td>66.310376</td>\n",
              "      <td>50.796282</td>\n",
              "      <td>63.409376</td>\n",
              "      <td>73.446184</td>\n",
              "      <td>73.985189</td>\n",
              "      <td>72.136509</td>\n",
              "      <td>41.176051</td>\n",
              "      <td>74.108410</td>\n",
              "      <td>71.727496</td>\n",
              "      <td>73.163122</td>\n",
              "      <td>71.883512</td>\n",
              "      <td>50.149459</td>\n",
              "      <td>42.128849</td>\n",
              "      <td>62.418151</td>\n",
              "      <td>72.725224</td>\n",
              "      <td>70.131874</td>\n",
              "      <td>40.971538</td>\n",
              "      <td>67.298412</td>\n",
              "      <td>70.631576</td>\n",
              "      <td>70.113695</td>\n",
              "      <td>67.158145</td>\n",
              "      <td>38.507593</td>\n",
              "      <td>71.599281</td>\n",
              "      <td>69.768119</td>\n",
              "      <td>72.111243</td>\n",
              "      <td>71.698058</td>\n",
              "      <td>59.377652</td>\n",
              "      <td>66.876441</td>\n",
              "      <td>71.785337</td>\n",
              "      <td>71.052480</td>\n",
              "      <td>54.430097</td>\n",
              "      <td>75.378466</td>\n",
              "      <td>68.461561</td>\n",
              "      <td>50.635380</td>\n",
              "      <td>58.496195</td>\n",
              "      <td>65.064138</td>\n",
              "      <td>62.762278</td>\n",
              "      <td>63.558018</td>\n",
              "      <td>65.622163</td>\n",
              "      <td>66.379267</td>\n",
              "      <td>69.048905</td>\n",
              "      <td>58.793271</td>\n",
              "      <td>62.333030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>69.049191</td>\n",
              "      <td>66.318005</td>\n",
              "      <td>73.155653</td>\n",
              "      <td>73.523390</td>\n",
              "      <td>72.985840</td>\n",
              "      <td>66.385049</td>\n",
              "      <td>68.927622</td>\n",
              "      <td>68.367136</td>\n",
              "      <td>53.513491</td>\n",
              "      <td>75.332546</td>\n",
              "      <td>74.130625</td>\n",
              "      <td>71.575391</td>\n",
              "      <td>88.524705</td>\n",
              "      <td>60.911018</td>\n",
              "      <td>71.346241</td>\n",
              "      <td>68.293542</td>\n",
              "      <td>72.224498</td>\n",
              "      <td>74.863398</td>\n",
              "      <td>72.767866</td>\n",
              "      <td>71.941185</td>\n",
              "      <td>73.264325</td>\n",
              "      <td>76.172227</td>\n",
              "      <td>64.452952</td>\n",
              "      <td>60.746992</td>\n",
              "      <td>71.590483</td>\n",
              "      <td>72.297430</td>\n",
              "      <td>71.659863</td>\n",
              "      <td>77.320302</td>\n",
              "      <td>67.448586</td>\n",
              "      <td>84.819227</td>\n",
              "      <td>68.363243</td>\n",
              "      <td>61.668277</td>\n",
              "      <td>61.990064</td>\n",
              "      <td>61.996752</td>\n",
              "      <td>69.304931</td>\n",
              "      <td>75.359941</td>\n",
              "      <td>75.762445</td>\n",
              "      <td>74.979699</td>\n",
              "      <td>58.212060</td>\n",
              "      <td>77.444780</td>\n",
              "      <td>72.709912</td>\n",
              "      <td>71.166813</td>\n",
              "      <td>73.550236</td>\n",
              "      <td>63.982975</td>\n",
              "      <td>61.108553</td>\n",
              "      <td>67.346680</td>\n",
              "      <td>71.876681</td>\n",
              "      <td>72.344667</td>\n",
              "      <td>52.216482</td>\n",
              "      <td>65.165257</td>\n",
              "      <td>71.095788</td>\n",
              "      <td>72.969925</td>\n",
              "      <td>64.384335</td>\n",
              "      <td>40.342388</td>\n",
              "      <td>66.356200</td>\n",
              "      <td>77.711433</td>\n",
              "      <td>72.259676</td>\n",
              "      <td>68.837053</td>\n",
              "      <td>56.474066</td>\n",
              "      <td>68.393230</td>\n",
              "      <td>70.054871</td>\n",
              "      <td>71.892542</td>\n",
              "      <td>64.663768</td>\n",
              "      <td>76.430416</td>\n",
              "      <td>68.551928</td>\n",
              "      <td>57.218838</td>\n",
              "      <td>69.687325</td>\n",
              "      <td>72.499788</td>\n",
              "      <td>58.394593</td>\n",
              "      <td>71.370292</td>\n",
              "      <td>65.477729</td>\n",
              "      <td>61.437380</td>\n",
              "      <td>67.572218</td>\n",
              "      <td>58.184642</td>\n",
              "      <td>73.169208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 76 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_CLAHE_B3_ver2_pretrained_4\n",
              "filename                    ...                                     \n",
              "img00085008_00_1R.jpg   61  ...                            59.452468\n",
              "img00085024_00_1R.jpg   29  ...                            33.086747\n",
              "img00241280_10_1R.jpg   51  ...                            50.764579\n",
              "img00265140_00_1R.jpg   29  ...                            33.655614\n",
              "img00265140_00_2L.jpg   29  ...                            31.945181\n",
              "...                    ...  ...                                  ...\n",
              "img76791392_10_1R.jpg   38  ...                            37.632969\n",
              "img76843122_10_1R.jpg   49  ...                            51.421803\n",
              "img76843122_11_1R.jpg   49  ...                            47.501767\n",
              "img76888512_00_1R.jpg   74  ...                            62.333030\n",
              "img76888512_00_2L.jpg   74  ...                            73.169208\n",
              "\n",
              "[1414 rows x 76 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8L_f0Qdq17-",
        "outputId": "d99d31c4-bd51-4c40-f7ca-e1e5ff35a32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "#評価用ファイルの呼び出し\n",
        "df_dst = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv\", index_col=0, sep=\",\")\n",
        "df_dst\n",
        "\n",
        "index = df_dst.iloc[7:408,0] #画像名リスト\n",
        "cols = df.columns #modelリスト\n",
        "\n",
        "df_temp = pd.DataFrame(index=index, columns=cols)\n",
        "df_temp\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img76901008_06_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_06_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img77009741_01_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962800_00_1L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962810_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962820_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962830_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962840_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 76 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   age  ... vascular_CLAHE_B3_ver2_pretrained_4\n",
              "Unnamed: 1              ...                                    \n",
              "img76901008_06_1R  NaN  ...                                 NaN\n",
              "img76901008_06_2L  NaN  ...                                 NaN\n",
              "img76901008_07_1R  NaN  ...                                 NaN\n",
              "img76901008_07_2L  NaN  ...                                 NaN\n",
              "img77009741_01_1R  NaN  ...                                 NaN\n",
              "...                ...  ...                                 ...\n",
              "img99962800_00_1L  NaN  ...                                 NaN\n",
              "img99962810_00_1R  NaN  ...                                 NaN\n",
              "img99962820_00_1R  NaN  ...                                 NaN\n",
              "img99962830_00_1R  NaN  ...                                 NaN\n",
              "img99962840_00_1R  NaN  ...                                 NaN\n",
              "\n",
              "[401 rows x 76 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGbfrHokrOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f64afa4-c0f3-40e8-aed4-b02432ce4e32"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "#!pip install adabelief-pytorch==0.1.0\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "\"\"\"\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\"\"\"\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入##########改変要\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df_temp.loc[df_temp.index.str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "class Select_dataset:\n",
        "    \"\"\"\n",
        "    「name = cropped_CLAHE_A2_pretrained_2」\n",
        "    からモデルのダウンロードとdatasetの選択を行う\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.preprocess = \"\"\n",
        "        self.part = \"\"\n",
        "        self.DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "        self.dst_path = \"\"\n",
        "\n",
        "    def select_preprocess(self):\n",
        "        if \"CLAHE\" in self.name:\n",
        "            self.preprocess = \"_CLAHE\"\n",
        "        else:\n",
        "            self.preprocess = \"\"\n",
        "    \n",
        "    def select_part(self):\n",
        "        if \"disc\" in self.name:\n",
        "            self.part = \"disc\"\n",
        "        elif \"macula\" in self.name:\n",
        "            self.part = \"macula\"\n",
        "        else:\n",
        "            self.part = \"cropped\"\n",
        "\n",
        "    def output_dataset(self):\n",
        "        self.dst_path = self.DATASET_PATH + \"/test_\"+ self.part + self.preprocess +\"_img\"\n",
        "        return self.dst_path\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.1.0-py3-none-any.whl (72 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.1.0\n",
            "Collecting ranger-adabelief==0.1.0\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger-adabelief==0.1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (3.7.4.3)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-a53c54b4-b9a0-3bae-8c44-0380b135f565)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmiqljhz02F"
      },
      "source": [
        "import glob\n",
        "\n",
        "model_size = \"\"\n",
        "preprocess = \"\"\n",
        "for i in cols[1:]: #modelごとに結果を出す\n",
        "    print(i)\n",
        "    \n",
        "    if \"A2\" in i:\n",
        "        model_size_temp = \"A2\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    elif \"B3\" in i:\n",
        "        model_size_temp = \"B3\"\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    else:\n",
        "        print(\"A2あるいはB3で指定して下さい\")\n",
        "        sys.exit(1)\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/FundusPhoto/model/'+str(i)+\".pth\"))\n",
        "    model_ft.to(device)\n",
        "    \n",
        "    select_dataset = Select_dataset(i)\n",
        "    select_dataset.select_preprocess()\n",
        "    select_dataset.select_part()\n",
        "    data_path = select_dataset.output_dataset()\n",
        "\n",
        "    data_path = glob.glob(data_path+\"/*\")\n",
        "    print(data_path)\n",
        "\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        print(j)\n",
        "        #print(os.path.splitext(os.path.basename(m))[0])\n",
        "        #image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "        image_name = os.path.splitext(os.path.basename(j))[0]\n",
        "        image_tensor = image_transform(j)  #予測のための画像下処理\n",
        "        pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "        write_result(df_temp, image_name, pred, str(i))\n",
        "        #print(str(k)+\"/\"+str(len(df_temp)) + \" images processed! pred: \"+str(pred))\n",
        "        k+=1\n",
        "df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3Jw9LPgEgu"
      },
      "source": [
        "#save CSV file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_5.csv'\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-eMHoKHnIsX",
        "outputId": "ba628cec-e505-441b-8bcb-7424b451694d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "#load csv file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_5.csv'\n",
        "df_temp = pd.read_csv(temp_path, index_col=0, sep=\",\")\n",
        "#df_temp\n",
        "\n",
        "dst_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv'\n",
        "df_dst = pd.read_csv(dst_path, index_col=0, sep=\",\")\n",
        "df_dst"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>第2回日本眼科AI学会総会　眼科AIコンテスト\n",
              "提出フォーム</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>提出締切日：2021年10月29日（金）</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>エントリーNo:</td>\n",
              "      <td>7_600XX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>（XXの入力をお願いいたします。）</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>お名前</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397.0</th>\n",
              "      <td>img99962800_00_1L</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398.0</th>\n",
              "      <td>img99962810_00_1R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399.0</th>\n",
              "      <td>img99962820_00_1R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400.0</th>\n",
              "      <td>img99962830_00_1R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401.0</th>\n",
              "      <td>img99962840_00_1R</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>408 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Unnamed: 1  ...         Unnamed: 4\n",
              "第2回日本眼科AI学会総会　眼科AIコンテスト\\n提出フォーム                     ...                   \n",
              "NaN                                            NaN  ...                NaN\n",
              "NaN                                            NaN  ...                NaN\n",
              "NaN                                            NaN  ...                NaN\n",
              "NaN                                       エントリーNo:  ...  （XXの入力をお願いいたします。）\n",
              "NaN                                            お名前  ...                NaN\n",
              "...                                            ...  ...                ...\n",
              "397.0                            img99962800_00_1L  ...                NaN\n",
              "398.0                            img99962810_00_1R  ...                NaN\n",
              "399.0                            img99962820_00_1R  ...                NaN\n",
              "400.0                            img99962830_00_1R  ...                NaN\n",
              "401.0                            img99962840_00_1R  ...                NaN\n",
              "\n",
              "[408 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Jp4BqEhnKe",
        "outputId": "e7dd5be1-5838-4b98-b9d6-a64b42a561e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from decimal import *\n",
        "\n",
        "#XGBoostのベストモデルを用いて予測をする\n",
        "def get_model_predicts(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "def my_round(x):\n",
        "    y = Decimal(x).quantize(Decimal('0'), rounding=ROUND_HALF_UP) \n",
        "    return int(y)\n",
        "\n",
        "FEATURE_COLS=df_temp.columns.values[1:].tolist()\n",
        "X_test = df_temp[FEATURE_COLS]\n",
        "#Y_test = df_temp[\"age\"]\n",
        "\n",
        "bestmodel = grid.best_estimator_\n",
        "predictive_results = get_model_predicts(X_test, bestmodel)\n",
        "#print(predictive_results)\n",
        "\n",
        "predictive_results = [my_round(float(predictive_results[n])) for n in range(len(predictive_results))] \n",
        "print(predictive_results)\n",
        "\n",
        "df_temp.loc[:, \"age\"] = predictive_results\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[71, 68, 71, 69, 43, 34, 41, 59, 42, 39, 67, 65, 40, 68, 72, 61, 61, 57, 61, 60, 59, 60, 60, 62, 62, 65, 61, 62, 57, 63, 50, 59, 31, 71, 68, 46, 48, 66, 65, 62, 67, 61, 59, 60, 61, 57, 57, 50, 43, 61, 35, 29, 35, 29, 61, 47, 47, 58, 54, 59, 49, 55, 55, 35, 51, 61, 56, 61, 38, 36, 34, 37, 62, 62, 62, 63, 57, 48, 39, 39, 41, 58, 42, 51, 55, 47, 48, 38, 34, 34, 68, 47, 47, 36, 36, 33, 62, 73, 29, 68, 68, 38, 54, 59, 44, 69, 65, 30, 33, 30, 30, 34, 29, 30, 59, 61, 61, 60, 47, 46, 69, 59, 57, 32, 30, 34, 30, 30, 30, 71, 62, 65, 68, 66, 66, 61, 48, 53, 34, 59, 59, 66, 30, 50, 50, 59, 62, 59, 60, 61, 64, 67, 57, 65, 66, 43, 46, 62, 65, 62, 61, 71, 72, 60, 60, 56, 58, 61, 59, 55, 72, 71, 57, 59, 61, 60, 51, 34, 67, 66, 66, 61, 39, 35, 46, 64, 64, 60, 66, 56, 61, 65, 61, 55, 60, 47, 60, 54, 62, 50, 61, 60, 57, 56, 47, 33, 61, 62, 59, 60, 60, 59, 69, 64, 68, 67, 67, 44, 60, 60, 57, 68, 43, 56, 53, 59, 56, 63, 33, 57, 62, 66, 71, 70, 71, 68, 69, 38, 38, 30, 33, 31, 34, 34, 63, 46, 43, 58, 65, 61, 62, 56, 46, 54, 50, 57, 60, 43, 44, 29, 48, 58, 57, 60, 59, 33, 34, 34, 44, 61, 63, 63, 65, 62, 60, 61, 67, 33, 35, 51, 42, 39, 61, 40, 61, 61, 64, 61, 69, 68, 71, 69, 64, 62, 62, 60, 60, 66, 68, 54, 52, 62, 63, 62, 62, 67, 60, 67, 64, 62, 64, 62, 61, 61, 45, 62, 70, 59, 65, 66, 46, 47, 61, 59, 41, 46, 40, 38, 40, 39, 39, 35, 61, 63, 62, 47, 59, 45, 64, 60, 55, 29, 30, 35, 32, 35, 35, 29, 29, 61, 30, 29, 30, 30, 30, 30, 30, 30, 30, 30, 62, 64, 67, 58, 60, 60, 50, 65, 62, 62, 64, 59, 65, 39, 67, 67, 68, 69, 61, 60, 57, 51, 58, 58, 59, 68, 69, 56, 53, 65, 70, 59, 62, 29, 37, 29, 29, 29, 29, 29, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnvIk_wZy-PD"
      },
      "source": [
        "#目的のCSVに記載\n",
        "df_dst.iloc[3,1] = \"7_60004\"\n",
        "df_dst.iloc[4,1] = \"北口善之\"\n",
        "df_dst.iloc[7:408, 1] = predictive_results\n",
        "\n",
        "df_dst.to_csv(os.path.splitext(dst_path)[0]+\"20211021\"+\".csv\", encoding='utf_8_sig')\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gza1KAO60Zqs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}