{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled69.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1JnO8G8KM3eaL7zL7IrR7NU-Q2MllCCtk",
      "authorship_tag": "ABX9TyOBWPQjxUgTjKg9To2oQwTZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/RandomForest_and_XGBoost_1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOmIegf1c6s",
        "outputId": "a0791efb-612e-41ed-f403-f97ac36ae7d8"
      },
      "source": [
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNbbDfQ5lid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "0d2e0c69-54c6-41ee-8606-37d21f65e66b"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/result_5_CLAHE_drop.csv\", index_col=0, sep=\",\")\n",
        "df\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>51.513016</td>\n",
              "      <td>60.443723</td>\n",
              "      <td>59.180284</td>\n",
              "      <td>57.925946</td>\n",
              "      <td>61.356062</td>\n",
              "      <td>50.794721</td>\n",
              "      <td>59.937066</td>\n",
              "      <td>57.612771</td>\n",
              "      <td>61.397052</td>\n",
              "      <td>46.190515</td>\n",
              "      <td>45.208085</td>\n",
              "      <td>57.761061</td>\n",
              "      <td>63.372260</td>\n",
              "      <td>58.118635</td>\n",
              "      <td>59.059167</td>\n",
              "      <td>45.416451</td>\n",
              "      <td>62.391269</td>\n",
              "      <td>46.070179</td>\n",
              "      <td>60.394639</td>\n",
              "      <td>58.396441</td>\n",
              "      <td>63.028634</td>\n",
              "      <td>60.167629</td>\n",
              "      <td>63.968348</td>\n",
              "      <td>55.218077</td>\n",
              "      <td>53.921479</td>\n",
              "      <td>61.277235</td>\n",
              "      <td>61.864400</td>\n",
              "      <td>64.423221</td>\n",
              "      <td>47.498825</td>\n",
              "      <td>39.615372</td>\n",
              "      <td>66.959667</td>\n",
              "      <td>66.500616</td>\n",
              "      <td>62.237757</td>\n",
              "      <td>48.370329</td>\n",
              "      <td>61.953497</td>\n",
              "      <td>54.935169</td>\n",
              "      <td>56.899101</td>\n",
              "      <td>60.968000</td>\n",
              "      <td>32.802081</td>\n",
              "      <td>59.452468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>33.798340</td>\n",
              "      <td>32.601157</td>\n",
              "      <td>31.196275</td>\n",
              "      <td>27.557728</td>\n",
              "      <td>33.944768</td>\n",
              "      <td>30.446360</td>\n",
              "      <td>29.304698</td>\n",
              "      <td>26.477981</td>\n",
              "      <td>29.368344</td>\n",
              "      <td>27.883038</td>\n",
              "      <td>24.574579</td>\n",
              "      <td>28.125578</td>\n",
              "      <td>30.332983</td>\n",
              "      <td>27.869955</td>\n",
              "      <td>30.062532</td>\n",
              "      <td>28.621274</td>\n",
              "      <td>26.432323</td>\n",
              "      <td>25.892881</td>\n",
              "      <td>28.595570</td>\n",
              "      <td>27.253726</td>\n",
              "      <td>27.305934</td>\n",
              "      <td>29.994479</td>\n",
              "      <td>28.159496</td>\n",
              "      <td>25.735974</td>\n",
              "      <td>21.707861</td>\n",
              "      <td>27.959991</td>\n",
              "      <td>28.589666</td>\n",
              "      <td>28.499722</td>\n",
              "      <td>21.598046</td>\n",
              "      <td>26.380828</td>\n",
              "      <td>35.283571</td>\n",
              "      <td>41.595712</td>\n",
              "      <td>40.237117</td>\n",
              "      <td>50.527757</td>\n",
              "      <td>33.700836</td>\n",
              "      <td>30.545381</td>\n",
              "      <td>32.332805</td>\n",
              "      <td>29.989961</td>\n",
              "      <td>32.775521</td>\n",
              "      <td>33.086747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>59.604460</td>\n",
              "      <td>67.162800</td>\n",
              "      <td>52.348655</td>\n",
              "      <td>52.609223</td>\n",
              "      <td>58.175653</td>\n",
              "      <td>49.676123</td>\n",
              "      <td>60.613930</td>\n",
              "      <td>48.423052</td>\n",
              "      <td>51.381540</td>\n",
              "      <td>53.468233</td>\n",
              "      <td>63.071638</td>\n",
              "      <td>48.292780</td>\n",
              "      <td>52.528238</td>\n",
              "      <td>50.668210</td>\n",
              "      <td>50.591427</td>\n",
              "      <td>58.855903</td>\n",
              "      <td>51.447606</td>\n",
              "      <td>50.004244</td>\n",
              "      <td>49.102244</td>\n",
              "      <td>52.055264</td>\n",
              "      <td>51.907486</td>\n",
              "      <td>50.094593</td>\n",
              "      <td>50.960755</td>\n",
              "      <td>52.623403</td>\n",
              "      <td>58.816636</td>\n",
              "      <td>49.755389</td>\n",
              "      <td>53.065294</td>\n",
              "      <td>58.409935</td>\n",
              "      <td>55.093735</td>\n",
              "      <td>55.827039</td>\n",
              "      <td>53.996080</td>\n",
              "      <td>54.605067</td>\n",
              "      <td>49.949187</td>\n",
              "      <td>61.310375</td>\n",
              "      <td>54.841155</td>\n",
              "      <td>50.700021</td>\n",
              "      <td>48.117417</td>\n",
              "      <td>53.539336</td>\n",
              "      <td>62.086725</td>\n",
              "      <td>50.764579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.447189</td>\n",
              "      <td>34.168077</td>\n",
              "      <td>30.493429</td>\n",
              "      <td>29.301286</td>\n",
              "      <td>33.749220</td>\n",
              "      <td>31.672558</td>\n",
              "      <td>29.825637</td>\n",
              "      <td>29.177326</td>\n",
              "      <td>31.059107</td>\n",
              "      <td>28.019741</td>\n",
              "      <td>29.460776</td>\n",
              "      <td>28.995550</td>\n",
              "      <td>30.806449</td>\n",
              "      <td>31.359655</td>\n",
              "      <td>30.032742</td>\n",
              "      <td>31.992900</td>\n",
              "      <td>26.391345</td>\n",
              "      <td>27.324587</td>\n",
              "      <td>28.775471</td>\n",
              "      <td>32.848647</td>\n",
              "      <td>31.013748</td>\n",
              "      <td>26.702192</td>\n",
              "      <td>24.901672</td>\n",
              "      <td>27.801692</td>\n",
              "      <td>21.340437</td>\n",
              "      <td>28.522485</td>\n",
              "      <td>29.261309</td>\n",
              "      <td>28.128195</td>\n",
              "      <td>25.244799</td>\n",
              "      <td>26.992267</td>\n",
              "      <td>36.704639</td>\n",
              "      <td>38.350153</td>\n",
              "      <td>35.942692</td>\n",
              "      <td>47.493604</td>\n",
              "      <td>35.055676</td>\n",
              "      <td>27.620485</td>\n",
              "      <td>30.764979</td>\n",
              "      <td>30.090940</td>\n",
              "      <td>38.280925</td>\n",
              "      <td>33.655614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>40.375280</td>\n",
              "      <td>33.965418</td>\n",
              "      <td>29.740995</td>\n",
              "      <td>29.303265</td>\n",
              "      <td>34.901044</td>\n",
              "      <td>28.703645</td>\n",
              "      <td>28.300020</td>\n",
              "      <td>27.297571</td>\n",
              "      <td>30.610925</td>\n",
              "      <td>27.929401</td>\n",
              "      <td>31.178254</td>\n",
              "      <td>29.032320</td>\n",
              "      <td>29.705697</td>\n",
              "      <td>27.765700</td>\n",
              "      <td>33.182472</td>\n",
              "      <td>31.730193</td>\n",
              "      <td>27.523825</td>\n",
              "      <td>26.797888</td>\n",
              "      <td>29.070142</td>\n",
              "      <td>31.052959</td>\n",
              "      <td>28.335732</td>\n",
              "      <td>27.585560</td>\n",
              "      <td>29.050910</td>\n",
              "      <td>27.625880</td>\n",
              "      <td>24.823041</td>\n",
              "      <td>30.414790</td>\n",
              "      <td>29.290730</td>\n",
              "      <td>30.451465</td>\n",
              "      <td>22.950853</td>\n",
              "      <td>27.947775</td>\n",
              "      <td>41.916993</td>\n",
              "      <td>34.301230</td>\n",
              "      <td>36.889029</td>\n",
              "      <td>42.366844</td>\n",
              "      <td>34.267986</td>\n",
              "      <td>29.653075</td>\n",
              "      <td>34.019947</td>\n",
              "      <td>31.958094</td>\n",
              "      <td>30.553010</td>\n",
              "      <td>31.945181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>42.409110</td>\n",
              "      <td>40.077686</td>\n",
              "      <td>37.977579</td>\n",
              "      <td>36.893642</td>\n",
              "      <td>42.594829</td>\n",
              "      <td>39.264897</td>\n",
              "      <td>37.870255</td>\n",
              "      <td>35.099649</td>\n",
              "      <td>38.703468</td>\n",
              "      <td>34.652242</td>\n",
              "      <td>31.834236</td>\n",
              "      <td>34.224910</td>\n",
              "      <td>31.262583</td>\n",
              "      <td>33.991134</td>\n",
              "      <td>38.869512</td>\n",
              "      <td>35.793000</td>\n",
              "      <td>35.120636</td>\n",
              "      <td>26.139495</td>\n",
              "      <td>35.731488</td>\n",
              "      <td>29.872346</td>\n",
              "      <td>44.848314</td>\n",
              "      <td>51.827860</td>\n",
              "      <td>44.909871</td>\n",
              "      <td>31.455088</td>\n",
              "      <td>40.449962</td>\n",
              "      <td>38.877404</td>\n",
              "      <td>52.941495</td>\n",
              "      <td>43.271992</td>\n",
              "      <td>35.293564</td>\n",
              "      <td>37.773979</td>\n",
              "      <td>35.583228</td>\n",
              "      <td>44.036415</td>\n",
              "      <td>43.149778</td>\n",
              "      <td>50.892937</td>\n",
              "      <td>35.965312</td>\n",
              "      <td>31.347474</td>\n",
              "      <td>29.877606</td>\n",
              "      <td>39.098856</td>\n",
              "      <td>34.426931</td>\n",
              "      <td>37.632969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>54.108298</td>\n",
              "      <td>49.421489</td>\n",
              "      <td>48.863503</td>\n",
              "      <td>51.081926</td>\n",
              "      <td>55.026782</td>\n",
              "      <td>44.446120</td>\n",
              "      <td>46.082148</td>\n",
              "      <td>45.929974</td>\n",
              "      <td>50.156689</td>\n",
              "      <td>40.987971</td>\n",
              "      <td>45.965067</td>\n",
              "      <td>46.292043</td>\n",
              "      <td>51.588768</td>\n",
              "      <td>49.585876</td>\n",
              "      <td>53.223592</td>\n",
              "      <td>49.383083</td>\n",
              "      <td>52.410209</td>\n",
              "      <td>49.659091</td>\n",
              "      <td>48.516831</td>\n",
              "      <td>47.656766</td>\n",
              "      <td>52.504253</td>\n",
              "      <td>47.339574</td>\n",
              "      <td>49.313083</td>\n",
              "      <td>48.411244</td>\n",
              "      <td>54.349107</td>\n",
              "      <td>48.708078</td>\n",
              "      <td>44.102505</td>\n",
              "      <td>56.852949</td>\n",
              "      <td>48.273543</td>\n",
              "      <td>50.966114</td>\n",
              "      <td>49.529347</td>\n",
              "      <td>57.750505</td>\n",
              "      <td>62.443388</td>\n",
              "      <td>64.850932</td>\n",
              "      <td>52.418566</td>\n",
              "      <td>45.366701</td>\n",
              "      <td>56.356877</td>\n",
              "      <td>51.327443</td>\n",
              "      <td>56.484932</td>\n",
              "      <td>51.421803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>56.916833</td>\n",
              "      <td>47.124928</td>\n",
              "      <td>49.280134</td>\n",
              "      <td>51.028162</td>\n",
              "      <td>54.305077</td>\n",
              "      <td>45.320338</td>\n",
              "      <td>45.486036</td>\n",
              "      <td>45.827433</td>\n",
              "      <td>50.921273</td>\n",
              "      <td>45.166197</td>\n",
              "      <td>45.776716</td>\n",
              "      <td>43.373102</td>\n",
              "      <td>52.698910</td>\n",
              "      <td>50.443983</td>\n",
              "      <td>50.774556</td>\n",
              "      <td>50.571752</td>\n",
              "      <td>50.687742</td>\n",
              "      <td>45.854795</td>\n",
              "      <td>48.858061</td>\n",
              "      <td>47.505662</td>\n",
              "      <td>49.167371</td>\n",
              "      <td>44.990662</td>\n",
              "      <td>43.962091</td>\n",
              "      <td>37.034979</td>\n",
              "      <td>45.219013</td>\n",
              "      <td>47.632921</td>\n",
              "      <td>47.237745</td>\n",
              "      <td>51.599389</td>\n",
              "      <td>49.923894</td>\n",
              "      <td>52.648532</td>\n",
              "      <td>43.682286</td>\n",
              "      <td>51.910472</td>\n",
              "      <td>57.996839</td>\n",
              "      <td>63.871813</td>\n",
              "      <td>53.339827</td>\n",
              "      <td>41.465706</td>\n",
              "      <td>50.168627</td>\n",
              "      <td>47.388595</td>\n",
              "      <td>50.673580</td>\n",
              "      <td>47.501767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>73.446184</td>\n",
              "      <td>73.985189</td>\n",
              "      <td>72.136509</td>\n",
              "      <td>41.176051</td>\n",
              "      <td>74.108410</td>\n",
              "      <td>71.727496</td>\n",
              "      <td>73.163122</td>\n",
              "      <td>71.883512</td>\n",
              "      <td>50.149459</td>\n",
              "      <td>42.128849</td>\n",
              "      <td>62.418151</td>\n",
              "      <td>72.725224</td>\n",
              "      <td>70.131874</td>\n",
              "      <td>40.971538</td>\n",
              "      <td>67.298412</td>\n",
              "      <td>70.631576</td>\n",
              "      <td>70.113695</td>\n",
              "      <td>67.158145</td>\n",
              "      <td>38.507593</td>\n",
              "      <td>71.599281</td>\n",
              "      <td>69.768119</td>\n",
              "      <td>72.111243</td>\n",
              "      <td>71.698058</td>\n",
              "      <td>59.377652</td>\n",
              "      <td>66.876441</td>\n",
              "      <td>71.785337</td>\n",
              "      <td>71.052480</td>\n",
              "      <td>54.430097</td>\n",
              "      <td>75.378466</td>\n",
              "      <td>68.461561</td>\n",
              "      <td>50.635380</td>\n",
              "      <td>58.496195</td>\n",
              "      <td>65.064138</td>\n",
              "      <td>62.762278</td>\n",
              "      <td>63.558018</td>\n",
              "      <td>65.622163</td>\n",
              "      <td>66.379267</td>\n",
              "      <td>69.048905</td>\n",
              "      <td>58.793271</td>\n",
              "      <td>62.333030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>75.359941</td>\n",
              "      <td>75.762445</td>\n",
              "      <td>74.979699</td>\n",
              "      <td>58.212060</td>\n",
              "      <td>77.444780</td>\n",
              "      <td>72.709912</td>\n",
              "      <td>71.166813</td>\n",
              "      <td>73.550236</td>\n",
              "      <td>63.982975</td>\n",
              "      <td>61.108553</td>\n",
              "      <td>67.346680</td>\n",
              "      <td>71.876681</td>\n",
              "      <td>72.344667</td>\n",
              "      <td>52.216482</td>\n",
              "      <td>65.165257</td>\n",
              "      <td>71.095788</td>\n",
              "      <td>72.969925</td>\n",
              "      <td>64.384335</td>\n",
              "      <td>40.342388</td>\n",
              "      <td>66.356200</td>\n",
              "      <td>77.711433</td>\n",
              "      <td>72.259676</td>\n",
              "      <td>68.837053</td>\n",
              "      <td>56.474066</td>\n",
              "      <td>68.393230</td>\n",
              "      <td>70.054871</td>\n",
              "      <td>71.892542</td>\n",
              "      <td>64.663768</td>\n",
              "      <td>76.430416</td>\n",
              "      <td>68.551928</td>\n",
              "      <td>57.218838</td>\n",
              "      <td>69.687325</td>\n",
              "      <td>72.499788</td>\n",
              "      <td>58.394593</td>\n",
              "      <td>71.370292</td>\n",
              "      <td>65.477729</td>\n",
              "      <td>61.437380</td>\n",
              "      <td>67.572218</td>\n",
              "      <td>58.184642</td>\n",
              "      <td>73.169208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_CLAHE_B3_ver2_pretrained_4\n",
              "filename                    ...                                     \n",
              "img00085008_00_1R.jpg   61  ...                            59.452468\n",
              "img00085024_00_1R.jpg   29  ...                            33.086747\n",
              "img00241280_10_1R.jpg   51  ...                            50.764579\n",
              "img00265140_00_1R.jpg   29  ...                            33.655614\n",
              "img00265140_00_2L.jpg   29  ...                            31.945181\n",
              "...                    ...  ...                                  ...\n",
              "img76791392_10_1R.jpg   38  ...                            37.632969\n",
              "img76843122_10_1R.jpg   49  ...                            51.421803\n",
              "img76843122_11_1R.jpg   49  ...                            47.501767\n",
              "img76888512_00_1R.jpg   74  ...                            62.333030\n",
              "img76888512_00_2L.jpg   74  ...                            73.169208\n",
              "\n",
              "[1414 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mqY5TnHxuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa4efef-dcc3-43cd-adca-83c0aba0010f"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df.columns.values[1:].tolist()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cropped_CLAHE_A2_ver2_pretrained_0', 'cropped_CLAHE_A2_ver2_pretrained_1', 'cropped_CLAHE_A2_ver2_pretrained_2', 'cropped_CLAHE_A2_ver2_pretrained_3', 'cropped_CLAHE_A2_ver2_pretrained_4', 'cropped_CLAHE_B3_ver2_pretrained_0', 'cropped_CLAHE_B3_ver2_pretrained_1', 'cropped_CLAHE_B3_ver2_pretrained_2', 'cropped_CLAHE_B3_ver2_pretrained_3', 'cropped_CLAHE_B3_ver2_pretrained_4', 'disc_CLAHE_A2_ver2_pretrained_0', 'disc_CLAHE_A2_ver2_pretrained_1', 'disc_CLAHE_A2_ver2_pretrained_2', 'disc_CLAHE_A2_ver2_pretrained_3', 'disc_CLAHE_A2_ver2_pretrained_4', 'disc_CLAHE_B3_ver2_pretrained_0', 'disc_CLAHE_B3_ver2_pretrained_1', 'disc_CLAHE_B3_ver2_pretrained_2', 'disc_CLAHE_B3_ver2_pretrained_3', 'disc_CLAHE_B3_ver2_pretrained_4', 'macula_CLAHE_A2_ver2_pretrained_0', 'macula_CLAHE_A2_ver2_pretrained_1', 'macula_CLAHE_A2_ver2_pretrained_2', 'macula_CLAHE_A2_ver2_pretrained_3', 'macula_CLAHE_A2_ver2_pretrained_4', 'macula_CLAHE_B3_ver2_pretrained_0', 'macula_CLAHE_B3_ver2_pretrained_1', 'macula_CLAHE_B3_ver2_pretrained_2', 'macula_CLAHE_B3_ver2_pretrained_3', 'macula_CLAHE_B3_ver2_pretrained_4', 'vascular_CLAHE_A2_ver2_pretrained_0', 'vascular_CLAHE_A2_ver2_pretrained_1', 'vascular_CLAHE_A2_ver2_pretrained_2', 'vascular_CLAHE_A2_ver2_pretrained_3', 'vascular_CLAHE_A2_ver2_pretrained_4', 'vascular_CLAHE_B3_ver2_pretrained_0', 'vascular_CLAHE_B3_ver2_pretrained_1', 'vascular_CLAHE_B3_ver2_pretrained_2', 'vascular_CLAHE_B3_ver2_pretrained_3', 'vascular_CLAHE_B3_ver2_pretrained_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzK-7A7RRXiu"
      },
      "source": [
        "#**Prediction accuracy for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZej9BelRsro"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "!pip install bayesian-optimization \n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"age\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"age\"]\n",
        "    print(str(i))\n",
        "    get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    print(\"\")\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpy4m8XyRKtV"
      },
      "source": [
        "#**Analysis using XGBoost**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/12/07/000022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d966OQgNzX9"
      },
      "source": [
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20JJ1H4Nmva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524f2d04-6c28-4db7-90b6-aed559cd1049"
      },
      "source": [
        "# Grid Search用のパラメータ作成。\n",
        "# あまり組み合わせが多いと時間がかかる(time consuming)\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "params = {\n",
        "        'eta': [0.01],             # default = 0.3      \n",
        "        'gamma': [1,2,3],            # default = 0\n",
        "        'max_depth': [7,8,9],      # default = 6\n",
        "        'min_child_weight': [1],   # default = 1\n",
        "        'subsample': [0.8,1.0],        # default = 1\n",
        "        'colsample_bytree': [0.8,1.0], # default = 1\n",
        "        }\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 1)\n",
        "\n",
        "#最適解探索\n",
        "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error', n_jobs=2, cv=kf.split(X_train,Y_train), verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train,Y_train)\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   30.7s\n",
            "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:   46.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ベストスコア:\n",
            "-1.7957638628540082\n",
            "\n",
            "\n",
            "ベストestimator:\n",
            "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=0.8, eta=0.01, gamma=2,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
            "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
            "             seed=None, silent=None, subsample=0.8, verbosity=1)\n",
            "\n",
            "\n",
            "ベストparams:\n",
            "{'colsample_bytree': 0.8, 'eta': 0.01, 'gamma': 2, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8}\n",
            "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
            "0        0.588378      0.249913  ...        0.757495                3\n",
            "1        0.405409      0.004464  ...        0.882666               13\n",
            "2        0.434062      0.004552  ...        0.732765                2\n",
            "3        0.456807      0.005114  ...        0.894005               12\n",
            "4        0.481835      0.009296  ...        0.766625                4\n",
            "5        0.497534      0.015790  ...        0.845334                7\n",
            "6        0.388567      0.006396  ...        0.766341                6\n",
            "7        0.418273      0.020961  ...        0.959683               21\n",
            "8        0.439706      0.004643  ...        0.735346                5\n",
            "9        0.448722      0.006241  ...        0.897926               18\n",
            "10       0.480859      0.015004  ...        0.695061                1\n",
            "11       0.498034      0.020410  ...        0.886414               14\n",
            "12       0.385371      0.003068  ...        0.764851               10\n",
            "13       0.403770      0.006730  ...        0.896329               20\n",
            "14       0.437851      0.010278  ...        0.732461                9\n",
            "15       0.452463      0.006592  ...        0.894843               16\n",
            "16       0.474606      0.005076  ...        0.724442                8\n",
            "17       0.513257      0.024362  ...        0.892787               15\n",
            "18       0.458341      0.004170  ...        1.097099               28\n",
            "19       0.476216      0.006406  ...        1.162171               23\n",
            "20       0.516129      0.011807  ...        1.116120               35\n",
            "21       0.538462      0.009440  ...        1.139982               17\n",
            "22       0.566453      0.008334  ...        1.093198               22\n",
            "23       0.591652      0.001977  ...        1.114157               11\n",
            "24       0.462041      0.006142  ...        1.134216               33\n",
            "25       0.493538      0.011516  ...        1.126861               19\n",
            "26       0.517271      0.009078  ...        1.115049               32\n",
            "27       0.537056      0.008590  ...        1.153435               25\n",
            "28       0.563850      0.007272  ...        1.091629               34\n",
            "29       0.592533      0.016287  ...        1.158118               24\n",
            "30       0.461153      0.008395  ...        1.082999               30\n",
            "31       0.490188      0.015131  ...        1.114691               31\n",
            "32       0.514730      0.006898  ...        1.112805               36\n",
            "33       0.548630      0.005715  ...        1.122564               27\n",
            "34       0.648175      0.055156  ...        1.078667               29\n",
            "35       0.600699      0.019103  ...        1.112086               26\n",
            "\n",
            "[36 rows x 19 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9992863321132477',\n",
              " 'adjusted_r2(test)      :0.9867920261248598',\n",
              " '平均誤差率(test)       :0.016491223324835196',\n",
              " 'MAE(test)              :0.8800020858171551',\n",
              " 'MedianAE(test)         :0.5713386535644531',\n",
              " 'RMSE(test)             :1.6257476892070504',\n",
              " 'RMSE(test) / MAE(test) :1.8474361770374765')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "QeZYNf5nX7-k",
        "outputId": "037679ea-d47f-452c-b642-6369ca999177"
      },
      "source": [
        "#Bayesian Optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# BaysianOptimizationで最適化する関数を定義する\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# BaysianOptimizationで最適化する関数を定義する\n",
        "def xgb_regressor(max_depth, min_child_weight, gamma, subsample, colsample_bytree,reg_alpha, n_estimators, reg_lambda,learning_rate):\n",
        "\n",
        "    params = {'max_depth':int(max_depth),\n",
        "                'min_child_weight':int(min_child_weight),\n",
        "                'gamma':gamma,\n",
        "                'subsample':subsample,\n",
        "                'colsample_bytree':colsample_bytree,\n",
        "                'reg_alpha':reg_alpha,\n",
        "                'n_estimators':int(n_estimators),\n",
        "                'reg_lambda':reg_lambda,\n",
        "                'learning_rate':learning_rate\n",
        "                }\n",
        "    model = xgb.XGBRegressor(**params,\n",
        "                            early_stopping_rounds=50,\n",
        "                            eval_set=[(X_test, Y_test)],\n",
        "                            eval_metric='rmse',\n",
        "                            silent=False,\n",
        "                            n_jobs=-1\n",
        "                            )\n",
        "\n",
        "    Y_pred_cv = cross_val_predict(model,X_train,Y_train,cv=5, n_jobs=-1)\n",
        "    rmse_cv = np.sqrt(mean_squared_error(Y_train, Y_pred_cv))\n",
        "\n",
        "    return -rmse_cv\n",
        "\n",
        "#ベイズ最適化で探索するパラメータ空間を定義する\n",
        "xgb_bo = BayesianOptimization(xgb_regressor,\n",
        "                            {'max_depth':(3,8),\n",
        "                            'min_child_weight':(1,5),\n",
        "                            'gamma':(0,0.5),\n",
        "                            'subsample':(0.6,1),\n",
        "                            'colsample_bytree':(0.6,1),\n",
        "                            'reg_alpha':(1e-5,100),\n",
        "                            'n_estimators':(1000,2000),\n",
        "                            'reg_lambda':(1e-5,1),\n",
        "                            'learning_rate':(0.1,0.3)\n",
        "                            })\n",
        "\n",
        "#ベイズ最適化を実行（scoreが最大となるようにパラメータを探索していく）\n",
        "#init_point：初期に探索する点数\n",
        "#acq:獲得関数。EIは(expected improvement)\n",
        "xgb_bo.maximize(init_points=5, n_iter=200, acq='ei')\n",
        "\n",
        "#最もスコアのよかったパラメータの値を取得する。\n",
        "optimized_params = xgb_bo.max['params']\n",
        "\n",
        "#整数のパラメータは変換\n",
        "optimized_params['max_depth'] = int(optimized_params['max_depth'])\n",
        "optimized_params['min_child_weight'] = int(optimized_params['min_child_weight'])\n",
        "optimized_params['n_estimators'] = int(optimized_params['n_estimators'])\n",
        "\n",
        "#調整したパラメータで精度検証する\n",
        "opt_model = xgb.XGBRegressor()\n",
        "opt_model.set_params(**optimized_params)\n",
        "opt_model.fit(X_train, Y_train)\n",
        "#y_pred_train = opt_model.predict(X_train)\n",
        "#y_pred_test = opt_model.predict(X_test)\n",
        "bestmodel = opt_model\n",
        "print(bestmodel)\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)\n",
        "\n",
        "\"\"\"\n",
        "# 学習モデルの評価（RMSEを計算）\n",
        "print('RMSE(train data):',round(np.sqrt(mean_squared_error(Y_train, Y_pred_train)),3))\n",
        "print('RMSE(test data):',round(np.sqrt(mean_squared_error(Y_test, Y_pred_test)),3))\n",
        "#output\n",
        "#RMSE(train data): 0.426\n",
        "#RMSE(test data): 2.266\n",
        "#CPU times: user 32.1 s, sys: 4.64 s, total: 36.7 s\n",
        "#Wall time: 11min 42s\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: (0.9295073584857534, 0.11347183930603083, 0.2919747590099303, 4.458139234735454, 2.721674137245281, 1996.83982750748, 86.79823475048373, 0.3076434514207537, 0.8047990427611114)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-eba308ba90d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#init_point：初期に探索する点数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#acq:獲得関数。EIは(expected improvement)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mxgb_bo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ei'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#最もスコアのよかったパラメータの値を取得する。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-eba308ba90d8>\u001b[0m in \u001b[0;36mxgb_regressor\u001b[0;34m(max_depth, min_child_weight, gamma, subsample, colsample_bytree, reg_alpha, n_estimators, reg_lambda, learning_rate)\u001b[0m\n\u001b[1;32m     33\u001b[0m                             )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mY_pred_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mrmse_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    753\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    754\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 755\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nASsIwGt10r",
        "outputId": "c7a746e1-4eee-43c5-d8bd-0554ba309434"
      },
      "source": [
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9992863321132477',\n",
              " 'adjusted_r2(test)      :0.9867920261248598',\n",
              " '平均誤差率(test)       :0.016491223324835196',\n",
              " 'MAE(test)              :0.8800020858171551',\n",
              " 'MedianAE(test)         :0.5713386535644531',\n",
              " 'RMSE(test)             :1.6257476892070504',\n",
              " 'RMSE(test) / MAE(test) :1.8474361770374765')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndXsi0Q0qnIc"
      },
      "source": [
        "\"\"\"\n",
        "#Optuna\n",
        "import optuna\n",
        "start = time.time()\n",
        "# ベイズ最適化時の評価指標算出メソッド\n",
        "def bayes_objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 8),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 4),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 0.1, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 0.1, log=True),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0001, 0.1, log=True),\n",
        "    }\n",
        "    # モデルにパラメータ適用\n",
        "    model.set_params(**params)\n",
        "    # cross_val_scoreでクロスバリデーション\n",
        "    scores = cross_val_score(model, X, y, cv=cv,\n",
        "                             scoring=scoring, fit_params=fit_params, n_jobs=-1)\n",
        "    val = scores.mean()\n",
        "    return val\n",
        "\n",
        "# ベイズ最適化を実行\n",
        "study = optuna.create_study(direction='maximize',\n",
        "                            sampler=optuna.samplers.TPESampler(seed=seed))\n",
        "study.optimize(bayes_objective, n_trials=5)\n",
        "\n",
        "# 最適パラメータの表示と保持\n",
        "best_params = study.best_trial.params\n",
        "best_score = study.best_trial.value\n",
        "print(f'最適パラメータ {best_params}\\nスコア {best_score}')\n",
        "print(f'所要時間{time.time() - start}秒')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wq2xWzPPEln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "d20525e6-3268-4d0d-832d-0968d4428d2c"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=bestmodel.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f532da3e8d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AseFYOzD8mV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c0ae338-e8b9-4873-d8e5-5789315c8e3d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = bestmodel.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>importances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_3</td>\n",
              "      <td>0.413264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.175796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_3</td>\n",
              "      <td>0.116003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.079977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.0416702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.0324077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.0286703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.0245729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.0186949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.0169336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.0153686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.0114438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.00800688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.00538635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.00321705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.00134496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.000835197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.000794664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.00058052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_3</td>\n",
              "      <td>0.000503875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.000441103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>cropped_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.000375897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.000278511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.000254685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_0</td>\n",
              "      <td>0.000237072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>disc_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.000236075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>disc_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.00023531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.000235059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_2</td>\n",
              "      <td>0.000221951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.000212859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>cropped_CLAHE_B3_ver2_pretrained_4</td>\n",
              "      <td>0.000212776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.000209702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_2</td>\n",
              "      <td>0.000195729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.000179833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>macula_CLAHE_A2_ver2_pretrained_4</td>\n",
              "      <td>0.000176429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>macula_CLAHE_B3_ver2_pretrained_3</td>\n",
              "      <td>0.000175127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_0</td>\n",
              "      <td>0.000173701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_1</td>\n",
              "      <td>0.000171709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>vascular_CLAHE_B3_ver2_pretrained_1</td>\n",
              "      <td>0.000154494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>vascular_CLAHE_A2_ver2_pretrained_3</td>\n",
              "      <td>0.000150595</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               features  importances\n",
              "0    cropped_CLAHE_B3_ver2_pretrained_3     0.413264\n",
              "1    cropped_CLAHE_A2_ver2_pretrained_0     0.175796\n",
              "2       disc_CLAHE_B3_ver2_pretrained_3     0.116003\n",
              "3    cropped_CLAHE_B3_ver2_pretrained_2     0.079977\n",
              "4       disc_CLAHE_B3_ver2_pretrained_0    0.0416702\n",
              "5    cropped_CLAHE_B3_ver2_pretrained_1    0.0324077\n",
              "6       disc_CLAHE_B3_ver2_pretrained_1    0.0286703\n",
              "7    cropped_CLAHE_B3_ver2_pretrained_0    0.0245729\n",
              "8       disc_CLAHE_A2_ver2_pretrained_4    0.0186949\n",
              "9    cropped_CLAHE_A2_ver2_pretrained_4    0.0169336\n",
              "10    macula_CLAHE_A2_ver2_pretrained_1    0.0153686\n",
              "11   cropped_CLAHE_A2_ver2_pretrained_2    0.0114438\n",
              "12    macula_CLAHE_B3_ver2_pretrained_0   0.00800688\n",
              "13      disc_CLAHE_A2_ver2_pretrained_2   0.00538635\n",
              "14    macula_CLAHE_B3_ver2_pretrained_1   0.00321705\n",
              "15      disc_CLAHE_B3_ver2_pretrained_4   0.00134496\n",
              "16  vascular_CLAHE_B3_ver2_pretrained_2  0.000835197\n",
              "17    macula_CLAHE_A2_ver2_pretrained_2  0.000794664\n",
              "18   cropped_CLAHE_A2_ver2_pretrained_1   0.00058052\n",
              "19  vascular_CLAHE_B3_ver2_pretrained_3  0.000503875\n",
              "20  vascular_CLAHE_B3_ver2_pretrained_4  0.000441103\n",
              "21   cropped_CLAHE_A2_ver2_pretrained_3  0.000375897\n",
              "22      disc_CLAHE_A2_ver2_pretrained_1  0.000278511\n",
              "23      disc_CLAHE_A2_ver2_pretrained_3  0.000254685\n",
              "24  vascular_CLAHE_B3_ver2_pretrained_0  0.000237072\n",
              "25      disc_CLAHE_A2_ver2_pretrained_0  0.000236075\n",
              "26      disc_CLAHE_B3_ver2_pretrained_2   0.00023531\n",
              "27    macula_CLAHE_B3_ver2_pretrained_4  0.000235059\n",
              "28    macula_CLAHE_B3_ver2_pretrained_2  0.000221951\n",
              "29    macula_CLAHE_A2_ver2_pretrained_0  0.000212859\n",
              "30   cropped_CLAHE_B3_ver2_pretrained_4  0.000212776\n",
              "31  vascular_CLAHE_A2_ver2_pretrained_4  0.000209702\n",
              "32  vascular_CLAHE_A2_ver2_pretrained_2  0.000195729\n",
              "33    macula_CLAHE_A2_ver2_pretrained_3  0.000179833\n",
              "34    macula_CLAHE_A2_ver2_pretrained_4  0.000176429\n",
              "35    macula_CLAHE_B3_ver2_pretrained_3  0.000175127\n",
              "36  vascular_CLAHE_A2_ver2_pretrained_0  0.000173701\n",
              "37  vascular_CLAHE_A2_ver2_pretrained_1  0.000171709\n",
              "38  vascular_CLAHE_B3_ver2_pretrained_1  0.000154494\n",
              "39  vascular_CLAHE_A2_ver2_pretrained_3  0.000150595"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIobiMOEPGKc"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='gain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnbP5EF_6pc9"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpEpFczPHkK"
      },
      "source": [
        "xgb.to_graphviz(bestmodel, num_trees=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-Kj_RHRQ-9"
      },
      "source": [
        "#**Analysis using RandomForest**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/11/14/200857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSyqmEyGRfHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602e77c0-476e-4e83-e7b9-b4772210ff91"
      },
      "source": [
        "#Create model\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=10)\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\"\"\"\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "           oob_score=False, random_state=2525, verbose=0, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_result(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9986845416179527',\n",
              " 'adjusted_r2(test)      :0.9716478339245996',\n",
              " '平均誤差率(test)       :0.019483058812510973',\n",
              " 'MAE(test)              :1.0077738515901062',\n",
              " 'MedianAE(test)         :0.6000000000000014',\n",
              " 'RMSE(test)             :2.381925461594808',\n",
              " 'RMSE(test) / MAE(test) :2.3635515625221966')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW6HVmKTUWsB"
      },
      "source": [
        "#Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(X_train,Y_train)\n",
        "\n",
        "\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkW5oubR4MJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rci5gcXQQ9XG"
      },
      "source": [
        "\"\"\"\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('Importances')\n",
        "plt.rcParams['font.size']=10\n",
        "sns.barplot(y='features', x='importances', data=df_s, palette='viridis')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DihmVVSbKI"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3Qw-hrjFi-"
      },
      "source": [
        "#**Analysis using neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwwcmwczMwfE"
      },
      "source": [
        "#正規化する\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#モデル作成\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "model = MLPRegressor(alpha=0.1, hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive', max_iter=500, random_state=42, solver=\"lbfgs\", early_stopping=True) \n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "初期設定：\n",
        "\n",
        "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "       verbose=False, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcqR8-Nj1E9"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlExOBk8fCoE"
      },
      "source": [
        "#**Predict age from test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zC8VftCfIcr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "4286e3a2-7f98-4213-a391-1c38c81380d6"
      },
      "source": [
        "df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>60.885948</td>\n",
              "      <td>60.356665</td>\n",
              "      <td>50.935251</td>\n",
              "      <td>59.631753</td>\n",
              "      <td>58.965695</td>\n",
              "      <td>45.052648</td>\n",
              "      <td>60.332221</td>\n",
              "      <td>61.809397</td>\n",
              "      <td>59.062302</td>\n",
              "      <td>68.153375</td>\n",
              "      <td>51.562381</td>\n",
              "      <td>58.757454</td>\n",
              "      <td>68.297571</td>\n",
              "      <td>59.610933</td>\n",
              "      <td>55.720055</td>\n",
              "      <td>58.482534</td>\n",
              "      <td>59.504211</td>\n",
              "      <td>45.093548</td>\n",
              "      <td>58.708310</td>\n",
              "      <td>57.960665</td>\n",
              "      <td>44.306228</td>\n",
              "      <td>62.429917</td>\n",
              "      <td>47.746590</td>\n",
              "      <td>60.145330</td>\n",
              "      <td>59.885645</td>\n",
              "      <td>63.356745</td>\n",
              "      <td>62.210029</td>\n",
              "      <td>52.995640</td>\n",
              "      <td>60.519272</td>\n",
              "      <td>57.649809</td>\n",
              "      <td>63.051468</td>\n",
              "      <td>61.155617</td>\n",
              "      <td>60.746276</td>\n",
              "      <td>38.692406</td>\n",
              "      <td>57.933575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>29.766262</td>\n",
              "      <td>30.331397</td>\n",
              "      <td>29.118884</td>\n",
              "      <td>31.672752</td>\n",
              "      <td>30.989829</td>\n",
              "      <td>26.809660</td>\n",
              "      <td>32.241669</td>\n",
              "      <td>30.086446</td>\n",
              "      <td>30.817971</td>\n",
              "      <td>32.113385</td>\n",
              "      <td>26.403788</td>\n",
              "      <td>27.999404</td>\n",
              "      <td>31.571031</td>\n",
              "      <td>26.205668</td>\n",
              "      <td>21.942243</td>\n",
              "      <td>28.228927</td>\n",
              "      <td>28.847709</td>\n",
              "      <td>27.994281</td>\n",
              "      <td>28.715485</td>\n",
              "      <td>28.885067</td>\n",
              "      <td>26.357773</td>\n",
              "      <td>28.899875</td>\n",
              "      <td>26.704368</td>\n",
              "      <td>28.894490</td>\n",
              "      <td>28.859845</td>\n",
              "      <td>28.657392</td>\n",
              "      <td>28.822759</td>\n",
              "      <td>22.991714</td>\n",
              "      <td>28.690979</td>\n",
              "      <td>25.721887</td>\n",
              "      <td>34.075314</td>\n",
              "      <td>31.509855</td>\n",
              "      <td>33.798274</td>\n",
              "      <td>38.365373</td>\n",
              "      <td>29.952043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>58.364809</td>\n",
              "      <td>50.553083</td>\n",
              "      <td>63.250524</td>\n",
              "      <td>54.238850</td>\n",
              "      <td>50.851762</td>\n",
              "      <td>63.289428</td>\n",
              "      <td>54.653805</td>\n",
              "      <td>49.245375</td>\n",
              "      <td>50.571257</td>\n",
              "      <td>57.794720</td>\n",
              "      <td>49.765614</td>\n",
              "      <td>49.845201</td>\n",
              "      <td>54.795003</td>\n",
              "      <td>59.864140</td>\n",
              "      <td>54.611915</td>\n",
              "      <td>57.051009</td>\n",
              "      <td>54.708534</td>\n",
              "      <td>57.299381</td>\n",
              "      <td>49.541694</td>\n",
              "      <td>54.624343</td>\n",
              "      <td>52.290088</td>\n",
              "      <td>56.760901</td>\n",
              "      <td>47.204936</td>\n",
              "      <td>52.778614</td>\n",
              "      <td>52.187645</td>\n",
              "      <td>51.639259</td>\n",
              "      <td>53.236330</td>\n",
              "      <td>44.357553</td>\n",
              "      <td>52.916056</td>\n",
              "      <td>56.503397</td>\n",
              "      <td>47.425610</td>\n",
              "      <td>57.344145</td>\n",
              "      <td>51.043272</td>\n",
              "      <td>55.263293</td>\n",
              "      <td>48.160061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.213056</td>\n",
              "      <td>31.123018</td>\n",
              "      <td>29.923308</td>\n",
              "      <td>31.866950</td>\n",
              "      <td>31.424466</td>\n",
              "      <td>33.026874</td>\n",
              "      <td>27.775347</td>\n",
              "      <td>31.257206</td>\n",
              "      <td>30.184183</td>\n",
              "      <td>31.335768</td>\n",
              "      <td>28.773826</td>\n",
              "      <td>28.549322</td>\n",
              "      <td>29.491693</td>\n",
              "      <td>27.227801</td>\n",
              "      <td>29.133636</td>\n",
              "      <td>28.235692</td>\n",
              "      <td>31.660154</td>\n",
              "      <td>30.401087</td>\n",
              "      <td>29.131159</td>\n",
              "      <td>27.815926</td>\n",
              "      <td>33.806103</td>\n",
              "      <td>34.369171</td>\n",
              "      <td>30.322504</td>\n",
              "      <td>30.721486</td>\n",
              "      <td>30.021170</td>\n",
              "      <td>27.490881</td>\n",
              "      <td>30.023479</td>\n",
              "      <td>23.335579</td>\n",
              "      <td>29.751483</td>\n",
              "      <td>28.661990</td>\n",
              "      <td>33.212128</td>\n",
              "      <td>37.661710</td>\n",
              "      <td>37.906623</td>\n",
              "      <td>35.059234</td>\n",
              "      <td>30.629086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.485062</td>\n",
              "      <td>31.811762</td>\n",
              "      <td>30.549696</td>\n",
              "      <td>32.765386</td>\n",
              "      <td>31.352851</td>\n",
              "      <td>35.573980</td>\n",
              "      <td>32.451853</td>\n",
              "      <td>30.288148</td>\n",
              "      <td>31.099230</td>\n",
              "      <td>30.537629</td>\n",
              "      <td>29.595745</td>\n",
              "      <td>27.726558</td>\n",
              "      <td>31.044161</td>\n",
              "      <td>32.806641</td>\n",
              "      <td>29.797870</td>\n",
              "      <td>29.842737</td>\n",
              "      <td>28.483209</td>\n",
              "      <td>29.473320</td>\n",
              "      <td>28.350401</td>\n",
              "      <td>31.485087</td>\n",
              "      <td>32.985473</td>\n",
              "      <td>37.007666</td>\n",
              "      <td>28.809839</td>\n",
              "      <td>28.963286</td>\n",
              "      <td>29.689914</td>\n",
              "      <td>26.915285</td>\n",
              "      <td>28.129721</td>\n",
              "      <td>24.725600</td>\n",
              "      <td>28.009915</td>\n",
              "      <td>28.578359</td>\n",
              "      <td>31.528470</td>\n",
              "      <td>32.324287</td>\n",
              "      <td>38.401335</td>\n",
              "      <td>32.143921</td>\n",
              "      <td>30.726725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>38.199157</td>\n",
              "      <td>39.335907</td>\n",
              "      <td>38.415360</td>\n",
              "      <td>40.701389</td>\n",
              "      <td>37.806478</td>\n",
              "      <td>37.474301</td>\n",
              "      <td>32.679823</td>\n",
              "      <td>31.805116</td>\n",
              "      <td>37.843254</td>\n",
              "      <td>33.726096</td>\n",
              "      <td>36.371392</td>\n",
              "      <td>49.667397</td>\n",
              "      <td>39.193630</td>\n",
              "      <td>38.588050</td>\n",
              "      <td>34.526837</td>\n",
              "      <td>38.396522</td>\n",
              "      <td>35.274139</td>\n",
              "      <td>38.497335</td>\n",
              "      <td>38.434505</td>\n",
              "      <td>34.112072</td>\n",
              "      <td>35.426679</td>\n",
              "      <td>35.021561</td>\n",
              "      <td>28.289860</td>\n",
              "      <td>35.640907</td>\n",
              "      <td>36.847824</td>\n",
              "      <td>37.365493</td>\n",
              "      <td>46.835411</td>\n",
              "      <td>31.393817</td>\n",
              "      <td>38.262957</td>\n",
              "      <td>42.541334</td>\n",
              "      <td>36.452386</td>\n",
              "      <td>44.501454</td>\n",
              "      <td>43.832183</td>\n",
              "      <td>44.443870</td>\n",
              "      <td>36.340073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>53.196847</td>\n",
              "      <td>45.640141</td>\n",
              "      <td>45.546347</td>\n",
              "      <td>51.625419</td>\n",
              "      <td>50.128996</td>\n",
              "      <td>48.410195</td>\n",
              "      <td>42.230716</td>\n",
              "      <td>46.253222</td>\n",
              "      <td>51.311338</td>\n",
              "      <td>51.198155</td>\n",
              "      <td>48.310232</td>\n",
              "      <td>45.538834</td>\n",
              "      <td>44.979483</td>\n",
              "      <td>52.453923</td>\n",
              "      <td>44.837600</td>\n",
              "      <td>47.394177</td>\n",
              "      <td>48.088434</td>\n",
              "      <td>49.969494</td>\n",
              "      <td>49.401051</td>\n",
              "      <td>50.176543</td>\n",
              "      <td>47.796735</td>\n",
              "      <td>57.036519</td>\n",
              "      <td>50.078702</td>\n",
              "      <td>50.911272</td>\n",
              "      <td>49.306154</td>\n",
              "      <td>49.032882</td>\n",
              "      <td>48.545510</td>\n",
              "      <td>33.817515</td>\n",
              "      <td>41.229436</td>\n",
              "      <td>50.404090</td>\n",
              "      <td>50.643623</td>\n",
              "      <td>59.744704</td>\n",
              "      <td>54.123229</td>\n",
              "      <td>57.273388</td>\n",
              "      <td>48.106965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>56.886828</td>\n",
              "      <td>50.544816</td>\n",
              "      <td>47.587875</td>\n",
              "      <td>52.457392</td>\n",
              "      <td>50.793570</td>\n",
              "      <td>52.799886</td>\n",
              "      <td>45.932961</td>\n",
              "      <td>44.371003</td>\n",
              "      <td>51.916403</td>\n",
              "      <td>50.504851</td>\n",
              "      <td>44.726014</td>\n",
              "      <td>42.309937</td>\n",
              "      <td>45.024800</td>\n",
              "      <td>40.706378</td>\n",
              "      <td>42.950150</td>\n",
              "      <td>55.220819</td>\n",
              "      <td>48.409539</td>\n",
              "      <td>49.657461</td>\n",
              "      <td>49.004924</td>\n",
              "      <td>47.710246</td>\n",
              "      <td>47.885427</td>\n",
              "      <td>55.062169</td>\n",
              "      <td>52.543592</td>\n",
              "      <td>51.201683</td>\n",
              "      <td>50.496775</td>\n",
              "      <td>49.698067</td>\n",
              "      <td>47.475055</td>\n",
              "      <td>29.821983</td>\n",
              "      <td>40.268657</td>\n",
              "      <td>56.234378</td>\n",
              "      <td>50.509459</td>\n",
              "      <td>53.434712</td>\n",
              "      <td>52.482903</td>\n",
              "      <td>54.819530</td>\n",
              "      <td>47.122028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>56.605852</td>\n",
              "      <td>71.386600</td>\n",
              "      <td>74.264765</td>\n",
              "      <td>73.703772</td>\n",
              "      <td>72.917128</td>\n",
              "      <td>68.061024</td>\n",
              "      <td>74.160743</td>\n",
              "      <td>74.606669</td>\n",
              "      <td>42.933744</td>\n",
              "      <td>78.277564</td>\n",
              "      <td>73.981255</td>\n",
              "      <td>69.788361</td>\n",
              "      <td>79.573733</td>\n",
              "      <td>68.793005</td>\n",
              "      <td>71.677345</td>\n",
              "      <td>70.824075</td>\n",
              "      <td>70.887142</td>\n",
              "      <td>74.848467</td>\n",
              "      <td>73.488754</td>\n",
              "      <td>73.900068</td>\n",
              "      <td>71.458507</td>\n",
              "      <td>79.234850</td>\n",
              "      <td>59.871906</td>\n",
              "      <td>43.737605</td>\n",
              "      <td>69.913667</td>\n",
              "      <td>70.363796</td>\n",
              "      <td>72.958624</td>\n",
              "      <td>59.976119</td>\n",
              "      <td>71.317726</td>\n",
              "      <td>78.840834</td>\n",
              "      <td>68.769974</td>\n",
              "      <td>62.816906</td>\n",
              "      <td>66.310376</td>\n",
              "      <td>50.796282</td>\n",
              "      <td>63.409376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>69.049191</td>\n",
              "      <td>66.318005</td>\n",
              "      <td>73.155653</td>\n",
              "      <td>73.523390</td>\n",
              "      <td>72.985840</td>\n",
              "      <td>66.385049</td>\n",
              "      <td>68.927622</td>\n",
              "      <td>68.367136</td>\n",
              "      <td>53.513491</td>\n",
              "      <td>75.332546</td>\n",
              "      <td>74.130625</td>\n",
              "      <td>71.575391</td>\n",
              "      <td>88.524705</td>\n",
              "      <td>60.911018</td>\n",
              "      <td>71.346241</td>\n",
              "      <td>68.293542</td>\n",
              "      <td>72.224498</td>\n",
              "      <td>74.863398</td>\n",
              "      <td>72.767866</td>\n",
              "      <td>71.941185</td>\n",
              "      <td>73.264325</td>\n",
              "      <td>76.172227</td>\n",
              "      <td>64.452952</td>\n",
              "      <td>60.746992</td>\n",
              "      <td>71.590483</td>\n",
              "      <td>72.297430</td>\n",
              "      <td>71.659863</td>\n",
              "      <td>77.320302</td>\n",
              "      <td>67.448586</td>\n",
              "      <td>84.819227</td>\n",
              "      <td>68.363243</td>\n",
              "      <td>61.668277</td>\n",
              "      <td>61.990064</td>\n",
              "      <td>61.996752</td>\n",
              "      <td>69.304931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_2_RGB_B3_GaussianBlur_pretrained_4\n",
              "filename                    ...                                             \n",
              "img00085008_00_1R.jpg   61  ...                                    57.933575\n",
              "img00085024_00_1R.jpg   29  ...                                    29.952043\n",
              "img00241280_10_1R.jpg   51  ...                                    48.160061\n",
              "img00265140_00_1R.jpg   29  ...                                    30.629086\n",
              "img00265140_00_2L.jpg   29  ...                                    30.726725\n",
              "...                    ...  ...                                          ...\n",
              "img76791392_10_1R.jpg   38  ...                                    36.340073\n",
              "img76843122_10_1R.jpg   49  ...                                    48.106965\n",
              "img76843122_11_1R.jpg   49  ...                                    47.122028\n",
              "img76888512_00_1R.jpg   74  ...                                    63.409376\n",
              "img76888512_00_2L.jpg   74  ...                                    69.304931\n",
              "\n",
              "[1414 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8L_f0Qdq17-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "36bad807-a5ed-4ba1-d758-dc5a3fd166b0"
      },
      "source": [
        "import sys\n",
        "\n",
        "#評価用ファイルの呼び出し\n",
        "df_dst = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv\", index_col=0, sep=\",\")\n",
        "df_dst\n",
        "\n",
        "index = df_dst.iloc[7:408,0] #画像名リスト\n",
        "cols = df.columns #modelリスト\n",
        "\n",
        "df_temp = pd.DataFrame(index=index, columns=cols)\n",
        "df_temp\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>...</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img76901008_06_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_06_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img77009741_01_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962800_00_1L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962810_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962820_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962830_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962840_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 155 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   age  ... vascular_2_RGB_B3_GB_L1Loss_pretrained_4\n",
              "Unnamed: 1              ...                                         \n",
              "img76901008_06_1R  NaN  ...                                      NaN\n",
              "img76901008_06_2L  NaN  ...                                      NaN\n",
              "img76901008_07_1R  NaN  ...                                      NaN\n",
              "img76901008_07_2L  NaN  ...                                      NaN\n",
              "img77009741_01_1R  NaN  ...                                      NaN\n",
              "...                ...  ...                                      ...\n",
              "img99962800_00_1L  NaN  ...                                      NaN\n",
              "img99962810_00_1R  NaN  ...                                      NaN\n",
              "img99962820_00_1R  NaN  ...                                      NaN\n",
              "img99962830_00_1R  NaN  ...                                      NaN\n",
              "img99962840_00_1R  NaN  ...                                      NaN\n",
              "\n",
              "[401 rows x 155 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGbfrHokrOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b34143e-aeb4-489a-dbd1-a34a9a09169e"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "#!pip install adabelief-pytorch==0.1.0\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "\"\"\"\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\"\"\"\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入##########改変要\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df_temp.loc[df_temp.index.str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "class Select_dataset:\n",
        "    \"\"\"\n",
        "    「name = cropped_CLAHE_A2_pretrained_2」\n",
        "    からモデルのダウンロードとdatasetの選択を行う\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.preprocess = \"\"\n",
        "        self.part = \"\"\n",
        "        self.DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "        self.dst_path = \"\"\n",
        "\n",
        "    def select_preprocess(self):\n",
        "        if \"CLAHE\" in self.name:\n",
        "            self.preprocess = \"_CLAHE\"\n",
        "        else:\n",
        "            self.preprocess = \"\"\n",
        "    \n",
        "    def select_part(self):\n",
        "        if \"disc\" in self.name:\n",
        "            self.part = \"disc\"\n",
        "        elif \"macula\" in self.name:\n",
        "            self.part = \"macula\"\n",
        "        else:\n",
        "            self.part = \"cropped\"\n",
        "\n",
        "    def output_dataset(self):\n",
        "        self.dst_path = self.DATASET_PATH + \"/test_\"+ self.part + self.preprocess +\"_img\"\n",
        "        return self.dst_path\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.2.0-py3-none-any.whl (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.2.0\n",
            "Collecting ranger-adabelief==0.1.0\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger-adabelief==0.1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (3.7.4.3)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-bfcb7f3b-6f77-3bbe-7f1e-fd007ab67df9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmiqljhz02F"
      },
      "source": [
        "import glob\n",
        "\n",
        "model_size = \"\"\n",
        "preprocess = \"\"\n",
        "for i in cols[1:]: #modelごとに結果を出す\n",
        "    print(i)\n",
        "    \n",
        "    if \"A2\" in i:\n",
        "        model_size_temp = \"A2\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    elif \"B3\" in i:\n",
        "        model_size_temp = \"B3\"\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    else:\n",
        "        print(\"A2あるいはB3で指定して下さい\")\n",
        "        sys.exit(1)\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/FundusPhoto/model/'+str(i)+\".pth\"))\n",
        "    model_ft.to(device)\n",
        "    \n",
        "    select_dataset = Select_dataset(i)\n",
        "    select_dataset.select_preprocess()\n",
        "    select_dataset.select_part()\n",
        "    data_path = select_dataset.output_dataset()\n",
        "\n",
        "    data_path = glob.glob(data_path+\"/*\")\n",
        "    print(data_path)\n",
        "\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        print(j)\n",
        "        #print(os.path.splitext(os.path.basename(m))[0])\n",
        "        #image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "        image_name = os.path.splitext(os.path.basename(j))[0]\n",
        "        image_tensor = image_transform(j)  #予測のための画像下処理\n",
        "        pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "        write_result(df_temp, image_name, pred, str(i))\n",
        "        #print(str(k)+\"/\"+str(len(df_temp)) + \" images processed! pred: \"+str(pred))\n",
        "        k+=1\n",
        "df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3Jw9LPgEgu"
      },
      "source": [
        "#save CSV file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_5_GB.csv'\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-eMHoKHnIsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedd28b6-9180-48dc-a206-b9293c019a6a"
      },
      "source": [
        "#load csv file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_concat.csv'\n",
        "df_temp = pd.read_csv(temp_path, index_col=0, sep=\",\")\n",
        "print(df_temp)\n",
        "\n",
        "dst_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv'\n",
        "df_dst = pd.read_csv(dst_path, index_col=0, sep=\",\")\n",
        "#df_dst"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   age  ...  vascular_2_RGB_B3_GB_L1Loss_pretrained_4\n",
            "Unnamed: 1              ...                                          \n",
            "img76901008_06_1R   70  ...                                 53.131670\n",
            "img76901008_06_2L   68  ...                                 55.750787\n",
            "img76901008_07_1R   69  ...                                 52.608454\n",
            "img76901008_07_2L   66  ...                                 54.159564\n",
            "img77009741_01_1R   44  ...                                 50.823110\n",
            "...                ...  ...                                       ...\n",
            "img99962800_00_1L   29  ...                                 52.267468\n",
            "img99962810_00_1R   30  ...                                 51.456147\n",
            "img99962820_00_1R   30  ...                                 52.083141\n",
            "img99962830_00_1R   29  ...                                 51.914799\n",
            "img99962840_00_1R   30  ...                                 51.695716\n",
            "\n",
            "[401 rows x 155 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Jp4BqEhnKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76367153-8561-467b-b7c5-8d39a9cb0c60"
      },
      "source": [
        "from decimal import *\n",
        "\n",
        "#XGBoostのベストモデルを用いて予測をする\n",
        "def get_model_predicts(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "def my_round(x):\n",
        "    y = Decimal(x).quantize(Decimal('0'), rounding=ROUND_HALF_UP) \n",
        "    return int(y)\n",
        "\n",
        "FEATURE_COLS=df_temp.columns.values[1:].tolist()\n",
        "X_test = df_temp[FEATURE_COLS]\n",
        "#Y_test = df_temp[\"age\"]\n",
        "\n",
        "predictive_results = get_model_predicts(X_test, bestmodel)\n",
        "#print(predictive_results)\n",
        "\n",
        "predictive_results = [my_round(float(predictive_results[n])) for n in range(len(predictive_results))] \n",
        "print(predictive_results)\n",
        "\n",
        "df_temp.loc[:, \"age\"] = predictive_results\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[70, 70, 71, 69, 44, 34, 42, 57, 41, 39, 67, 63, 40, 67, 70, 61, 58, 59, 59, 59, 60, 61, 60, 62, 61, 63, 60, 62, 57, 61, 49, 59, 32, 70, 69, 47, 48, 65, 63, 60, 65, 61, 59, 59, 61, 58, 58, 50, 44, 60, 34, 30, 35, 31, 62, 49, 49, 59, 55, 60, 48, 54, 57, 34, 51, 60, 56, 61, 38, 36, 36, 37, 61, 61, 62, 62, 55, 46, 38, 41, 42, 59, 44, 51, 53, 48, 48, 37, 32, 33, 68, 45, 47, 35, 36, 33, 62, 72, 29, 66, 67, 35, 52, 59, 43, 69, 63, 31, 33, 31, 32, 33, 29, 30, 60, 60, 60, 60, 49, 45, 70, 61, 59, 30, 31, 34, 32, 30, 33, 71, 61, 64, 67, 63, 65, 61, 47, 55, 31, 58, 58, 65, 31, 50, 48, 59, 61, 61, 61, 63, 65, 67, 56, 65, 66, 44, 46, 60, 62, 60, 61, 71, 72, 60, 60, 58, 58, 61, 60, 53, 71, 72, 58, 60, 60, 60, 50, 33, 65, 66, 66, 61, 38, 36, 45, 62, 63, 59, 68, 57, 60, 63, 61, 57, 60, 49, 61, 54, 62, 50, 61, 60, 57, 57, 47, 31, 61, 61, 59, 60, 59, 60, 69, 64, 66, 66, 67, 42, 60, 60, 57, 67, 44, 56, 54, 59, 57, 61, 33, 58, 61, 65, 71, 71, 71, 71, 70, 38, 38, 31, 31, 34, 32, 31, 62, 46, 42, 59, 63, 61, 62, 57, 47, 56, 51, 57, 59, 42, 43, 29, 44, 60, 58, 60, 59, 30, 35, 34, 42, 60, 62, 62, 65, 61, 60, 62, 68, 31, 35, 51, 42, 40, 61, 38, 62, 60, 63, 60, 70, 68, 70, 68, 63, 61, 61, 58, 60, 63, 68, 57, 53, 61, 61, 61, 61, 67, 61, 66, 62, 64, 62, 60, 61, 61, 46, 62, 69, 59, 64, 66, 44, 46, 61, 60, 42, 43, 38, 39, 38, 38, 38, 35, 61, 62, 61, 47, 58, 44, 62, 60, 59, 29, 31, 35, 35, 35, 35, 29, 30, 61, 30, 30, 31, 30, 31, 30, 31, 32, 31, 32, 62, 63, 64, 58, 60, 60, 48, 62, 61, 61, 62, 59, 61, 41, 67, 67, 67, 68, 61, 61, 58, 51, 58, 60, 61, 68, 68, 55, 51, 65, 70, 60, 61, 29, 37, 29, 30, 29, 30, 29, 31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnvIk_wZy-PD"
      },
      "source": [
        "import os\n",
        "#目的のCSVに記載\n",
        "df_dst.iloc[3,1] = \"7_60004\"\n",
        "df_dst.iloc[4,1] = \"北口善之\"\n",
        "df_dst.iloc[7:408, 1] = predictive_results\n",
        "\n",
        "df_dst.to_csv(os.path.splitext(dst_path)[0]+\"20211028GB_concat\"+\".csv\", encoding='utf_8_sig')\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp69lCxaTN8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}