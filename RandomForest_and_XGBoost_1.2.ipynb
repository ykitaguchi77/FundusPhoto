{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled69.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1JnO8G8KM3eaL7zL7IrR7NU-Q2MllCCtk",
      "authorship_tag": "ABX9TyMa5xnuH1FC2bjQGQPW5/mj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/RandomForest_and_XGBoost_1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOmIegf1c6s",
        "outputId": "7a67650a-8d7e-4e38-abf7-ccc3e0ace453"
      },
      "source": [
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNbbDfQ5lid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "9008bacc-7b45-463e-b139-c39661e4f460"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/result_6.csv\", index_col=0, sep=\",\")\n",
        "df\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_ver3_pretrained_0</th>\n",
              "      <th>cropped_2_A2_ver3_pretrained_1</th>\n",
              "      <th>cropped_2_A2_ver3_pretrained_2</th>\n",
              "      <th>cropped_2_A2_ver3_pretrained_3</th>\n",
              "      <th>cropped_2_A2_ver3_pretrained_4</th>\n",
              "      <th>cropped_2_B3_ver3_pretrained_0</th>\n",
              "      <th>cropped_2_B3_ver3_pretrained_1</th>\n",
              "      <th>cropped_2_B3_ver3_pretrained_2</th>\n",
              "      <th>cropped_2_B3_ver3_pretrained_3</th>\n",
              "      <th>cropped_2_B3_ver3_pretrained_4</th>\n",
              "      <th>disc_2_A2_ver3_pretrained_0</th>\n",
              "      <th>disc_2_A2_ver3_pretrained_1</th>\n",
              "      <th>disc_2_A2_ver3_pretrained_2</th>\n",
              "      <th>disc_2_A2_ver3_pretrained_3</th>\n",
              "      <th>disc_2_A2_ver3_pretrained_4</th>\n",
              "      <th>disc_2_B3_ver3_pretrained_0</th>\n",
              "      <th>disc_2_B3_ver3_pretrained_1</th>\n",
              "      <th>disc_2_B3_ver3_pretrained_2</th>\n",
              "      <th>disc_2_B3_ver3_pretrained_3</th>\n",
              "      <th>disc_2_B3_ver3_pretrained_4</th>\n",
              "      <th>macula_2_A2_ver3_pretrained_0</th>\n",
              "      <th>macula_2_A2_ver3_pretrained_1</th>\n",
              "      <th>macula_2_A2_ver3_pretrained_2</th>\n",
              "      <th>macula_2_A2_ver3_pretrained_3</th>\n",
              "      <th>macula_2_A2_ver3_pretrained_4</th>\n",
              "      <th>macula_2_B3_ver3_pretrained_0</th>\n",
              "      <th>macula_2_B3_ver3_pretrained_1</th>\n",
              "      <th>macula_2_B3_ver3_pretrained_2</th>\n",
              "      <th>macula_2_B3_ver3_pretrained_3</th>\n",
              "      <th>macula_2_B3_ver3_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_A2_ver3_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_A2_ver3_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_A2_ver3_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_A2_ver3_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_A2_ver3_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_ver3_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_ver3_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_ver3_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_ver3_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_ver3_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>55.377793</td>\n",
              "      <td>60.919893</td>\n",
              "      <td>46.377924</td>\n",
              "      <td>56.868428</td>\n",
              "      <td>68.401957</td>\n",
              "      <td>53.370196</td>\n",
              "      <td>61.067003</td>\n",
              "      <td>46.887916</td>\n",
              "      <td>63.977724</td>\n",
              "      <td>55.499285</td>\n",
              "      <td>41.669416</td>\n",
              "      <td>61.481702</td>\n",
              "      <td>57.895392</td>\n",
              "      <td>58.291399</td>\n",
              "      <td>59.488833</td>\n",
              "      <td>45.184523</td>\n",
              "      <td>58.590883</td>\n",
              "      <td>67.199898</td>\n",
              "      <td>61.259288</td>\n",
              "      <td>59.661192</td>\n",
              "      <td>61.228997</td>\n",
              "      <td>60.566139</td>\n",
              "      <td>71.042526</td>\n",
              "      <td>57.155603</td>\n",
              "      <td>56.642127</td>\n",
              "      <td>63.892657</td>\n",
              "      <td>61.410379</td>\n",
              "      <td>61.052155</td>\n",
              "      <td>61.514783</td>\n",
              "      <td>58.423340</td>\n",
              "      <td>65.546918</td>\n",
              "      <td>52.769285</td>\n",
              "      <td>56.162190</td>\n",
              "      <td>48.652282</td>\n",
              "      <td>62.569851</td>\n",
              "      <td>61.833233</td>\n",
              "      <td>63.751435</td>\n",
              "      <td>66.642082</td>\n",
              "      <td>44.885778</td>\n",
              "      <td>58.451027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>31.175834</td>\n",
              "      <td>33.074155</td>\n",
              "      <td>26.423880</td>\n",
              "      <td>29.685512</td>\n",
              "      <td>39.439747</td>\n",
              "      <td>28.150076</td>\n",
              "      <td>29.732630</td>\n",
              "      <td>30.026960</td>\n",
              "      <td>30.672064</td>\n",
              "      <td>28.443289</td>\n",
              "      <td>30.510649</td>\n",
              "      <td>28.073615</td>\n",
              "      <td>30.254704</td>\n",
              "      <td>35.565633</td>\n",
              "      <td>28.416041</td>\n",
              "      <td>28.427771</td>\n",
              "      <td>27.885759</td>\n",
              "      <td>30.364490</td>\n",
              "      <td>28.504840</td>\n",
              "      <td>29.196480</td>\n",
              "      <td>24.503216</td>\n",
              "      <td>22.350059</td>\n",
              "      <td>27.394772</td>\n",
              "      <td>26.632816</td>\n",
              "      <td>26.343137</td>\n",
              "      <td>28.594548</td>\n",
              "      <td>28.460786</td>\n",
              "      <td>27.219105</td>\n",
              "      <td>27.770963</td>\n",
              "      <td>26.733011</td>\n",
              "      <td>41.383716</td>\n",
              "      <td>46.684438</td>\n",
              "      <td>38.854292</td>\n",
              "      <td>48.938054</td>\n",
              "      <td>66.043717</td>\n",
              "      <td>35.348901</td>\n",
              "      <td>44.046059</td>\n",
              "      <td>36.691275</td>\n",
              "      <td>35.232958</td>\n",
              "      <td>42.795855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>52.704924</td>\n",
              "      <td>55.032635</td>\n",
              "      <td>63.135052</td>\n",
              "      <td>53.962374</td>\n",
              "      <td>57.826841</td>\n",
              "      <td>56.829524</td>\n",
              "      <td>60.671735</td>\n",
              "      <td>62.307817</td>\n",
              "      <td>56.984836</td>\n",
              "      <td>53.146797</td>\n",
              "      <td>54.415303</td>\n",
              "      <td>49.307936</td>\n",
              "      <td>55.523223</td>\n",
              "      <td>58.208382</td>\n",
              "      <td>52.654773</td>\n",
              "      <td>55.157554</td>\n",
              "      <td>48.508537</td>\n",
              "      <td>54.571617</td>\n",
              "      <td>53.856242</td>\n",
              "      <td>51.106358</td>\n",
              "      <td>55.107373</td>\n",
              "      <td>49.828374</td>\n",
              "      <td>61.550289</td>\n",
              "      <td>52.448863</td>\n",
              "      <td>55.728042</td>\n",
              "      <td>59.532076</td>\n",
              "      <td>54.704946</td>\n",
              "      <td>53.234494</td>\n",
              "      <td>56.166548</td>\n",
              "      <td>60.350442</td>\n",
              "      <td>63.358819</td>\n",
              "      <td>60.479277</td>\n",
              "      <td>59.012717</td>\n",
              "      <td>62.780356</td>\n",
              "      <td>73.214680</td>\n",
              "      <td>59.200013</td>\n",
              "      <td>55.720735</td>\n",
              "      <td>60.996199</td>\n",
              "      <td>58.883482</td>\n",
              "      <td>55.009782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.181722</td>\n",
              "      <td>33.484635</td>\n",
              "      <td>26.278612</td>\n",
              "      <td>29.998308</td>\n",
              "      <td>39.250773</td>\n",
              "      <td>31.755334</td>\n",
              "      <td>32.222313</td>\n",
              "      <td>30.615148</td>\n",
              "      <td>32.616922</td>\n",
              "      <td>29.880187</td>\n",
              "      <td>33.320615</td>\n",
              "      <td>29.361647</td>\n",
              "      <td>32.680100</td>\n",
              "      <td>33.856291</td>\n",
              "      <td>28.475264</td>\n",
              "      <td>33.127204</td>\n",
              "      <td>29.245320</td>\n",
              "      <td>32.075882</td>\n",
              "      <td>29.445279</td>\n",
              "      <td>29.960233</td>\n",
              "      <td>27.022967</td>\n",
              "      <td>24.399249</td>\n",
              "      <td>26.091862</td>\n",
              "      <td>30.268914</td>\n",
              "      <td>27.455422</td>\n",
              "      <td>28.384092</td>\n",
              "      <td>33.205849</td>\n",
              "      <td>28.285080</td>\n",
              "      <td>27.960712</td>\n",
              "      <td>28.056645</td>\n",
              "      <td>40.909886</td>\n",
              "      <td>42.688680</td>\n",
              "      <td>43.298110</td>\n",
              "      <td>60.197330</td>\n",
              "      <td>57.998359</td>\n",
              "      <td>34.383667</td>\n",
              "      <td>34.948787</td>\n",
              "      <td>39.676252</td>\n",
              "      <td>38.922688</td>\n",
              "      <td>47.229689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.949308</td>\n",
              "      <td>30.636829</td>\n",
              "      <td>29.814917</td>\n",
              "      <td>30.998290</td>\n",
              "      <td>44.250217</td>\n",
              "      <td>31.885111</td>\n",
              "      <td>37.558371</td>\n",
              "      <td>29.637209</td>\n",
              "      <td>30.640844</td>\n",
              "      <td>29.668033</td>\n",
              "      <td>38.157618</td>\n",
              "      <td>30.033493</td>\n",
              "      <td>34.493011</td>\n",
              "      <td>33.941346</td>\n",
              "      <td>30.759692</td>\n",
              "      <td>35.056716</td>\n",
              "      <td>28.951031</td>\n",
              "      <td>30.344492</td>\n",
              "      <td>29.784876</td>\n",
              "      <td>29.494187</td>\n",
              "      <td>28.903010</td>\n",
              "      <td>27.075979</td>\n",
              "      <td>34.006506</td>\n",
              "      <td>27.486074</td>\n",
              "      <td>28.437665</td>\n",
              "      <td>29.204485</td>\n",
              "      <td>30.435911</td>\n",
              "      <td>28.221434</td>\n",
              "      <td>30.276456</td>\n",
              "      <td>29.162553</td>\n",
              "      <td>38.805702</td>\n",
              "      <td>53.903848</td>\n",
              "      <td>46.847543</td>\n",
              "      <td>53.930962</td>\n",
              "      <td>55.528116</td>\n",
              "      <td>32.683885</td>\n",
              "      <td>33.438739</td>\n",
              "      <td>32.201198</td>\n",
              "      <td>30.882773</td>\n",
              "      <td>31.920341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>38.617152</td>\n",
              "      <td>39.938369</td>\n",
              "      <td>34.902564</td>\n",
              "      <td>40.854990</td>\n",
              "      <td>48.509029</td>\n",
              "      <td>36.200154</td>\n",
              "      <td>40.085340</td>\n",
              "      <td>36.576092</td>\n",
              "      <td>41.754621</td>\n",
              "      <td>36.324263</td>\n",
              "      <td>37.504429</td>\n",
              "      <td>36.056393</td>\n",
              "      <td>35.448733</td>\n",
              "      <td>39.626664</td>\n",
              "      <td>37.643766</td>\n",
              "      <td>36.873424</td>\n",
              "      <td>36.733958</td>\n",
              "      <td>31.725448</td>\n",
              "      <td>38.542235</td>\n",
              "      <td>38.927111</td>\n",
              "      <td>48.134094</td>\n",
              "      <td>40.094623</td>\n",
              "      <td>47.380465</td>\n",
              "      <td>37.812737</td>\n",
              "      <td>39.568955</td>\n",
              "      <td>34.415933</td>\n",
              "      <td>46.505505</td>\n",
              "      <td>37.043968</td>\n",
              "      <td>36.672834</td>\n",
              "      <td>38.146043</td>\n",
              "      <td>49.837956</td>\n",
              "      <td>45.483840</td>\n",
              "      <td>43.663633</td>\n",
              "      <td>51.917875</td>\n",
              "      <td>47.215098</td>\n",
              "      <td>39.655149</td>\n",
              "      <td>32.618782</td>\n",
              "      <td>37.931019</td>\n",
              "      <td>33.218914</td>\n",
              "      <td>39.798796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>51.255584</td>\n",
              "      <td>52.453631</td>\n",
              "      <td>45.138389</td>\n",
              "      <td>51.133186</td>\n",
              "      <td>58.763945</td>\n",
              "      <td>53.669500</td>\n",
              "      <td>53.591442</td>\n",
              "      <td>47.794807</td>\n",
              "      <td>42.583719</td>\n",
              "      <td>43.217388</td>\n",
              "      <td>50.610334</td>\n",
              "      <td>46.133351</td>\n",
              "      <td>55.562574</td>\n",
              "      <td>48.367876</td>\n",
              "      <td>49.287948</td>\n",
              "      <td>49.704978</td>\n",
              "      <td>46.847120</td>\n",
              "      <td>49.579686</td>\n",
              "      <td>48.947582</td>\n",
              "      <td>48.406985</td>\n",
              "      <td>51.073343</td>\n",
              "      <td>39.700949</td>\n",
              "      <td>55.298501</td>\n",
              "      <td>48.440430</td>\n",
              "      <td>48.328602</td>\n",
              "      <td>47.892609</td>\n",
              "      <td>43.371052</td>\n",
              "      <td>46.353692</td>\n",
              "      <td>47.382104</td>\n",
              "      <td>50.312561</td>\n",
              "      <td>61.313093</td>\n",
              "      <td>58.439368</td>\n",
              "      <td>58.761537</td>\n",
              "      <td>63.903582</td>\n",
              "      <td>58.817023</td>\n",
              "      <td>54.278123</td>\n",
              "      <td>55.820125</td>\n",
              "      <td>54.502201</td>\n",
              "      <td>57.868826</td>\n",
              "      <td>49.659681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>51.277673</td>\n",
              "      <td>56.211644</td>\n",
              "      <td>51.562268</td>\n",
              "      <td>53.032565</td>\n",
              "      <td>59.777886</td>\n",
              "      <td>51.986933</td>\n",
              "      <td>50.401127</td>\n",
              "      <td>47.400597</td>\n",
              "      <td>45.482603</td>\n",
              "      <td>46.143773</td>\n",
              "      <td>54.515558</td>\n",
              "      <td>46.634084</td>\n",
              "      <td>54.438710</td>\n",
              "      <td>50.460851</td>\n",
              "      <td>48.462719</td>\n",
              "      <td>53.647947</td>\n",
              "      <td>46.889788</td>\n",
              "      <td>48.381466</td>\n",
              "      <td>48.705465</td>\n",
              "      <td>49.291992</td>\n",
              "      <td>47.315624</td>\n",
              "      <td>41.348130</td>\n",
              "      <td>56.138045</td>\n",
              "      <td>42.730415</td>\n",
              "      <td>47.300920</td>\n",
              "      <td>48.119476</td>\n",
              "      <td>39.936969</td>\n",
              "      <td>49.443421</td>\n",
              "      <td>47.605893</td>\n",
              "      <td>48.371243</td>\n",
              "      <td>57.510078</td>\n",
              "      <td>60.615885</td>\n",
              "      <td>56.808972</td>\n",
              "      <td>59.338725</td>\n",
              "      <td>58.416742</td>\n",
              "      <td>54.018742</td>\n",
              "      <td>56.286573</td>\n",
              "      <td>55.308914</td>\n",
              "      <td>56.250960</td>\n",
              "      <td>49.841756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>70.487154</td>\n",
              "      <td>80.713266</td>\n",
              "      <td>72.522926</td>\n",
              "      <td>72.169262</td>\n",
              "      <td>76.703817</td>\n",
              "      <td>65.454996</td>\n",
              "      <td>80.726916</td>\n",
              "      <td>70.996362</td>\n",
              "      <td>80.038249</td>\n",
              "      <td>73.105294</td>\n",
              "      <td>61.633122</td>\n",
              "      <td>71.157026</td>\n",
              "      <td>67.852330</td>\n",
              "      <td>47.953850</td>\n",
              "      <td>69.323808</td>\n",
              "      <td>70.474923</td>\n",
              "      <td>70.004922</td>\n",
              "      <td>76.037008</td>\n",
              "      <td>37.748444</td>\n",
              "      <td>71.632761</td>\n",
              "      <td>85.262549</td>\n",
              "      <td>70.173568</td>\n",
              "      <td>69.093287</td>\n",
              "      <td>67.848450</td>\n",
              "      <td>77.731794</td>\n",
              "      <td>66.426814</td>\n",
              "      <td>64.014667</td>\n",
              "      <td>63.761973</td>\n",
              "      <td>69.494390</td>\n",
              "      <td>70.640433</td>\n",
              "      <td>61.477244</td>\n",
              "      <td>60.366315</td>\n",
              "      <td>67.249823</td>\n",
              "      <td>61.182117</td>\n",
              "      <td>72.550988</td>\n",
              "      <td>63.059264</td>\n",
              "      <td>65.780389</td>\n",
              "      <td>70.460844</td>\n",
              "      <td>46.029803</td>\n",
              "      <td>62.997508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>67.850590</td>\n",
              "      <td>76.848000</td>\n",
              "      <td>71.523428</td>\n",
              "      <td>69.496781</td>\n",
              "      <td>75.466728</td>\n",
              "      <td>70.252585</td>\n",
              "      <td>79.088777</td>\n",
              "      <td>71.612304</td>\n",
              "      <td>79.634643</td>\n",
              "      <td>71.681231</td>\n",
              "      <td>69.651288</td>\n",
              "      <td>68.051302</td>\n",
              "      <td>72.740686</td>\n",
              "      <td>53.502810</td>\n",
              "      <td>68.316090</td>\n",
              "      <td>72.474748</td>\n",
              "      <td>68.754297</td>\n",
              "      <td>71.422029</td>\n",
              "      <td>52.367407</td>\n",
              "      <td>71.497822</td>\n",
              "      <td>77.534980</td>\n",
              "      <td>64.542532</td>\n",
              "      <td>72.293323</td>\n",
              "      <td>71.237528</td>\n",
              "      <td>79.341739</td>\n",
              "      <td>65.835202</td>\n",
              "      <td>62.762266</td>\n",
              "      <td>65.851676</td>\n",
              "      <td>66.506732</td>\n",
              "      <td>74.307323</td>\n",
              "      <td>63.295627</td>\n",
              "      <td>68.904281</td>\n",
              "      <td>67.212421</td>\n",
              "      <td>66.881490</td>\n",
              "      <td>77.996999</td>\n",
              "      <td>64.329475</td>\n",
              "      <td>68.495512</td>\n",
              "      <td>71.327364</td>\n",
              "      <td>44.443822</td>\n",
              "      <td>60.848469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_2_RGB_B3_ver3_pretrained_4\n",
              "filename                    ...                                     \n",
              "img00085008_00_1R.jpg   61  ...                            58.451027\n",
              "img00085024_00_1R.jpg   29  ...                            42.795855\n",
              "img00241280_10_1R.jpg   51  ...                            55.009782\n",
              "img00265140_00_1R.jpg   29  ...                            47.229689\n",
              "img00265140_00_2L.jpg   29  ...                            31.920341\n",
              "...                    ...  ...                                  ...\n",
              "img76791392_10_1R.jpg   38  ...                            39.798796\n",
              "img76843122_10_1R.jpg   49  ...                            49.659681\n",
              "img76843122_11_1R.jpg   49  ...                            49.841756\n",
              "img76888512_00_1R.jpg   74  ...                            62.997508\n",
              "img76888512_00_2L.jpg   74  ...                            60.848469\n",
              "\n",
              "[1414 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mqY5TnHxuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3bea0f-99a5-4032-f347-36649b1040d0"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df.columns.values[1:].tolist()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cropped_2_A2_ver3_pretrained_0', 'cropped_2_A2_ver3_pretrained_1', 'cropped_2_A2_ver3_pretrained_2', 'cropped_2_A2_ver3_pretrained_3', 'cropped_2_A2_ver3_pretrained_4', 'cropped_2_B3_ver3_pretrained_0', 'cropped_2_B3_ver3_pretrained_1', 'cropped_2_B3_ver3_pretrained_2', 'cropped_2_B3_ver3_pretrained_3', 'cropped_2_B3_ver3_pretrained_4', 'disc_2_A2_ver3_pretrained_0', 'disc_2_A2_ver3_pretrained_1', 'disc_2_A2_ver3_pretrained_2', 'disc_2_A2_ver3_pretrained_3', 'disc_2_A2_ver3_pretrained_4', 'disc_2_B3_ver3_pretrained_0', 'disc_2_B3_ver3_pretrained_1', 'disc_2_B3_ver3_pretrained_2', 'disc_2_B3_ver3_pretrained_3', 'disc_2_B3_ver3_pretrained_4', 'macula_2_A2_ver3_pretrained_0', 'macula_2_A2_ver3_pretrained_1', 'macula_2_A2_ver3_pretrained_2', 'macula_2_A2_ver3_pretrained_3', 'macula_2_A2_ver3_pretrained_4', 'macula_2_B3_ver3_pretrained_0', 'macula_2_B3_ver3_pretrained_1', 'macula_2_B3_ver3_pretrained_2', 'macula_2_B3_ver3_pretrained_3', 'macula_2_B3_ver3_pretrained_4', 'vascular_2_RGB_A2_ver3_pretrained_0', 'vascular_2_RGB_A2_ver3_pretrained_1', 'vascular_2_RGB_A2_ver3_pretrained_2', 'vascular_2_RGB_A2_ver3_pretrained_3', 'vascular_2_RGB_A2_ver3_pretrained_4', 'vascular_2_RGB_B3_ver3_pretrained_0', 'vascular_2_RGB_B3_ver3_pretrained_1', 'vascular_2_RGB_B3_ver3_pretrained_2', 'vascular_2_RGB_B3_ver3_pretrained_3', 'vascular_2_RGB_B3_ver3_pretrained_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzK-7A7RRXiu"
      },
      "source": [
        "#**Prediction accuracy for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZej9BelRsro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6e9c92-ffd7-45c0-e3cf-77c3ff2a4847"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"age\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"age\"]\n",
        "    print(str(i))\n",
        "    get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    print(\"\")\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cropped_2_A2_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.8884971132510568\n",
            "adjusted_r2(test)      :0.8914295682189962\n",
            "MAE(test)              :3.8386575501714915\n",
            "MedianAE(test)         :3.1998171806335307\n",
            "RMSE(test)             :5.022689188869269\n",
            "RMSE(test) / MAE(test) :1.308449405351327\n",
            "\n",
            "cropped_2_A2_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.8862738884479985\n",
            "adjusted_r2(test)      :0.8860727790180005\n",
            "MAE(test)              :3.844242495277324\n",
            "MedianAE(test)         :3.1329593658447337\n",
            "RMSE(test)             :5.1451053727929725\n",
            "RMSE(test) / MAE(test) :1.33839251272878\n",
            "\n",
            "cropped_2_A2_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.8854651623817613\n",
            "adjusted_r2(test)      :0.8755892681444557\n",
            "MAE(test)              :3.971929813021063\n",
            "MedianAE(test)         :2.8778975009918213\n",
            "RMSE(test)             :5.376621249862737\n",
            "RMSE(test) / MAE(test) :1.3536546472288393\n",
            "\n",
            "cropped_2_A2_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.8912902850764083\n",
            "adjusted_r2(test)      :0.8866969944672795\n",
            "MAE(test)              :3.757361008295322\n",
            "MedianAE(test)         :2.7827935218811035\n",
            "RMSE(test)             :5.130990811107655\n",
            "RMSE(test) / MAE(test) :1.365583663581886\n",
            "\n",
            "cropped_2_A2_ver3_pretrained_4\n",
            "adjusted_r2(train)     :0.6799004607018222\n",
            "adjusted_r2(test)      :0.6946585974006465\n",
            "MAE(test)              :6.720745438821745\n",
            "MedianAE(test)         :6.008037328720093\n",
            "RMSE(test)             :8.42312740737686\n",
            "RMSE(test) / MAE(test) :1.253302551636827\n",
            "\n",
            "cropped_2_B3_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.8779909649527724\n",
            "adjusted_r2(test)      :0.8924114130285612\n",
            "MAE(test)              :3.6120026113708956\n",
            "MedianAE(test)         :2.7803728580474925\n",
            "RMSE(test)             :4.99992653930206\n",
            "RMSE(test) / MAE(test) :1.3842533013574965\n",
            "\n",
            "cropped_2_B3_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.8180857463771906\n",
            "adjusted_r2(test)      :0.7999978104890172\n",
            "MAE(test)              :5.183927622363761\n",
            "MedianAE(test)         :4.156502485275283\n",
            "RMSE(test)             :6.817072248965331\n",
            "RMSE(test) / MAE(test) :1.3150400132046771\n",
            "\n",
            "cropped_2_B3_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.9336471576067285\n",
            "adjusted_r2(test)      :0.9247615800736374\n",
            "MAE(test)              :2.5889510965178806\n",
            "MedianAE(test)         :1.6146115064620865\n",
            "RMSE(test)             :4.181194350622036\n",
            "RMSE(test) / MAE(test) :1.6150148051254078\n",
            "\n",
            "cropped_2_B3_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.8908507518487478\n",
            "adjusted_r2(test)      :0.868176463023476\n",
            "MAE(test)              :4.125456708058873\n",
            "MedianAE(test)         :3.310821533203125\n",
            "RMSE(test)             :5.534482286177583\n",
            "RMSE(test) / MAE(test) :1.3415441435529427\n",
            "\n",
            "cropped_2_B3_ver3_pretrained_4\n",
            "adjusted_r2(train)     :0.9033194925283731\n",
            "adjusted_r2(test)      :0.8806838313996141\n",
            "MAE(test)              :3.5952536145705634\n",
            "MedianAE(test)         :2.4380738735198975\n",
            "RMSE(test)             :5.265385477872091\n",
            "RMSE(test) / MAE(test) :1.4645379832268155\n",
            "\n",
            "disc_2_A2_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.8869283012668455\n",
            "adjusted_r2(test)      :0.8762725905672286\n",
            "MAE(test)              :3.993754931136492\n",
            "MedianAE(test)         :3.2724506855010844\n",
            "RMSE(test)             :5.361835449256123\n",
            "RMSE(test) / MAE(test) :1.3425549493419517\n",
            "\n",
            "disc_2_A2_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.9336342488072809\n",
            "adjusted_r2(test)      :0.9320094903281513\n",
            "MAE(test)              :2.4064012072954077\n",
            "MedianAE(test)         :1.3627738952636719\n",
            "RMSE(test)             :3.974702885586906\n",
            "RMSE(test) / MAE(test) :1.651720782692815\n",
            "\n",
            "disc_2_A2_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.8592779293546297\n",
            "adjusted_r2(test)      :0.8648167395209031\n",
            "MAE(test)              :4.374436733579467\n",
            "MedianAE(test)         :3.6213700771331787\n",
            "RMSE(test)             :5.604565901659591\n",
            "RMSE(test) / MAE(test) :1.2812085859277127\n",
            "\n",
            "disc_2_A2_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.8474131143518325\n",
            "adjusted_r2(test)      :0.8388322498273735\n",
            "MAE(test)              :4.396529449590947\n",
            "MedianAE(test)         :3.340080499649048\n",
            "RMSE(test)             :6.119551491902346\n",
            "RMSE(test) / MAE(test) :1.3919050382959925\n",
            "\n",
            "disc_2_A2_ver3_pretrained_4\n",
            "adjusted_r2(train)     :0.897979575549366\n",
            "adjusted_r2(test)      :0.8941208949028823\n",
            "MAE(test)              :3.497336310548411\n",
            "MedianAE(test)         :2.598862886428826\n",
            "RMSE(test)             :4.960045411763172\n",
            "RMSE(test) / MAE(test) :1.418235185676323\n",
            "\n",
            "disc_2_B3_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.9518236281329651\n",
            "adjusted_r2(test)      :0.934998104310984\n",
            "MAE(test)              :2.2153632824075515\n",
            "MedianAE(test)         :1.317957878112793\n",
            "RMSE(test)             :3.8863645225670354\n",
            "RMSE(test) / MAE(test) :1.7542786564303436\n",
            "\n",
            "disc_2_B3_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.9072943787007919\n",
            "adjusted_r2(test)      :0.8972633081768228\n",
            "MAE(test)              :3.3750094632377894\n",
            "MedianAE(test)         :2.6322708129882812\n",
            "RMSE(test)             :4.885885782919538\n",
            "RMSE(test) / MAE(test) :1.447665802463351\n",
            "\n",
            "disc_2_B3_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.8673655669801169\n",
            "adjusted_r2(test)      :0.8661631162328207\n",
            "MAE(test)              :4.2637312117398\n",
            "MedianAE(test)         :3.484302520751953\n",
            "RMSE(test)             :5.576586329189766\n",
            "RMSE(test) / MAE(test) :1.3079122609406375\n",
            "\n",
            "disc_2_B3_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.9060377239007532\n",
            "adjusted_r2(test)      :0.8955916966603261\n",
            "MAE(test)              :2.383082124032739\n",
            "MedianAE(test)         :0.9817750453948975\n",
            "RMSE(test)             :4.925474113791199\n",
            "RMSE(test) / MAE(test) :2.0668503464983954\n",
            "\n",
            "disc_2_B3_ver3_pretrained_4\n",
            "adjusted_r2(train)     :0.9374700530689077\n",
            "adjusted_r2(test)      :0.923385410849715\n",
            "MAE(test)              :2.1996076882096136\n",
            "MedianAE(test)         :1.0028891563415456\n",
            "RMSE(test)             :4.219259726507984\n",
            "RMSE(test) / MAE(test) :1.9181873881984293\n",
            "\n",
            "macula_2_A2_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.835760291345014\n",
            "adjusted_r2(test)      :0.845932664034029\n",
            "MAE(test)              :4.4969702015495985\n",
            "MedianAE(test)         :3.469940662384033\n",
            "RMSE(test)             :5.983231522275257\n",
            "RMSE(test) / MAE(test) :1.330502817255385\n",
            "\n",
            "macula_2_A2_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.785509895201361\n",
            "adjusted_r2(test)      :0.7958825911252498\n",
            "MAE(test)              :5.290188346861108\n",
            "MedianAE(test)         :4.062795400619507\n",
            "RMSE(test)             :6.886848749961638\n",
            "RMSE(test) / MAE(test) :1.30181541722383\n",
            "\n",
            "macula_2_A2_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.7603884168585224\n",
            "adjusted_r2(test)      :0.7735823042686438\n",
            "MAE(test)              :5.393056474599737\n",
            "MedianAE(test)         :4.176701307296753\n",
            "RMSE(test)             :7.253301075303129\n",
            "RMSE(test) / MAE(test) :1.3449332691887776\n",
            "\n",
            "macula_2_A2_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.8089830436307226\n",
            "adjusted_r2(test)      :0.798149413126675\n",
            "MAE(test)              :5.013776290964321\n",
            "MedianAE(test)         :3.674271821975694\n",
            "RMSE(test)             :6.84850110155262\n",
            "RMSE(test) / MAE(test) :1.365936711993869\n",
            "\n",
            "macula_2_A2_ver3_pretrained_4\n",
            "adjusted_r2(train)     :0.9081785885747725\n",
            "adjusted_r2(test)      :0.9170955330015681\n",
            "MAE(test)              :3.1222379203398742\n",
            "MedianAE(test)         :2.157883882522576\n",
            "RMSE(test)             :4.389039480913865\n",
            "RMSE(test) / MAE(test) :1.4057351146501005\n",
            "\n",
            "macula_2_B3_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.8387086427838517\n",
            "adjusted_r2(test)      :0.8534319313726078\n",
            "MAE(test)              :4.275929383170057\n",
            "MedianAE(test)         :3.216460943222046\n",
            "RMSE(test)             :5.8357973741154865\n",
            "RMSE(test) / MAE(test) :1.3648020935717573\n",
            "\n",
            "macula_2_B3_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.7873253807512643\n",
            "adjusted_r2(test)      :0.7941090879543639\n",
            "MAE(test)              :5.10664192147474\n",
            "MedianAE(test)         :3.6043708324432444\n",
            "RMSE(test)             :6.9167027255674585\n",
            "RMSE(test) / MAE(test) :1.3544522666609828\n",
            "\n",
            "macula_2_B3_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.8255431665458914\n",
            "adjusted_r2(test)      :0.8237480131042019\n",
            "MAE(test)              :4.067164235317244\n",
            "MedianAE(test)         :1.9793753623962402\n",
            "RMSE(test)             :6.3995219422558485\n",
            "RMSE(test) / MAE(test) :1.573460419101241\n",
            "\n",
            "macula_2_B3_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.8795334262547846\n",
            "adjusted_r2(test)      :0.8665799519191526\n",
            "MAE(test)              :3.706924320530976\n",
            "MedianAE(test)         :2.1510586738586426\n",
            "RMSE(test)             :5.56789540303742\n",
            "RMSE(test) / MAE(test) :1.502025647569703\n",
            "\n",
            "macula_2_B3_ver3_pretrained_4\n",
            "adjusted_r2(train)     :0.8985062601790543\n",
            "adjusted_r2(test)      :0.909334055320276\n",
            "MAE(test)              :3.1928280966863194\n",
            "MedianAE(test)         :2.054799437522888\n",
            "RMSE(test)             :4.589893590505801\n",
            "RMSE(test) / MAE(test) :1.4375636431129593\n",
            "\n",
            "vascular_2_RGB_A2_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.4988670337580624\n",
            "adjusted_r2(test)      :0.576199631807417\n",
            "MAE(test)              :7.515218893967753\n",
            "MedianAE(test)         :5.39088249206543\n",
            "RMSE(test)             :9.923415743054427\n",
            "RMSE(test) / MAE(test) :1.3204426754648042\n",
            "\n",
            "vascular_2_RGB_A2_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.45448391550107414\n",
            "adjusted_r2(test)      :0.46756683122744136\n",
            "MAE(test)              :8.442148915449216\n",
            "MedianAE(test)         :6.4158055782318115\n",
            "RMSE(test)             :11.12277297713078\n",
            "RMSE(test) / MAE(test) :1.3175286397490567\n",
            "\n",
            "vascular_2_RGB_A2_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.636306557626027\n",
            "adjusted_r2(test)      :0.721325614364607\n",
            "MAE(test)              :5.988133405628139\n",
            "MedianAE(test)         :4.427292466163642\n",
            "RMSE(test)             :8.046908219110533\n",
            "RMSE(test) / MAE(test) :1.3438091094542732\n",
            "\n",
            "vascular_2_RGB_A2_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.4832094760550947\n",
            "adjusted_r2(test)      :0.5271872019845731\n",
            "MAE(test)              :8.168113097285213\n",
            "MedianAE(test)         :6.520475387573242\n",
            "RMSE(test)             :10.481540902835741\n",
            "RMSE(test) / MAE(test) :1.2832267107466262\n",
            "\n",
            "vascular_2_RGB_A2_ver3_pretrained_4\n",
            "adjusted_r2(train)     :-0.3738924899593512\n",
            "adjusted_r2(test)      :-0.38830813359019367\n",
            "MAE(test)              :14.86813937480374\n",
            "MedianAE(test)         :12.881084680557251\n",
            "RMSE(test)             :17.960708143124567\n",
            "RMSE(test) / MAE(test) :1.207999716061422\n",
            "\n",
            "vascular_2_RGB_B3_ver3_pretrained_0\n",
            "adjusted_r2(train)     :0.7772213626536922\n",
            "adjusted_r2(test)      :0.7997366230093885\n",
            "MAE(test)              :4.869129411323332\n",
            "MedianAE(test)         :3.4084572792053223\n",
            "RMSE(test)             :6.821522082721339\n",
            "RMSE(test) / MAE(test) :1.4009736662282275\n",
            "\n",
            "vascular_2_RGB_B3_ver3_pretrained_1\n",
            "adjusted_r2(train)     :0.7239680972231779\n",
            "adjusted_r2(test)      :0.7630320987192345\n",
            "MAE(test)              :5.4256930422867145\n",
            "MedianAE(test)         :4.1157708168029785\n",
            "RMSE(test)             :7.420365248398224\n",
            "RMSE(test) / MAE(test) :1.3676345474330105\n",
            "\n",
            "vascular_2_RGB_B3_ver3_pretrained_2\n",
            "adjusted_r2(train)     :0.6890591888436046\n",
            "adjusted_r2(test)      :0.7987455700200893\n",
            "MAE(test)              :5.290492447863198\n",
            "MedianAE(test)         :4.292620658874512\n",
            "RMSE(test)             :6.8383802486895355\n",
            "RMSE(test) / MAE(test) :1.2925791532792985\n",
            "\n",
            "vascular_2_RGB_B3_ver3_pretrained_3\n",
            "adjusted_r2(train)     :0.6706545263503452\n",
            "adjusted_r2(test)      :0.748756359157904\n",
            "MAE(test)              :5.919360611127038\n",
            "MedianAE(test)         :4.946001529693589\n",
            "RMSE(test)             :7.6406104983032685\n",
            "RMSE(test) / MAE(test) :1.2907830761215453\n",
            "\n",
            "vascular_2_RGB_B3_ver3_pretrained_4\n",
            "adjusted_r2(train)     :0.7651221922613647\n",
            "adjusted_r2(test)      :0.7584494522187667\n",
            "MAE(test)              :5.776068594767432\n",
            "MedianAE(test)         :4.696081638336182\n",
            "RMSE(test)             :7.4917717106996955\n",
            "RMSE(test) / MAE(test) :1.2970364855927312\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpy4m8XyRKtV"
      },
      "source": [
        "#**Analysis using XGBoost**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/12/07/000022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20JJ1H4Nmva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4dcc2a-bb80-497e-ee8c-80808870aceb"
      },
      "source": [
        "# Grid Search用のパラメータ作成。\n",
        "# あまり組み合わせが多いと時間がかかる(time consuming)\n",
        "params = {\n",
        "        'eta': [0.01],             # default = 0.3      \n",
        "        'gamma': [1,2,3],            # default = 0\n",
        "        'max_depth': [7,8,9],      # default = 6\n",
        "        'min_child_weight': [1],   # default = 1\n",
        "        'subsample': [0.8,1.0],        # default = 1\n",
        "        'colsample_bytree': [0.8,1.0], # default = 1\n",
        "        }\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 1)\n",
        "\n",
        "#最適解探索\n",
        "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error', n_jobs=2, cv=kf.split(X_train,Y_train), verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train,Y_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   29.6s\n",
            "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:   44.7s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7f9fec503a50>,\n",
              "             error_score=nan,\n",
              "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                    colsample_bylevel=1, colsample_bynode=1,\n",
              "                                    colsample_bytree=1, gamma=0,\n",
              "                                    importance_type='gain', learning_rate=0.1,\n",
              "                                    max_delta_step=0, max_depth=3,\n",
              "                                    min_child_weight=1, missing=None,\n",
              "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
              "                                    object...\n",
              "                                    random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                                    scale_pos_weight=1, seed=None, silent=None,\n",
              "                                    subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=2,\n",
              "             param_grid={'colsample_bytree': [0.8, 1.0], 'eta': [0.01],\n",
              "                         'gamma': [1, 2, 3], 'max_depth': [7, 8, 9],\n",
              "                         'min_child_weight': [1], 'subsample': [0.8, 1.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXBzlSIrNu3u"
      },
      "source": [
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d966OQgNzX9",
        "outputId": "f5c007b0-c00a-471c-baa9-fb71b745f61c"
      },
      "source": [
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9994810643351937',\n",
              " 'adjusted_r2(test)      :0.9920531432174644',\n",
              " '平均誤差率(test)       :0.016516836791861753',\n",
              " 'MAE(test)              :0.8882319312213588',\n",
              " 'MedianAE(test)         :0.6019096374511719',\n",
              " 'RMSE(test)             :1.2610512527389852',\n",
              " 'RMSE(test) / MAE(test) :1.4197319510963573')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wq2xWzPPEln"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=bestmodel.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AseFYOzD8mV7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = bestmodel.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIobiMOEPGKc"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='gain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnbP5EF_6pc9"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpEpFczPHkK"
      },
      "source": [
        "xgb.to_graphviz(bestmodel, num_trees=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-Kj_RHRQ-9"
      },
      "source": [
        "#**Analysis using RandomForest**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/11/14/200857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSyqmEyGRfHU"
      },
      "source": [
        "#Create model\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=10)\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\"\"\"\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "           oob_score=False, random_state=2525, verbose=0, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_result(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW6HVmKTUWsB"
      },
      "source": [
        "#Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(X_train,Y_train)\n",
        "\n",
        "\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkW5oubR4MJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rci5gcXQQ9XG"
      },
      "source": [
        "\"\"\"\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('Importances')\n",
        "plt.rcParams['font.size']=10\n",
        "sns.barplot(y='features', x='importances', data=df_s, palette='viridis')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DihmVVSbKI"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3Qw-hrjFi-"
      },
      "source": [
        "#**Analysis using neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwwcmwczMwfE"
      },
      "source": [
        "#正規化する\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#モデル作成\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "model = MLPRegressor(alpha=0.1, hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive', max_iter=500, random_state=42, solver=\"lbfgs\", early_stopping=True) \n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "初期設定：\n",
        "\n",
        "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "       verbose=False, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcqR8-Nj1E9"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlExOBk8fCoE"
      },
      "source": [
        "#**Predict age from test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zC8VftCfIcr"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8L_f0Qdq17-"
      },
      "source": [
        "import sys\n",
        "\n",
        "#評価用ファイルの呼び出し\n",
        "df_dst = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv\", index_col=0, sep=\",\")\n",
        "df_dst\n",
        "\n",
        "index = df_dst.iloc[7:408,0] #画像名リスト\n",
        "cols = df.columns #modelリスト\n",
        "\n",
        "df_temp = pd.DataFrame(index=index, columns=cols)\n",
        "df_temp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGbfrHokrOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a0a7f5-938e-417f-9f96-cbe42d794f42"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "#!pip install adabelief-pytorch==0.1.0\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "\"\"\"\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\"\"\"\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入##########改変要\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df_temp.loc[df_temp.index.str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "class Select_dataset:\n",
        "    \"\"\"\n",
        "    「name = cropped_CLAHE_A2_pretrained_2」\n",
        "    からモデルのダウンロードとdatasetの選択を行う\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.preprocess = \"\"\n",
        "        self.part = \"\"\n",
        "        self.DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "        self.dst_path = \"\"\n",
        "\n",
        "    def select_preprocess(self):\n",
        "        if \"CLAHE\" in self.name:\n",
        "            self.preprocess = \"_CLAHE\"\n",
        "        else:\n",
        "            self.preprocess = \"\"\n",
        "    \n",
        "    def select_part(self):\n",
        "        if \"disc\" in self.name:\n",
        "            self.part = \"disc\"\n",
        "        elif \"macula\" in self.name:\n",
        "            self.part = \"macula\"\n",
        "        else:\n",
        "            self.part = \"cropped\"\n",
        "\n",
        "    def output_dataset(self):\n",
        "        self.dst_path = self.DATASET_PATH + \"/test_\"+ self.part + self.preprocess +\"_img\"\n",
        "        return self.dst_path\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.2.0-py3-none-any.whl (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.2.0\n",
            "Requirement already satisfied: ranger-adabelief==0.1.0 in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger-adabelief==0.1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (3.7.4.3)\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-ad328fca-57fb-5036-8ce5-d94d8bdec28b)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmiqljhz02F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd0b601-1ec9-4464-9d8a-e89d0cf4c369"
      },
      "source": [
        "import glob\n",
        "\n",
        "model_size = \"\"\n",
        "preprocess = \"\"\n",
        "for i in cols[1:]: #modelごとに結果を出す\n",
        "    print(i)\n",
        "    \n",
        "    if \"A2\" in i:\n",
        "        model_size_temp = \"A2\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    elif \"B3\" in i:\n",
        "        model_size_temp = \"B3\"\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    else:\n",
        "        print(\"A2あるいはB3で指定して下さい\")\n",
        "        sys.exit(1)\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/FundusPhoto/model/'+str(i)+\".pth\"))\n",
        "    model_ft.to(device)\n",
        "    \n",
        "    select_dataset = Select_dataset(i)\n",
        "    select_dataset.select_preprocess()\n",
        "    select_dataset.select_part()\n",
        "    data_path = select_dataset.output_dataset()\n",
        "\n",
        "    data_path = glob.glob(data_path+\"/*\")\n",
        "    print(data_path)\n",
        "\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        print(j)\n",
        "        #print(os.path.splitext(os.path.basename(m))[0])\n",
        "        #image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "        image_name = os.path.splitext(os.path.basename(j))[0]\n",
        "        image_tensor = image_transform(j)  #予測のための画像下処理\n",
        "        pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "        write_result(df_temp, image_name, pred, str(i))\n",
        "        #print(str(k)+\"/\"+str(len(df_temp)) + \" images processed! pred: \"+str(pred))\n",
        "        k+=1\n",
        "df_temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img80893271_09_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82194821_00_1L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81825740_09_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82232245_00_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83144095_00_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83144095_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82713235_06_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82646720_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81071222_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83261003_03_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82713235_07_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img80893271_08_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81228613_02_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82646720_01_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81495086_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83261003_03_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81145548_01_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img80809217_04_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81809541_04_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81809541_04_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img80669348_12_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82825603_05_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82718252_09_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81821872_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82493205_02_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83261003_01_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81435492_05_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81056963_05_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82718252_09_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82718252_10_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img82646720_01_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81821872_02_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81821872_02_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83006235_06_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81720358_01_3L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img81495086_00_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img86293134_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83298373_03_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img86502445_01_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85817909_05_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85032087_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85044981_01_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84186781_01_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83298373_03_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84186781_02_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83662626_06_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img86126910_04_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84493674_01_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img86448480_00_1L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84253832_00_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85079152_02_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84253832_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84186781_01_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84124612_05_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83298373_04_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85044981_01_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84317387_04_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img84269798_07_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83822964_01_1L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85310450_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img86126910_04_2L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img83776640_09_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85817909_05_3L.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85931506_00_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85422250_01_1R.png\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/test_cropped_img/img85152889_12_1R.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3Jw9LPgEgu"
      },
      "source": [
        "#save CSV file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result6.csv'\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-eMHoKHnIsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788f7b7b-23c3-4577-8442-40588ab0bd06"
      },
      "source": [
        "#load csv file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_6.csv'\n",
        "df_temp = pd.read_csv(temp_path, index_col=0, sep=\",\")\n",
        "print(df_temp)\n",
        "\n",
        "dst_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv'\n",
        "df_dst = pd.read_csv(dst_path, index_col=0, sep=\",\")\n",
        "#df_dst"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   age  ...  vascular_CLAHE_B3_ver2_pretrained_4\n",
            "Unnamed: 1              ...                                     \n",
            "img76901008_06_1R  NaN  ...                            59.878999\n",
            "img76901008_06_2L  NaN  ...                            48.995674\n",
            "img76901008_07_1R  NaN  ...                            54.314357\n",
            "img76901008_07_2L  NaN  ...                            49.047279\n",
            "img77009741_01_1R  NaN  ...                            41.672936\n",
            "...                ...  ...                                  ...\n",
            "img99962800_00_1L  NaN  ...                            44.824556\n",
            "img99962810_00_1R  NaN  ...                            51.548409\n",
            "img99962820_00_1R  NaN  ...                            43.355364\n",
            "img99962830_00_1R  NaN  ...                            42.282969\n",
            "img99962840_00_1R  NaN  ...                            59.662741\n",
            "\n",
            "[401 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Jp4BqEhnKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045668ad-9958-460d-acc1-ff12de8a9e6f"
      },
      "source": [
        "from decimal import *\n",
        "\n",
        "#XGBoostのベストモデルを用いて予測をする\n",
        "def get_model_predicts(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "def my_round(x):\n",
        "    y = Decimal(x).quantize(Decimal('0'), rounding=ROUND_HALF_UP) \n",
        "    return int(y)\n",
        "\n",
        "FEATURE_COLS=df_temp.columns.values[1:].tolist()\n",
        "X_test = df_temp[FEATURE_COLS]\n",
        "#Y_test = df_temp[\"age\"]\n",
        "\n",
        "bestmodel = grid.best_estimator_\n",
        "predictive_results = get_model_predicts(X_test, bestmodel)\n",
        "#print(predictive_results)\n",
        "\n",
        "predictive_results = [my_round(float(predictive_results[n])) for n in range(len(predictive_results))] \n",
        "print(predictive_results)\n",
        "\n",
        "df_temp.loc[:, \"age\"] = predictive_results\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[70, 68, 69, 66, 44, 35, 38, 57, 42, 40, 63, 64, 38, 67, 70, 61, 59, 54, 59, 58, 60, 60, 59, 63, 62, 63, 60, 63, 55, 63, 45, 59, 30, 71, 68, 46, 48, 58, 64, 61, 65, 59, 59, 58, 60, 58, 54, 48, 45, 58, 36, 31, 36, 33, 59, 46, 48, 56, 54, 58, 46, 52, 55, 35, 51, 59, 56, 60, 39, 35, 34, 31, 61, 62, 62, 62, 55, 46, 38, 39, 38, 54, 43, 47, 53, 45, 47, 37, 32, 33, 68, 44, 45, 36, 36, 31, 62, 73, 31, 67, 69, 36, 54, 58, 42, 68, 61, 31, 32, 31, 33, 33, 31, 31, 59, 60, 60, 58, 46, 40, 68, 60, 59, 30, 32, 32, 32, 30, 33, 68, 61, 60, 63, 63, 65, 60, 49, 51, 31, 56, 56, 68, 30, 51, 44, 59, 61, 60, 60, 61, 59, 66, 57, 67, 65, 45, 46, 60, 63, 60, 60, 72, 72, 58, 59, 56, 58, 59, 60, 50, 70, 71, 55, 60, 61, 60, 49, 31, 64, 62, 63, 60, 38, 34, 45, 62, 63, 58, 68, 56, 59, 62, 59, 57, 59, 43, 60, 52, 60, 49, 60, 61, 56, 55, 48, 33, 61, 62, 58, 57, 59, 59, 68, 63, 67, 68, 66, 40, 57, 60, 55, 66, 44, 55, 53, 58, 58, 61, 34, 55, 61, 65, 70, 69, 71, 67, 69, 37, 40, 32, 32, 30, 33, 30, 62, 46, 42, 58, 64, 61, 62, 56, 46, 54, 49, 57, 59, 43, 45, 29, 46, 57, 57, 59, 58, 30, 30, 32, 43, 59, 62, 64, 64, 60, 60, 61, 65, 32, 35, 47, 41, 39, 60, 40, 61, 60, 61, 60, 69, 67, 70, 68, 63, 61, 61, 58, 59, 63, 68, 54, 51, 61, 63, 60, 61, 66, 60, 68, 63, 61, 64, 61, 61, 60, 45, 64, 70, 58, 62, 64, 44, 49, 61, 58, 40, 43, 39, 38, 38, 38, 38, 32, 59, 62, 61, 46, 59, 41, 61, 59, 55, 30, 30, 36, 31, 36, 31, 31, 30, 61, 32, 30, 31, 33, 30, 31, 32, 34, 33, 33, 65, 64, 62, 56, 60, 60, 48, 63, 62, 61, 62, 58, 59, 42, 66, 67, 66, 68, 62, 61, 58, 51, 57, 60, 59, 67, 68, 54, 51, 63, 71, 59, 61, 29, 36, 29, 29, 30, 30, 29, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnvIk_wZy-PD"
      },
      "source": [
        "import os\n",
        "#目的のCSVに記載\n",
        "df_dst.iloc[3,1] = \"7_60004\"\n",
        "df_dst.iloc[4,1] = \"北口善之\"\n",
        "df_dst.iloc[7:408, 1] = predictive_results\n",
        "\n",
        "df_dst.to_csv(os.path.splitext(dst_path)[0]+\"20211026original\"+\".csv\", encoding='utf_8_sig')\n"
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}