{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled69.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1JnO8G8KM3eaL7zL7IrR7NU-Q2MllCCtk",
      "authorship_tag": "ABX9TyPKIGD8nGzDug5DOyR920hj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/RandomForest_and_XGBoost_1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOmIegf1c6s",
        "outputId": "dff92b5a-8dcc-4e60-9e07-9db17ed3925c"
      },
      "source": [
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNbbDfQ5lid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "ecaf5276-8e8e-496e-ca8c-94667a9295c8"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/result_5_CLAHE.csv\", index_col=0, sep=\",\")\n",
        "df\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>cropped_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>disc_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>macula_CLAHE_B3_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_A2_ver2_pretrained_4</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_0</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_1</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_2</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_3</th>\n",
              "      <th>vascular_CLAHE_B3_ver2_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>51.513016</td>\n",
              "      <td>60.443723</td>\n",
              "      <td>59.180284</td>\n",
              "      <td>57.925946</td>\n",
              "      <td>61.356062</td>\n",
              "      <td>50.794721</td>\n",
              "      <td>59.937066</td>\n",
              "      <td>57.612771</td>\n",
              "      <td>61.397052</td>\n",
              "      <td>46.190515</td>\n",
              "      <td>45.208085</td>\n",
              "      <td>57.761061</td>\n",
              "      <td>63.372260</td>\n",
              "      <td>58.118635</td>\n",
              "      <td>59.059167</td>\n",
              "      <td>45.416451</td>\n",
              "      <td>62.391269</td>\n",
              "      <td>46.070179</td>\n",
              "      <td>60.394639</td>\n",
              "      <td>58.396441</td>\n",
              "      <td>63.028634</td>\n",
              "      <td>60.167629</td>\n",
              "      <td>63.968348</td>\n",
              "      <td>55.218077</td>\n",
              "      <td>53.921479</td>\n",
              "      <td>61.277235</td>\n",
              "      <td>61.864400</td>\n",
              "      <td>64.423221</td>\n",
              "      <td>47.498825</td>\n",
              "      <td>39.615372</td>\n",
              "      <td>66.959667</td>\n",
              "      <td>66.500616</td>\n",
              "      <td>62.237757</td>\n",
              "      <td>48.370329</td>\n",
              "      <td>61.953497</td>\n",
              "      <td>54.935169</td>\n",
              "      <td>56.899101</td>\n",
              "      <td>60.968000</td>\n",
              "      <td>32.802081</td>\n",
              "      <td>59.452468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>33.798340</td>\n",
              "      <td>32.601157</td>\n",
              "      <td>31.196275</td>\n",
              "      <td>27.557728</td>\n",
              "      <td>33.944768</td>\n",
              "      <td>30.446360</td>\n",
              "      <td>29.304698</td>\n",
              "      <td>26.477981</td>\n",
              "      <td>29.368344</td>\n",
              "      <td>27.883038</td>\n",
              "      <td>24.574579</td>\n",
              "      <td>28.125578</td>\n",
              "      <td>30.332983</td>\n",
              "      <td>27.869955</td>\n",
              "      <td>30.062532</td>\n",
              "      <td>28.621274</td>\n",
              "      <td>26.432323</td>\n",
              "      <td>25.892881</td>\n",
              "      <td>28.595570</td>\n",
              "      <td>27.253726</td>\n",
              "      <td>27.305934</td>\n",
              "      <td>29.994479</td>\n",
              "      <td>28.159496</td>\n",
              "      <td>25.735974</td>\n",
              "      <td>21.707861</td>\n",
              "      <td>27.959991</td>\n",
              "      <td>28.589666</td>\n",
              "      <td>28.499722</td>\n",
              "      <td>21.598046</td>\n",
              "      <td>26.380828</td>\n",
              "      <td>35.283571</td>\n",
              "      <td>41.595712</td>\n",
              "      <td>40.237117</td>\n",
              "      <td>50.527757</td>\n",
              "      <td>33.700836</td>\n",
              "      <td>30.545381</td>\n",
              "      <td>32.332805</td>\n",
              "      <td>29.989961</td>\n",
              "      <td>32.775521</td>\n",
              "      <td>33.086747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>59.604460</td>\n",
              "      <td>67.162800</td>\n",
              "      <td>52.348655</td>\n",
              "      <td>52.609223</td>\n",
              "      <td>58.175653</td>\n",
              "      <td>49.676123</td>\n",
              "      <td>60.613930</td>\n",
              "      <td>48.423052</td>\n",
              "      <td>51.381540</td>\n",
              "      <td>53.468233</td>\n",
              "      <td>63.071638</td>\n",
              "      <td>48.292780</td>\n",
              "      <td>52.528238</td>\n",
              "      <td>50.668210</td>\n",
              "      <td>50.591427</td>\n",
              "      <td>58.855903</td>\n",
              "      <td>51.447606</td>\n",
              "      <td>50.004244</td>\n",
              "      <td>49.102244</td>\n",
              "      <td>52.055264</td>\n",
              "      <td>51.907486</td>\n",
              "      <td>50.094593</td>\n",
              "      <td>50.960755</td>\n",
              "      <td>52.623403</td>\n",
              "      <td>58.816636</td>\n",
              "      <td>49.755389</td>\n",
              "      <td>53.065294</td>\n",
              "      <td>58.409935</td>\n",
              "      <td>55.093735</td>\n",
              "      <td>55.827039</td>\n",
              "      <td>53.996080</td>\n",
              "      <td>54.605067</td>\n",
              "      <td>49.949187</td>\n",
              "      <td>61.310375</td>\n",
              "      <td>54.841155</td>\n",
              "      <td>50.700021</td>\n",
              "      <td>48.117417</td>\n",
              "      <td>53.539336</td>\n",
              "      <td>62.086725</td>\n",
              "      <td>50.764579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.447189</td>\n",
              "      <td>34.168077</td>\n",
              "      <td>30.493429</td>\n",
              "      <td>29.301286</td>\n",
              "      <td>33.749220</td>\n",
              "      <td>31.672558</td>\n",
              "      <td>29.825637</td>\n",
              "      <td>29.177326</td>\n",
              "      <td>31.059107</td>\n",
              "      <td>28.019741</td>\n",
              "      <td>29.460776</td>\n",
              "      <td>28.995550</td>\n",
              "      <td>30.806449</td>\n",
              "      <td>31.359655</td>\n",
              "      <td>30.032742</td>\n",
              "      <td>31.992900</td>\n",
              "      <td>26.391345</td>\n",
              "      <td>27.324587</td>\n",
              "      <td>28.775471</td>\n",
              "      <td>32.848647</td>\n",
              "      <td>31.013748</td>\n",
              "      <td>26.702192</td>\n",
              "      <td>24.901672</td>\n",
              "      <td>27.801692</td>\n",
              "      <td>21.340437</td>\n",
              "      <td>28.522485</td>\n",
              "      <td>29.261309</td>\n",
              "      <td>28.128195</td>\n",
              "      <td>25.244799</td>\n",
              "      <td>26.992267</td>\n",
              "      <td>36.704639</td>\n",
              "      <td>38.350153</td>\n",
              "      <td>35.942692</td>\n",
              "      <td>47.493604</td>\n",
              "      <td>35.055676</td>\n",
              "      <td>27.620485</td>\n",
              "      <td>30.764979</td>\n",
              "      <td>30.090940</td>\n",
              "      <td>38.280925</td>\n",
              "      <td>33.655614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>40.375280</td>\n",
              "      <td>33.965418</td>\n",
              "      <td>29.740995</td>\n",
              "      <td>29.303265</td>\n",
              "      <td>34.901044</td>\n",
              "      <td>28.703645</td>\n",
              "      <td>28.300020</td>\n",
              "      <td>27.297571</td>\n",
              "      <td>30.610925</td>\n",
              "      <td>27.929401</td>\n",
              "      <td>31.178254</td>\n",
              "      <td>29.032320</td>\n",
              "      <td>29.705697</td>\n",
              "      <td>27.765700</td>\n",
              "      <td>33.182472</td>\n",
              "      <td>31.730193</td>\n",
              "      <td>27.523825</td>\n",
              "      <td>26.797888</td>\n",
              "      <td>29.070142</td>\n",
              "      <td>31.052959</td>\n",
              "      <td>28.335732</td>\n",
              "      <td>27.585560</td>\n",
              "      <td>29.050910</td>\n",
              "      <td>27.625880</td>\n",
              "      <td>24.823041</td>\n",
              "      <td>30.414790</td>\n",
              "      <td>29.290730</td>\n",
              "      <td>30.451465</td>\n",
              "      <td>22.950853</td>\n",
              "      <td>27.947775</td>\n",
              "      <td>41.916993</td>\n",
              "      <td>34.301230</td>\n",
              "      <td>36.889029</td>\n",
              "      <td>42.366844</td>\n",
              "      <td>34.267986</td>\n",
              "      <td>29.653075</td>\n",
              "      <td>34.019947</td>\n",
              "      <td>31.958094</td>\n",
              "      <td>30.553010</td>\n",
              "      <td>31.945181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>42.409110</td>\n",
              "      <td>40.077686</td>\n",
              "      <td>37.977579</td>\n",
              "      <td>36.893642</td>\n",
              "      <td>42.594829</td>\n",
              "      <td>39.264897</td>\n",
              "      <td>37.870255</td>\n",
              "      <td>35.099649</td>\n",
              "      <td>38.703468</td>\n",
              "      <td>34.652242</td>\n",
              "      <td>31.834236</td>\n",
              "      <td>34.224910</td>\n",
              "      <td>31.262583</td>\n",
              "      <td>33.991134</td>\n",
              "      <td>38.869512</td>\n",
              "      <td>35.793000</td>\n",
              "      <td>35.120636</td>\n",
              "      <td>26.139495</td>\n",
              "      <td>35.731488</td>\n",
              "      <td>29.872346</td>\n",
              "      <td>44.848314</td>\n",
              "      <td>51.827860</td>\n",
              "      <td>44.909871</td>\n",
              "      <td>31.455088</td>\n",
              "      <td>40.449962</td>\n",
              "      <td>38.877404</td>\n",
              "      <td>52.941495</td>\n",
              "      <td>43.271992</td>\n",
              "      <td>35.293564</td>\n",
              "      <td>37.773979</td>\n",
              "      <td>35.583228</td>\n",
              "      <td>44.036415</td>\n",
              "      <td>43.149778</td>\n",
              "      <td>50.892937</td>\n",
              "      <td>35.965312</td>\n",
              "      <td>31.347474</td>\n",
              "      <td>29.877606</td>\n",
              "      <td>39.098856</td>\n",
              "      <td>34.426931</td>\n",
              "      <td>37.632969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>54.108298</td>\n",
              "      <td>49.421489</td>\n",
              "      <td>48.863503</td>\n",
              "      <td>51.081926</td>\n",
              "      <td>55.026782</td>\n",
              "      <td>44.446120</td>\n",
              "      <td>46.082148</td>\n",
              "      <td>45.929974</td>\n",
              "      <td>50.156689</td>\n",
              "      <td>40.987971</td>\n",
              "      <td>45.965067</td>\n",
              "      <td>46.292043</td>\n",
              "      <td>51.588768</td>\n",
              "      <td>49.585876</td>\n",
              "      <td>53.223592</td>\n",
              "      <td>49.383083</td>\n",
              "      <td>52.410209</td>\n",
              "      <td>49.659091</td>\n",
              "      <td>48.516831</td>\n",
              "      <td>47.656766</td>\n",
              "      <td>52.504253</td>\n",
              "      <td>47.339574</td>\n",
              "      <td>49.313083</td>\n",
              "      <td>48.411244</td>\n",
              "      <td>54.349107</td>\n",
              "      <td>48.708078</td>\n",
              "      <td>44.102505</td>\n",
              "      <td>56.852949</td>\n",
              "      <td>48.273543</td>\n",
              "      <td>50.966114</td>\n",
              "      <td>49.529347</td>\n",
              "      <td>57.750505</td>\n",
              "      <td>62.443388</td>\n",
              "      <td>64.850932</td>\n",
              "      <td>52.418566</td>\n",
              "      <td>45.366701</td>\n",
              "      <td>56.356877</td>\n",
              "      <td>51.327443</td>\n",
              "      <td>56.484932</td>\n",
              "      <td>51.421803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>56.916833</td>\n",
              "      <td>47.124928</td>\n",
              "      <td>49.280134</td>\n",
              "      <td>51.028162</td>\n",
              "      <td>54.305077</td>\n",
              "      <td>45.320338</td>\n",
              "      <td>45.486036</td>\n",
              "      <td>45.827433</td>\n",
              "      <td>50.921273</td>\n",
              "      <td>45.166197</td>\n",
              "      <td>45.776716</td>\n",
              "      <td>43.373102</td>\n",
              "      <td>52.698910</td>\n",
              "      <td>50.443983</td>\n",
              "      <td>50.774556</td>\n",
              "      <td>50.571752</td>\n",
              "      <td>50.687742</td>\n",
              "      <td>45.854795</td>\n",
              "      <td>48.858061</td>\n",
              "      <td>47.505662</td>\n",
              "      <td>49.167371</td>\n",
              "      <td>44.990662</td>\n",
              "      <td>43.962091</td>\n",
              "      <td>37.034979</td>\n",
              "      <td>45.219013</td>\n",
              "      <td>47.632921</td>\n",
              "      <td>47.237745</td>\n",
              "      <td>51.599389</td>\n",
              "      <td>49.923894</td>\n",
              "      <td>52.648532</td>\n",
              "      <td>43.682286</td>\n",
              "      <td>51.910472</td>\n",
              "      <td>57.996839</td>\n",
              "      <td>63.871813</td>\n",
              "      <td>53.339827</td>\n",
              "      <td>41.465706</td>\n",
              "      <td>50.168627</td>\n",
              "      <td>47.388595</td>\n",
              "      <td>50.673580</td>\n",
              "      <td>47.501767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>73.446184</td>\n",
              "      <td>73.985189</td>\n",
              "      <td>72.136509</td>\n",
              "      <td>41.176051</td>\n",
              "      <td>74.108410</td>\n",
              "      <td>71.727496</td>\n",
              "      <td>73.163122</td>\n",
              "      <td>71.883512</td>\n",
              "      <td>50.149459</td>\n",
              "      <td>42.128849</td>\n",
              "      <td>62.418151</td>\n",
              "      <td>72.725224</td>\n",
              "      <td>70.131874</td>\n",
              "      <td>40.971538</td>\n",
              "      <td>67.298412</td>\n",
              "      <td>70.631576</td>\n",
              "      <td>70.113695</td>\n",
              "      <td>67.158145</td>\n",
              "      <td>38.507593</td>\n",
              "      <td>71.599281</td>\n",
              "      <td>69.768119</td>\n",
              "      <td>72.111243</td>\n",
              "      <td>71.698058</td>\n",
              "      <td>59.377652</td>\n",
              "      <td>66.876441</td>\n",
              "      <td>71.785337</td>\n",
              "      <td>71.052480</td>\n",
              "      <td>54.430097</td>\n",
              "      <td>75.378466</td>\n",
              "      <td>68.461561</td>\n",
              "      <td>50.635380</td>\n",
              "      <td>58.496195</td>\n",
              "      <td>65.064138</td>\n",
              "      <td>62.762278</td>\n",
              "      <td>63.558018</td>\n",
              "      <td>65.622163</td>\n",
              "      <td>66.379267</td>\n",
              "      <td>69.048905</td>\n",
              "      <td>58.793271</td>\n",
              "      <td>62.333030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>75.359941</td>\n",
              "      <td>75.762445</td>\n",
              "      <td>74.979699</td>\n",
              "      <td>58.212060</td>\n",
              "      <td>77.444780</td>\n",
              "      <td>72.709912</td>\n",
              "      <td>71.166813</td>\n",
              "      <td>73.550236</td>\n",
              "      <td>63.982975</td>\n",
              "      <td>61.108553</td>\n",
              "      <td>67.346680</td>\n",
              "      <td>71.876681</td>\n",
              "      <td>72.344667</td>\n",
              "      <td>52.216482</td>\n",
              "      <td>65.165257</td>\n",
              "      <td>71.095788</td>\n",
              "      <td>72.969925</td>\n",
              "      <td>64.384335</td>\n",
              "      <td>40.342388</td>\n",
              "      <td>66.356200</td>\n",
              "      <td>77.711433</td>\n",
              "      <td>72.259676</td>\n",
              "      <td>68.837053</td>\n",
              "      <td>56.474066</td>\n",
              "      <td>68.393230</td>\n",
              "      <td>70.054871</td>\n",
              "      <td>71.892542</td>\n",
              "      <td>64.663768</td>\n",
              "      <td>76.430416</td>\n",
              "      <td>68.551928</td>\n",
              "      <td>57.218838</td>\n",
              "      <td>69.687325</td>\n",
              "      <td>72.499788</td>\n",
              "      <td>58.394593</td>\n",
              "      <td>71.370292</td>\n",
              "      <td>65.477729</td>\n",
              "      <td>61.437380</td>\n",
              "      <td>67.572218</td>\n",
              "      <td>58.184642</td>\n",
              "      <td>73.169208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_CLAHE_B3_ver2_pretrained_4\n",
              "filename                    ...                                     \n",
              "img00085008_00_1R.jpg   61  ...                            59.452468\n",
              "img00085024_00_1R.jpg   29  ...                            33.086747\n",
              "img00241280_10_1R.jpg   51  ...                            50.764579\n",
              "img00265140_00_1R.jpg   29  ...                            33.655614\n",
              "img00265140_00_2L.jpg   29  ...                            31.945181\n",
              "...                    ...  ...                                  ...\n",
              "img76791392_10_1R.jpg   38  ...                            37.632969\n",
              "img76843122_10_1R.jpg   49  ...                            51.421803\n",
              "img76843122_11_1R.jpg   49  ...                            47.501767\n",
              "img76888512_00_1R.jpg   74  ...                            62.333030\n",
              "img76888512_00_2L.jpg   74  ...                            73.169208\n",
              "\n",
              "[1414 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mqY5TnHxuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaf53b6-d376-4759-cc29-1c8a5582846a"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df.columns.values[1:].tolist()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cropped_CLAHE_A2_ver2_pretrained_0', 'cropped_CLAHE_A2_ver2_pretrained_1', 'cropped_CLAHE_A2_ver2_pretrained_2', 'cropped_CLAHE_A2_ver2_pretrained_3', 'cropped_CLAHE_A2_ver2_pretrained_4', 'cropped_CLAHE_B3_ver2_pretrained_0', 'cropped_CLAHE_B3_ver2_pretrained_1', 'cropped_CLAHE_B3_ver2_pretrained_2', 'cropped_CLAHE_B3_ver2_pretrained_3', 'cropped_CLAHE_B3_ver2_pretrained_4', 'disc_CLAHE_A2_ver2_pretrained_0', 'disc_CLAHE_A2_ver2_pretrained_1', 'disc_CLAHE_A2_ver2_pretrained_2', 'disc_CLAHE_A2_ver2_pretrained_3', 'disc_CLAHE_A2_ver2_pretrained_4', 'disc_CLAHE_B3_ver2_pretrained_0', 'disc_CLAHE_B3_ver2_pretrained_1', 'disc_CLAHE_B3_ver2_pretrained_2', 'disc_CLAHE_B3_ver2_pretrained_3', 'disc_CLAHE_B3_ver2_pretrained_4', 'macula_CLAHE_A2_ver2_pretrained_0', 'macula_CLAHE_A2_ver2_pretrained_1', 'macula_CLAHE_A2_ver2_pretrained_2', 'macula_CLAHE_A2_ver2_pretrained_3', 'macula_CLAHE_A2_ver2_pretrained_4', 'macula_CLAHE_B3_ver2_pretrained_0', 'macula_CLAHE_B3_ver2_pretrained_1', 'macula_CLAHE_B3_ver2_pretrained_2', 'macula_CLAHE_B3_ver2_pretrained_3', 'macula_CLAHE_B3_ver2_pretrained_4', 'vascular_CLAHE_A2_ver2_pretrained_0', 'vascular_CLAHE_A2_ver2_pretrained_1', 'vascular_CLAHE_A2_ver2_pretrained_2', 'vascular_CLAHE_A2_ver2_pretrained_3', 'vascular_CLAHE_A2_ver2_pretrained_4', 'vascular_CLAHE_B3_ver2_pretrained_0', 'vascular_CLAHE_B3_ver2_pretrained_1', 'vascular_CLAHE_B3_ver2_pretrained_2', 'vascular_CLAHE_B3_ver2_pretrained_3', 'vascular_CLAHE_B3_ver2_pretrained_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzK-7A7RRXiu"
      },
      "source": [
        "#**Prediction accuracy for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZej9BelRsro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0df324-d913-468c-dc2d-cb1d9d9a0537"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "!pip install bayesian-optimization \n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"age\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"age\"]\n",
        "    print(str(i))\n",
        "    get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    print(\"\")\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "cropped_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.8682180618573578\n",
            "adjusted_r2(test)      :0.8719281975835622\n",
            "MAE(test)              :4.326070116961131\n",
            "MedianAE(test)         :3.8662657699999983\n",
            "RMSE(test)             :5.455157356546638\n",
            "RMSE(test) / MAE(test) :1.2609960562494626\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.867833395261413\n",
            "adjusted_r2(test)      :0.8759052511960701\n",
            "MAE(test)              :4.177580339823321\n",
            "MedianAE(test)         :3.753598689999997\n",
            "RMSE(test)             :5.3697890365857175\n",
            "RMSE(test) / MAE(test) :1.2853825898684732\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.9310528438724953\n",
            "adjusted_r2(test)      :0.9313001107404242\n",
            "MAE(test)              :2.9422822742402825\n",
            "MedianAE(test)         :2.131381509999997\n",
            "RMSE(test)             :3.995384130042535\n",
            "RMSE(test) / MAE(test) :1.3579200626065595\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.8722931254295883\n",
            "adjusted_r2(test)      :0.8538693973292665\n",
            "MAE(test)              :3.797707654805654\n",
            "MedianAE(test)         :2.3788545099999965\n",
            "RMSE(test)             :5.827081729129868\n",
            "RMSE(test) / MAE(test) :1.5343681659530126\n",
            "\n",
            "cropped_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.9182558545693867\n",
            "adjusted_r2(test)      :0.915562674817055\n",
            "MAE(test)              :3.23047545565371\n",
            "MedianAE(test)         :2.60572243\n",
            "RMSE(test)             :4.429429108448544\n",
            "RMSE(test) / MAE(test) :1.371138449820606\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.9510502216687122\n",
            "adjusted_r2(test)      :0.9422340711842766\n",
            "MAE(test)              :2.1698860134275617\n",
            "MedianAE(test)         :1.4057776900000007\n",
            "RMSE(test)             :3.663670453967568\n",
            "RMSE(test) / MAE(test) :1.6884160878941368\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.9250480295041816\n",
            "adjusted_r2(test)      :0.928908898010816\n",
            "MAE(test)              :2.7483117092579508\n",
            "MedianAE(test)         :1.8112196900000015\n",
            "RMSE(test)             :4.064322344683186\n",
            "RMSE(test) / MAE(test) :1.4788432953191326\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.932726518474439\n",
            "adjusted_r2(test)      :0.9148858847093162\n",
            "MAE(test)              :2.8762985570671376\n",
            "MedianAE(test)         :1.7870788600000012\n",
            "RMSE(test)             :4.447145270705629\n",
            "RMSE(test) / MAE(test) :1.54613479180695\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.9248780181518566\n",
            "adjusted_r2(test)      :0.9003795462854263\n",
            "MAE(test)              :2.5629801530035334\n",
            "MedianAE(test)         :1.4213562000000053\n",
            "RMSE(test)             :4.8112151622633865\n",
            "RMSE(test) / MAE(test) :1.8771956375179755\n",
            "\n",
            "cropped_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.7623876354307848\n",
            "adjusted_r2(test)      :0.7594013900787779\n",
            "MAE(test)              :6.01996874024735\n",
            "MedianAE(test)         :5.126405949999999\n",
            "RMSE(test)             :7.476994800672362\n",
            "RMSE(test) / MAE(test) :1.2420321638356455\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.8971848028515567\n",
            "adjusted_r2(test)      :0.8780162241386347\n",
            "MAE(test)              :3.861221156819788\n",
            "MedianAE(test)         :2.897475959999994\n",
            "RMSE(test)             :5.3239204530897375\n",
            "RMSE(test) / MAE(test) :1.3788177980135876\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.8830722666865641\n",
            "adjusted_r2(test)      :0.8784289176085814\n",
            "MAE(test)              :3.6701021257597173\n",
            "MedianAE(test)         :2.6973524100000006\n",
            "RMSE(test)             :5.314906923716228\n",
            "RMSE(test) / MAE(test) :1.448163223146286\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.908176994976926\n",
            "adjusted_r2(test)      :0.9084739959107655\n",
            "MAE(test)              :3.1200995460424026\n",
            "MedianAE(test)         :2.087833169999996\n",
            "RMSE(test)             :4.6116121288884075\n",
            "RMSE(test) / MAE(test) :1.4780336527204299\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.8776329670156295\n",
            "adjusted_r2(test)      :0.8677679662953532\n",
            "MAE(test)              :3.4497409537809185\n",
            "MedianAE(test)         :2.0488952400000002\n",
            "RMSE(test)             :5.543050821061629\n",
            "RMSE(test) / MAE(test) :1.6068020455235752\n",
            "\n",
            "disc_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.9197925698325021\n",
            "adjusted_r2(test)      :0.9186753390140586\n",
            "MAE(test)              :2.7048680172791517\n",
            "MedianAE(test)         :1.6840598599999979\n",
            "RMSE(test)             :4.347020141902756\n",
            "RMSE(test) / MAE(test) :1.607109890069778\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.9541681493139124\n",
            "adjusted_r2(test)      :0.9426237197403308\n",
            "MAE(test)              :2.2132657907067137\n",
            "MedianAE(test)         :1.4670522199999994\n",
            "RMSE(test)             :3.6512932673790277\n",
            "RMSE(test) / MAE(test) :1.6497310366926785\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.9371156565687794\n",
            "adjusted_r2(test)      :0.9246988169578695\n",
            "MAE(test)              :2.459159973922261\n",
            "MedianAE(test)         :1.467107299999995\n",
            "RMSE(test)             :4.182937941729706\n",
            "RMSE(test) / MAE(test) :1.7009621114880493\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.8307273601347134\n",
            "adjusted_r2(test)      :0.835530573845059\n",
            "MAE(test)              :4.818363239116608\n",
            "MedianAE(test)         :4.022190330000001\n",
            "RMSE(test)             :6.181916152807489\n",
            "RMSE(test) / MAE(test) :1.2829908925548072\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.886113384659065\n",
            "adjusted_r2(test)      :0.8865787038332159\n",
            "MAE(test)              :2.7786681456183744\n",
            "MedianAE(test)         :1.3246402700000033\n",
            "RMSE(test)             :5.13366854158649\n",
            "RMSE(test) / MAE(test) :1.8475284821908902\n",
            "\n",
            "disc_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8864505947124529\n",
            "adjusted_r2(test)      :0.876930091094532\n",
            "MAE(test)              :3.778208590777385\n",
            "MedianAE(test)         :2.8297777200000027\n",
            "RMSE(test)             :5.347569791641249\n",
            "RMSE(test) / MAE(test) :1.4153717729335213\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.8512420567170065\n",
            "adjusted_r2(test)      :0.8527384751912985\n",
            "MAE(test)              :4.095689412720848\n",
            "MedianAE(test)         :2.8649733099999963\n",
            "RMSE(test)             :5.849586511000929\n",
            "RMSE(test) / MAE(test) :1.4282300051445875\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.8841947869432407\n",
            "adjusted_r2(test)      :0.8850501469436327\n",
            "MAE(test)              :3.5705264414487634\n",
            "MedianAE(test)         :2.5845224899999977\n",
            "RMSE(test)             :5.168145499933406\n",
            "RMSE(test) / MAE(test) :1.4474463597128266\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.8449430641793431\n",
            "adjusted_r2(test)      :0.862311140615909\n",
            "MAE(test)              :3.7460399755830385\n",
            "MedianAE(test)         :2.449175359999998\n",
            "RMSE(test)             :5.656267273812603\n",
            "RMSE(test) / MAE(test) :1.5099324381695245\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.7776826923458116\n",
            "adjusted_r2(test)      :0.7670724921848632\n",
            "MAE(test)              :5.793042839964665\n",
            "MedianAE(test)         :4.905557160000001\n",
            "RMSE(test)             :7.35683323822878\n",
            "RMSE(test) / MAE(test) :1.2699428334062957\n",
            "\n",
            "macula_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.7667492793837841\n",
            "adjusted_r2(test)      :0.7495021464663719\n",
            "MAE(test)              :5.964571831872791\n",
            "MedianAE(test)         :4.928456310000001\n",
            "RMSE(test)             :7.629261941839845\n",
            "RMSE(test) / MAE(test) :1.2790963302799834\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.888949654392104\n",
            "adjusted_r2(test)      :0.8849337450944252\n",
            "MAE(test)              :3.564604021413428\n",
            "MedianAE(test)         :2.539118530000003\n",
            "RMSE(test)             :5.1707615514510135\n",
            "RMSE(test) / MAE(test) :1.4505851198026523\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.8976055990170648\n",
            "adjusted_r2(test)      :0.88870049962605\n",
            "MAE(test)              :3.0756187068551237\n",
            "MedianAE(test)         :1.7334969000000058\n",
            "RMSE(test)             :5.085423541127656\n",
            "RMSE(test) / MAE(test) :1.653463587600426\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.795229923415489\n",
            "adjusted_r2(test)      :0.811217222793396\n",
            "MAE(test)              :4.6806341502826845\n",
            "MedianAE(test)         :3.064993379999997\n",
            "RMSE(test)             :6.623106019951369\n",
            "RMSE(test) / MAE(test) :1.415001858145946\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.8259224430926069\n",
            "adjusted_r2(test)      :0.8479424821241291\n",
            "MAE(test)              :4.576684652544168\n",
            "MedianAE(test)         :3.7830636500000026\n",
            "RMSE(test)             :5.944077595935653\n",
            "RMSE(test) / MAE(test) :1.2987736860199346\n",
            "\n",
            "macula_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8473683265646388\n",
            "adjusted_r2(test)      :0.8625330241560869\n",
            "MAE(test)              :4.235821627208481\n",
            "MedianAE(test)         :3.341442349999994\n",
            "RMSE(test)             :5.65170794113709\n",
            "RMSE(test) / MAE(test) :1.3342648578102934\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.7299851319216435\n",
            "adjusted_r2(test)      :0.7686972588612858\n",
            "MAE(test)              :5.633387902508835\n",
            "MedianAE(test)         :4.3931870499999945\n",
            "RMSE(test)             :7.331129844173153\n",
            "RMSE(test) / MAE(test) :1.3013713898359862\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.6662082475472144\n",
            "adjusted_r2(test)      :0.7299273209309471\n",
            "MAE(test)              :6.3383639049116605\n",
            "MedianAE(test)         :5.1174550100000005\n",
            "RMSE(test)             :7.921744810439268\n",
            "RMSE(test) / MAE(test) :1.249809087846886\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.7128865575920947\n",
            "adjusted_r2(test)      :0.7567633881527909\n",
            "MAE(test)              :5.911970653816255\n",
            "MedianAE(test)         :4.723615879999997\n",
            "RMSE(test)             :7.517873164600553\n",
            "RMSE(test) / MAE(test) :1.2716357378647791\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.4251423960813878\n",
            "adjusted_r2(test)      :0.4631194360950881\n",
            "MAE(test)              :8.970167836961132\n",
            "MedianAE(test)         :7.853443859999999\n",
            "RMSE(test)             :11.169130434459547\n",
            "RMSE(test) / MAE(test) :1.2451417451118025\n",
            "\n",
            "vascular_CLAHE_A2_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8212252032347921\n",
            "adjusted_r2(test)      :0.7903189010563639\n",
            "MAE(test)              :4.959725722438162\n",
            "MedianAE(test)         :3.6669139899999976\n",
            "RMSE(test)             :6.980076200426876\n",
            "RMSE(test) / MAE(test) :1.4073512510678767\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_0\n",
            "adjusted_r2(train)     :0.7938931140498457\n",
            "adjusted_r2(test)      :0.8117660905991081\n",
            "MAE(test)              :4.917520021413427\n",
            "MedianAE(test)         :3.7382364300000006\n",
            "RMSE(test)             :6.613470989081903\n",
            "RMSE(test) / MAE(test) :1.3448793213415355\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_1\n",
            "adjusted_r2(train)     :0.7571502012463014\n",
            "adjusted_r2(test)      :0.7973909073055134\n",
            "MAE(test)              :5.064087617314488\n",
            "MedianAE(test)         :3.8486008599999977\n",
            "RMSE(test)             :6.861356543639612\n",
            "RMSE(test) / MAE(test) :1.3549047848580127\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_2\n",
            "adjusted_r2(train)     :0.8674162081505432\n",
            "adjusted_r2(test)      :0.9136219512899821\n",
            "MAE(test)              :2.972066336749117\n",
            "MedianAE(test)         :2.1246814699999987\n",
            "RMSE(test)             :4.480043348980076\n",
            "RMSE(test) / MAE(test) :1.5073833627416282\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_3\n",
            "adjusted_r2(train)     :0.877027694385178\n",
            "adjusted_r2(test)      :0.8940807069029152\n",
            "MAE(test)              :3.0945192010954066\n",
            "MedianAE(test)         :1.9289002399999973\n",
            "RMSE(test)             :4.960986652214584\n",
            "RMSE(test) / MAE(test) :1.6031526482235043\n",
            "\n",
            "vascular_CLAHE_B3_ver2_pretrained_4\n",
            "adjusted_r2(train)     :0.8791126169411625\n",
            "adjusted_r2(test)      :0.8788958040111969\n",
            "MAE(test)              :3.397420600636042\n",
            "MedianAE(test)         :2.2262697199999977\n",
            "RMSE(test)             :5.304691316587194\n",
            "RMSE(test) / MAE(test) :1.561387870431493\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpy4m8XyRKtV"
      },
      "source": [
        "#**Analysis using XGBoost**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/12/07/000022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d966OQgNzX9"
      },
      "source": [
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20JJ1H4Nmva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f0cc8f-2ed6-4c1f-90ef-d438477f9ee6"
      },
      "source": [
        "# Grid Search用のパラメータ作成。\n",
        "# あまり組み合わせが多いと時間がかかる(time consuming)\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "params = {\n",
        "        'eta': [0.01],             # default = 0.3      \n",
        "        'gamma': [1,2,3],            # default = 0\n",
        "        'max_depth': [7,8,9],      # default = 6\n",
        "        'min_child_weight': [1],   # default = 1\n",
        "        'subsample': [0.8,1.0],        # default = 1\n",
        "        'colsample_bytree': [0.8,1.0], # default = 1\n",
        "        }\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 1)\n",
        "\n",
        "#最適解探索\n",
        "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error', n_jobs=2, cv=kf.split(X_train,Y_train), verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train,Y_train)\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   29.8s\n",
            "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:   44.7s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ベストスコア:\n",
            "-1.7957638628540082\n",
            "\n",
            "\n",
            "ベストestimator:\n",
            "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=0.8, eta=0.01, gamma=2,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
            "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
            "             seed=None, silent=None, subsample=0.8, verbosity=1)\n",
            "\n",
            "\n",
            "ベストparams:\n",
            "{'colsample_bytree': 0.8, 'eta': 0.01, 'gamma': 2, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8}\n",
            "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
            "0        0.560363      0.216359  ...        0.757495                3\n",
            "1        0.392591      0.005526  ...        0.882666               13\n",
            "2        0.419165      0.008880  ...        0.732765                2\n",
            "3        0.443402      0.005575  ...        0.894005               12\n",
            "4        0.467633      0.004867  ...        0.766625                4\n",
            "5        0.491491      0.006454  ...        0.845334                7\n",
            "6        0.380529      0.003910  ...        0.766341                6\n",
            "7        0.403422      0.008819  ...        0.959683               21\n",
            "8        0.427884      0.009049  ...        0.735346                5\n",
            "9        0.435867      0.005627  ...        0.897926               18\n",
            "10       0.465029      0.009029  ...        0.695061                1\n",
            "11       0.485536      0.006101  ...        0.886414               14\n",
            "12       0.379040      0.003452  ...        0.764851               10\n",
            "13       0.385857      0.008167  ...        0.896329               20\n",
            "14       0.428719      0.007406  ...        0.732461                9\n",
            "15       0.440999      0.006828  ...        0.894843               16\n",
            "16       0.471709      0.005877  ...        0.724442                8\n",
            "17       0.482334      0.005815  ...        0.892787               15\n",
            "18       0.443975      0.004530  ...        1.097099               28\n",
            "19       0.465401      0.002313  ...        1.162171               23\n",
            "20       0.501117      0.009453  ...        1.116120               35\n",
            "21       0.530923      0.011985  ...        1.139982               17\n",
            "22       0.557416      0.008123  ...        1.093198               22\n",
            "23       0.567127      0.006292  ...        1.114157               11\n",
            "24       0.441790      0.004697  ...        1.134216               33\n",
            "25       0.468096      0.008375  ...        1.126861               19\n",
            "26       0.500239      0.009870  ...        1.115049               32\n",
            "27       0.523553      0.008598  ...        1.153435               25\n",
            "28       0.550055      0.006688  ...        1.091629               34\n",
            "29       0.573186      0.007798  ...        1.158118               24\n",
            "30       0.460168      0.011181  ...        1.082999               30\n",
            "31       0.489251      0.004061  ...        1.114691               31\n",
            "32       0.519556      0.005484  ...        1.112805               36\n",
            "33       0.518327      0.004997  ...        1.122564               27\n",
            "34       0.564312      0.005618  ...        1.078667               29\n",
            "35       0.584890      0.016803  ...        1.112086               26\n",
            "\n",
            "[36 rows x 19 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.9992863321132477',\n",
              " 'adjusted_r2(test)      :0.9867920261248598',\n",
              " '平均誤差率(test)       :0.016491223324835196',\n",
              " 'MAE(test)              :0.8800020858171551',\n",
              " 'MedianAE(test)         :0.5713386535644531',\n",
              " 'RMSE(test)             :1.6257476892070504',\n",
              " 'RMSE(test) / MAE(test) :1.8474361770374765')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeZYNf5nX7-k"
      },
      "source": [
        "#Bayesian Optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# BaysianOptimizationで最適化する関数を定義する\n",
        "def get_model_predictions(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# BaysianOptimizationで最適化する関数を定義する\n",
        "def xgb_regressor(max_depth, min_child_weight, gamma, subsample, colsample_bytree,reg_alpha, n_estimators, reg_lambda,learning_rate):\n",
        "\n",
        "    params = {'max_depth':int(max_depth),\n",
        "                'min_child_weight':int(min_child_weight),\n",
        "                'gamma':gamma,\n",
        "                'subsample':subsample,\n",
        "                'colsample_bytree':colsample_bytree,\n",
        "                'reg_alpha':reg_alpha,\n",
        "                'n_estimators':int(n_estimators),\n",
        "                'reg_lambda':reg_lambda,\n",
        "                'learning_rate':learning_rate\n",
        "                }\n",
        "    model = xgb.XGBRegressor(**params,\n",
        "                            early_stopping_rounds=50,\n",
        "                            eval_set=[(X_test, Y_test)],\n",
        "                            eval_metric='rmse',\n",
        "                            silent=False,\n",
        "                            n_jobs=-1\n",
        "                            )\n",
        "\n",
        "    Y_pred_cv = cross_val_predict(model,X_train,Y_train,cv=5, n_jobs=-1)\n",
        "    rmse_cv = np.sqrt(mean_squared_error(Y_train, Y_pred_cv))\n",
        "\n",
        "    return -rmse_cv\n",
        "\n",
        "#ベイズ最適化で探索するパラメータ空間を定義する\n",
        "xgb_bo = BayesianOptimization(xgb_regressor,\n",
        "                            {'max_depth':(3,8),\n",
        "                            'min_child_weight':(1,5),\n",
        "                            'gamma':(0,0.5),\n",
        "                            'subsample':(0.6,1),\n",
        "                            'colsample_bytree':(0.6,1),\n",
        "                            'reg_alpha':(1e-5,100),\n",
        "                            'n_estimators':(1000,2000),\n",
        "                            'reg_lambda':(1e-5,1),\n",
        "                            'learning_rate':(0.1,0.3)\n",
        "                            })\n",
        "\n",
        "#ベイズ最適化を実行（scoreが最大となるようにパラメータを探索していく）\n",
        "#init_point：初期に探索する点数\n",
        "#acq:獲得関数。EIは(expected improvement)\n",
        "xgb_bo.maximize(init_points=5, n_iter=200, acq='ei')\n",
        "\n",
        "#最もスコアのよかったパラメータの値を取得する。\n",
        "optimized_params = xgb_bo.max['params']\n",
        "\n",
        "#整数のパラメータは変換\n",
        "optimized_params['max_depth'] = int(optimized_params['max_depth'])\n",
        "optimized_params['min_child_weight'] = int(optimized_params['min_child_weight'])\n",
        "optimized_params['n_estimators'] = int(optimized_params['n_estimators'])\n",
        "\n",
        "#調整したパラメータで精度検証する\n",
        "opt_model = xgb.XGBRegressor()\n",
        "opt_model.set_params(**optimized_params)\n",
        "opt_model.fit(X_train, Y_train)\n",
        "#y_pred_train = opt_model.predict(X_train)\n",
        "#y_pred_test = opt_model.predict(X_test)\n",
        "bestmodel = opt_model\n",
        "print(bestmodel)\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)\n",
        "\n",
        "\"\"\"\n",
        "# 学習モデルの評価（RMSEを計算）\n",
        "print('RMSE(train data):',round(np.sqrt(mean_squared_error(Y_train, Y_pred_train)),3))\n",
        "print('RMSE(test data):',round(np.sqrt(mean_squared_error(Y_test, Y_pred_test)),3))\n",
        "#output\n",
        "#RMSE(train data): 0.426\n",
        "#RMSE(test data): 2.266\n",
        "#CPU times: user 32.1 s, sys: 4.64 s, total: 36.7 s\n",
        "#Wall time: 11min 42s\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "-nASsIwGt10r",
        "outputId": "2ad390b6-56cc-4ce9-c92e-1c9be934f654"
      },
      "source": [
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-34d572d7bef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_model_evaluations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-8e6e4bfc635a>\u001b[0m in \u001b[0;36mget_model_evaluations\u001b[0;34m(X_train, Y_train, X_test, Y_test, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m    \u001b[0;31m# 評価指標確認\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m    \u001b[0;31m# 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0myhat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"adjusted_r2(train)     :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjusted_r2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;34m,\u001b[0m \u001b[0;34m\"adjusted_r2(test)      :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjusted_r2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;34m,\u001b[0m \u001b[0;34m\"平均誤差率(test)       :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0myhat_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;34m,\u001b[0m \u001b[0;34m\"MAE(test)              :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;34m,\u001b[0m \u001b[0;34m\"MedianAE(test)         :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedian_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;34m,\u001b[0m \u001b[0;34m\"RMSE(test)             :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;34m,\u001b[0m \u001b[0;34m\"RMSE(test) / MAE(test) :\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0...\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                                           validate_features=validate_features)\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['cropped_2_A2_GaussianBlur_pretrained_0', 'cropped_2_A2_GaussianBlur_pretrained_1', 'cropped_2_A2_GaussianBlur_pretrained_2', 'cropped_2_A2_GaussianBlur_pretrained_3', 'cropped_2_A2_GaussianBlur_pretrained_4', 'disc_2_A2_GaussianBlur_pretrained_0', 'disc_2_A2_GaussianBlur_pretrained_1', 'disc_2_A2_GaussianBlur_pretrained_2', 'disc_2_A2_GaussianBlur_pretrained_3', 'disc_2_A2_GaussianBlur_pretrained_4', 'macula_2_A2_GaussianBlur_pretrained_0', 'macula_2_A2_GaussianBlur_pretrained_1', 'macula_2_A2_GaussianBlur_pretrained_2', 'macula_2_A2_GaussianBlur_pretrained_3', 'macula_2_A2_GaussianBlur_pretrained_4', 'cropped_2_B3_GaussianBlur_pretrained_0', 'cropped_2_B3_GaussianBlur_pretrained_1', 'cropped_2_B3_GaussianBlur_pretrained_2', 'cropped_2_B3_GaussianBlur_pretrained_3', 'cropped_2_B3_GaussianBlur_pretrained_4', 'disc_2_B3_GaussianBlur_pretrained_0', 'disc_2_B3_GaussianBlur_pretrained_1', 'disc_2_B3_GaussianBlur_pretrained_2', 'disc_2_B3_GaussianBlur_pretrained_3', 'disc_2_B3_GaussianBlur_pretrained_4', 'macula_2_B3_GaussianBlur_pretrained_0', 'macula_2_B3_GaussianBlur_pretrained_1', 'macula_2_B3_GaussianBlur_pretrained_2', 'macula_2_B3_GaussianBlur_pretrained_3', 'macula_2_B3_GaussianBlur_pretrained_4', 'vascular_2_RGB_B3_GaussianBlur_pretrained_0', 'vascular_2_RGB_B3_GaussianBlur_pretrained_1', 'vascular_2_RGB_B3_GaussianBlur_pretrained_2', 'vascular_2_RGB_B3_GaussianBlur_pretrained_3', 'vascular_2_RGB_B3_GaussianBlur_pretraine...\nexpected disc_2_A2_GaussianBlur_pretrained_3, macula_2_A2_GaussianBlur_pretrained_4, macula_2_B3_GB_L1Loss_pretrained_0, macula_2_B3_GB_L1Loss_pretrained_2, vascular_CLAHE_A2_ver2_pretrained_3.1, disc_2_A2_GB_L1Loss_pretrained_1, disc_2_A2_GB_L1Loss_pretrained_2, macula_2_A2_GB_L1Loss_pretrained_1, cropped_2_A2_GB_L1Loss_pretrained_1, cropped_2_B3_GaussianBlur_pretrained_4, disc_2_A2_GaussianBlur_pretrained_2, disc_2_B3_GaussianBlur_pretrained_2, cropped_CLAHE_B3_ver2_pretrained_0.1, macula_CLAHE_B3_ver2_pretrained_1.1, disc_CLAHE_A2_ver2_pretrained_3.1, macula_CLAHE_B3_ver2_pretrained_3.1, disc_2_A2_GB_L1Loss_pretrained_0, cropped_CLAHE_B3_ver2_pretrained_3.1, disc_CLAHE_A2_ver2_pretrained_2.1, cropped_2_A2_GaussianBlur_pretrained_3, cropped_2_B3_GaussianBlur_pretrained_3, macula_2_B3_GaussianBlur_pretrained_4, macula_2_A2_GaussianBlur_pretrained_0, disc_2_A2_GaussianBlur_pretrained_1, vascular_2_RGB_B3_GaussianBlur_pretrained_3, cropped_CLAHE_B3_ver2_pretrained_1.1, macula_CLAHE_B3_ver2_pretrained_4.1, disc_2_B3_GB_L1Loss_pretrained_0, cropped_2_A2_GaussianBlur_pretrained_4, macula_2_A2_GB_L1Loss_pretrained_0, disc_2_B3_GaussianBlur_pretrained_0, macula_2_B3_GaussianBlur_pretrained_1, disc_CLAHE_A2_ver2_pretrained_0.1, disc_2_B3_GaussianBlur_pretrained_4, cropped_2_A2_GB_L1Loss_pretrained_3, vascular_2_RGB_B3_GB_L1Loss_pretrained_3, vascular_CLAHE_A2_ver2_pretrained_1.1, macula_2_B3_GaussianBlur_pretrained_3, cropped_2_A2_GB_L1Loss_pretrained_2, vascular_2_RGB_A2_GB_L1Lo..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndXsi0Q0qnIc"
      },
      "source": [
        "\"\"\"\n",
        "#Optuna\n",
        "import optuna\n",
        "start = time.time()\n",
        "# ベイズ最適化時の評価指標算出メソッド\n",
        "def bayes_objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 8),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 4),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 0.1, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 0.1, log=True),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0001, 0.1, log=True),\n",
        "    }\n",
        "    # モデルにパラメータ適用\n",
        "    model.set_params(**params)\n",
        "    # cross_val_scoreでクロスバリデーション\n",
        "    scores = cross_val_score(model, X, y, cv=cv,\n",
        "                             scoring=scoring, fit_params=fit_params, n_jobs=-1)\n",
        "    val = scores.mean()\n",
        "    return val\n",
        "\n",
        "# ベイズ最適化を実行\n",
        "study = optuna.create_study(direction='maximize',\n",
        "                            sampler=optuna.samplers.TPESampler(seed=seed))\n",
        "study.optimize(bayes_objective, n_trials=5)\n",
        "\n",
        "# 最適パラメータの表示と保持\n",
        "best_params = study.best_trial.params\n",
        "best_score = study.best_trial.value\n",
        "print(f'最適パラメータ {best_params}\\nスコア {best_score}')\n",
        "print(f'所要時間{time.time() - start}秒')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wq2xWzPPEln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "64b16f47-be5d-49b4-a8cf-4a8c1ad0bc37"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=bestmodel.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5435e9e9d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AseFYOzD8mV7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = bestmodel.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIobiMOEPGKc"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='gain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnbP5EF_6pc9"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpEpFczPHkK"
      },
      "source": [
        "xgb.to_graphviz(bestmodel, num_trees=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-Kj_RHRQ-9"
      },
      "source": [
        "#**Analysis using RandomForest**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/11/14/200857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSyqmEyGRfHU"
      },
      "source": [
        "#Create model\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=10)\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\"\"\"\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "           oob_score=False, random_state=2525, verbose=0, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_result(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW6HVmKTUWsB"
      },
      "source": [
        "#Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(X_train,Y_train)\n",
        "\n",
        "\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkW5oubR4MJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rci5gcXQQ9XG"
      },
      "source": [
        "\"\"\"\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('Importances')\n",
        "plt.rcParams['font.size']=10\n",
        "sns.barplot(y='features', x='importances', data=df_s, palette='viridis')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DihmVVSbKI"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3Qw-hrjFi-"
      },
      "source": [
        "#**Analysis using neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwwcmwczMwfE"
      },
      "source": [
        "#正規化する\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#モデル作成\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "model = MLPRegressor(alpha=0.1, hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive', max_iter=500, random_state=42, solver=\"lbfgs\", early_stopping=True) \n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "初期設定：\n",
        "\n",
        "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "       verbose=False, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcqR8-Nj1E9"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlExOBk8fCoE"
      },
      "source": [
        "#**Predict age from test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zC8VftCfIcr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "4286e3a2-7f98-4213-a391-1c38c81380d6"
      },
      "source": [
        "df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img00085008_00_1R.jpg</th>\n",
              "      <td>61</td>\n",
              "      <td>60.885948</td>\n",
              "      <td>60.356665</td>\n",
              "      <td>50.935251</td>\n",
              "      <td>59.631753</td>\n",
              "      <td>58.965695</td>\n",
              "      <td>45.052648</td>\n",
              "      <td>60.332221</td>\n",
              "      <td>61.809397</td>\n",
              "      <td>59.062302</td>\n",
              "      <td>68.153375</td>\n",
              "      <td>51.562381</td>\n",
              "      <td>58.757454</td>\n",
              "      <td>68.297571</td>\n",
              "      <td>59.610933</td>\n",
              "      <td>55.720055</td>\n",
              "      <td>58.482534</td>\n",
              "      <td>59.504211</td>\n",
              "      <td>45.093548</td>\n",
              "      <td>58.708310</td>\n",
              "      <td>57.960665</td>\n",
              "      <td>44.306228</td>\n",
              "      <td>62.429917</td>\n",
              "      <td>47.746590</td>\n",
              "      <td>60.145330</td>\n",
              "      <td>59.885645</td>\n",
              "      <td>63.356745</td>\n",
              "      <td>62.210029</td>\n",
              "      <td>52.995640</td>\n",
              "      <td>60.519272</td>\n",
              "      <td>57.649809</td>\n",
              "      <td>63.051468</td>\n",
              "      <td>61.155617</td>\n",
              "      <td>60.746276</td>\n",
              "      <td>38.692406</td>\n",
              "      <td>57.933575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00085024_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>29.766262</td>\n",
              "      <td>30.331397</td>\n",
              "      <td>29.118884</td>\n",
              "      <td>31.672752</td>\n",
              "      <td>30.989829</td>\n",
              "      <td>26.809660</td>\n",
              "      <td>32.241669</td>\n",
              "      <td>30.086446</td>\n",
              "      <td>30.817971</td>\n",
              "      <td>32.113385</td>\n",
              "      <td>26.403788</td>\n",
              "      <td>27.999404</td>\n",
              "      <td>31.571031</td>\n",
              "      <td>26.205668</td>\n",
              "      <td>21.942243</td>\n",
              "      <td>28.228927</td>\n",
              "      <td>28.847709</td>\n",
              "      <td>27.994281</td>\n",
              "      <td>28.715485</td>\n",
              "      <td>28.885067</td>\n",
              "      <td>26.357773</td>\n",
              "      <td>28.899875</td>\n",
              "      <td>26.704368</td>\n",
              "      <td>28.894490</td>\n",
              "      <td>28.859845</td>\n",
              "      <td>28.657392</td>\n",
              "      <td>28.822759</td>\n",
              "      <td>22.991714</td>\n",
              "      <td>28.690979</td>\n",
              "      <td>25.721887</td>\n",
              "      <td>34.075314</td>\n",
              "      <td>31.509855</td>\n",
              "      <td>33.798274</td>\n",
              "      <td>38.365373</td>\n",
              "      <td>29.952043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00241280_10_1R.jpg</th>\n",
              "      <td>51</td>\n",
              "      <td>58.364809</td>\n",
              "      <td>50.553083</td>\n",
              "      <td>63.250524</td>\n",
              "      <td>54.238850</td>\n",
              "      <td>50.851762</td>\n",
              "      <td>63.289428</td>\n",
              "      <td>54.653805</td>\n",
              "      <td>49.245375</td>\n",
              "      <td>50.571257</td>\n",
              "      <td>57.794720</td>\n",
              "      <td>49.765614</td>\n",
              "      <td>49.845201</td>\n",
              "      <td>54.795003</td>\n",
              "      <td>59.864140</td>\n",
              "      <td>54.611915</td>\n",
              "      <td>57.051009</td>\n",
              "      <td>54.708534</td>\n",
              "      <td>57.299381</td>\n",
              "      <td>49.541694</td>\n",
              "      <td>54.624343</td>\n",
              "      <td>52.290088</td>\n",
              "      <td>56.760901</td>\n",
              "      <td>47.204936</td>\n",
              "      <td>52.778614</td>\n",
              "      <td>52.187645</td>\n",
              "      <td>51.639259</td>\n",
              "      <td>53.236330</td>\n",
              "      <td>44.357553</td>\n",
              "      <td>52.916056</td>\n",
              "      <td>56.503397</td>\n",
              "      <td>47.425610</td>\n",
              "      <td>57.344145</td>\n",
              "      <td>51.043272</td>\n",
              "      <td>55.263293</td>\n",
              "      <td>48.160061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_1R.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.213056</td>\n",
              "      <td>31.123018</td>\n",
              "      <td>29.923308</td>\n",
              "      <td>31.866950</td>\n",
              "      <td>31.424466</td>\n",
              "      <td>33.026874</td>\n",
              "      <td>27.775347</td>\n",
              "      <td>31.257206</td>\n",
              "      <td>30.184183</td>\n",
              "      <td>31.335768</td>\n",
              "      <td>28.773826</td>\n",
              "      <td>28.549322</td>\n",
              "      <td>29.491693</td>\n",
              "      <td>27.227801</td>\n",
              "      <td>29.133636</td>\n",
              "      <td>28.235692</td>\n",
              "      <td>31.660154</td>\n",
              "      <td>30.401087</td>\n",
              "      <td>29.131159</td>\n",
              "      <td>27.815926</td>\n",
              "      <td>33.806103</td>\n",
              "      <td>34.369171</td>\n",
              "      <td>30.322504</td>\n",
              "      <td>30.721486</td>\n",
              "      <td>30.021170</td>\n",
              "      <td>27.490881</td>\n",
              "      <td>30.023479</td>\n",
              "      <td>23.335579</td>\n",
              "      <td>29.751483</td>\n",
              "      <td>28.661990</td>\n",
              "      <td>33.212128</td>\n",
              "      <td>37.661710</td>\n",
              "      <td>37.906623</td>\n",
              "      <td>35.059234</td>\n",
              "      <td>30.629086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img00265140_00_2L.jpg</th>\n",
              "      <td>29</td>\n",
              "      <td>32.485062</td>\n",
              "      <td>31.811762</td>\n",
              "      <td>30.549696</td>\n",
              "      <td>32.765386</td>\n",
              "      <td>31.352851</td>\n",
              "      <td>35.573980</td>\n",
              "      <td>32.451853</td>\n",
              "      <td>30.288148</td>\n",
              "      <td>31.099230</td>\n",
              "      <td>30.537629</td>\n",
              "      <td>29.595745</td>\n",
              "      <td>27.726558</td>\n",
              "      <td>31.044161</td>\n",
              "      <td>32.806641</td>\n",
              "      <td>29.797870</td>\n",
              "      <td>29.842737</td>\n",
              "      <td>28.483209</td>\n",
              "      <td>29.473320</td>\n",
              "      <td>28.350401</td>\n",
              "      <td>31.485087</td>\n",
              "      <td>32.985473</td>\n",
              "      <td>37.007666</td>\n",
              "      <td>28.809839</td>\n",
              "      <td>28.963286</td>\n",
              "      <td>29.689914</td>\n",
              "      <td>26.915285</td>\n",
              "      <td>28.129721</td>\n",
              "      <td>24.725600</td>\n",
              "      <td>28.009915</td>\n",
              "      <td>28.578359</td>\n",
              "      <td>31.528470</td>\n",
              "      <td>32.324287</td>\n",
              "      <td>38.401335</td>\n",
              "      <td>32.143921</td>\n",
              "      <td>30.726725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76791392_10_1R.jpg</th>\n",
              "      <td>38</td>\n",
              "      <td>38.199157</td>\n",
              "      <td>39.335907</td>\n",
              "      <td>38.415360</td>\n",
              "      <td>40.701389</td>\n",
              "      <td>37.806478</td>\n",
              "      <td>37.474301</td>\n",
              "      <td>32.679823</td>\n",
              "      <td>31.805116</td>\n",
              "      <td>37.843254</td>\n",
              "      <td>33.726096</td>\n",
              "      <td>36.371392</td>\n",
              "      <td>49.667397</td>\n",
              "      <td>39.193630</td>\n",
              "      <td>38.588050</td>\n",
              "      <td>34.526837</td>\n",
              "      <td>38.396522</td>\n",
              "      <td>35.274139</td>\n",
              "      <td>38.497335</td>\n",
              "      <td>38.434505</td>\n",
              "      <td>34.112072</td>\n",
              "      <td>35.426679</td>\n",
              "      <td>35.021561</td>\n",
              "      <td>28.289860</td>\n",
              "      <td>35.640907</td>\n",
              "      <td>36.847824</td>\n",
              "      <td>37.365493</td>\n",
              "      <td>46.835411</td>\n",
              "      <td>31.393817</td>\n",
              "      <td>38.262957</td>\n",
              "      <td>42.541334</td>\n",
              "      <td>36.452386</td>\n",
              "      <td>44.501454</td>\n",
              "      <td>43.832183</td>\n",
              "      <td>44.443870</td>\n",
              "      <td>36.340073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_10_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>53.196847</td>\n",
              "      <td>45.640141</td>\n",
              "      <td>45.546347</td>\n",
              "      <td>51.625419</td>\n",
              "      <td>50.128996</td>\n",
              "      <td>48.410195</td>\n",
              "      <td>42.230716</td>\n",
              "      <td>46.253222</td>\n",
              "      <td>51.311338</td>\n",
              "      <td>51.198155</td>\n",
              "      <td>48.310232</td>\n",
              "      <td>45.538834</td>\n",
              "      <td>44.979483</td>\n",
              "      <td>52.453923</td>\n",
              "      <td>44.837600</td>\n",
              "      <td>47.394177</td>\n",
              "      <td>48.088434</td>\n",
              "      <td>49.969494</td>\n",
              "      <td>49.401051</td>\n",
              "      <td>50.176543</td>\n",
              "      <td>47.796735</td>\n",
              "      <td>57.036519</td>\n",
              "      <td>50.078702</td>\n",
              "      <td>50.911272</td>\n",
              "      <td>49.306154</td>\n",
              "      <td>49.032882</td>\n",
              "      <td>48.545510</td>\n",
              "      <td>33.817515</td>\n",
              "      <td>41.229436</td>\n",
              "      <td>50.404090</td>\n",
              "      <td>50.643623</td>\n",
              "      <td>59.744704</td>\n",
              "      <td>54.123229</td>\n",
              "      <td>57.273388</td>\n",
              "      <td>48.106965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76843122_11_1R.jpg</th>\n",
              "      <td>49</td>\n",
              "      <td>56.886828</td>\n",
              "      <td>50.544816</td>\n",
              "      <td>47.587875</td>\n",
              "      <td>52.457392</td>\n",
              "      <td>50.793570</td>\n",
              "      <td>52.799886</td>\n",
              "      <td>45.932961</td>\n",
              "      <td>44.371003</td>\n",
              "      <td>51.916403</td>\n",
              "      <td>50.504851</td>\n",
              "      <td>44.726014</td>\n",
              "      <td>42.309937</td>\n",
              "      <td>45.024800</td>\n",
              "      <td>40.706378</td>\n",
              "      <td>42.950150</td>\n",
              "      <td>55.220819</td>\n",
              "      <td>48.409539</td>\n",
              "      <td>49.657461</td>\n",
              "      <td>49.004924</td>\n",
              "      <td>47.710246</td>\n",
              "      <td>47.885427</td>\n",
              "      <td>55.062169</td>\n",
              "      <td>52.543592</td>\n",
              "      <td>51.201683</td>\n",
              "      <td>50.496775</td>\n",
              "      <td>49.698067</td>\n",
              "      <td>47.475055</td>\n",
              "      <td>29.821983</td>\n",
              "      <td>40.268657</td>\n",
              "      <td>56.234378</td>\n",
              "      <td>50.509459</td>\n",
              "      <td>53.434712</td>\n",
              "      <td>52.482903</td>\n",
              "      <td>54.819530</td>\n",
              "      <td>47.122028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_1R.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>56.605852</td>\n",
              "      <td>71.386600</td>\n",
              "      <td>74.264765</td>\n",
              "      <td>73.703772</td>\n",
              "      <td>72.917128</td>\n",
              "      <td>68.061024</td>\n",
              "      <td>74.160743</td>\n",
              "      <td>74.606669</td>\n",
              "      <td>42.933744</td>\n",
              "      <td>78.277564</td>\n",
              "      <td>73.981255</td>\n",
              "      <td>69.788361</td>\n",
              "      <td>79.573733</td>\n",
              "      <td>68.793005</td>\n",
              "      <td>71.677345</td>\n",
              "      <td>70.824075</td>\n",
              "      <td>70.887142</td>\n",
              "      <td>74.848467</td>\n",
              "      <td>73.488754</td>\n",
              "      <td>73.900068</td>\n",
              "      <td>71.458507</td>\n",
              "      <td>79.234850</td>\n",
              "      <td>59.871906</td>\n",
              "      <td>43.737605</td>\n",
              "      <td>69.913667</td>\n",
              "      <td>70.363796</td>\n",
              "      <td>72.958624</td>\n",
              "      <td>59.976119</td>\n",
              "      <td>71.317726</td>\n",
              "      <td>78.840834</td>\n",
              "      <td>68.769974</td>\n",
              "      <td>62.816906</td>\n",
              "      <td>66.310376</td>\n",
              "      <td>50.796282</td>\n",
              "      <td>63.409376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76888512_00_2L.jpg</th>\n",
              "      <td>74</td>\n",
              "      <td>69.049191</td>\n",
              "      <td>66.318005</td>\n",
              "      <td>73.155653</td>\n",
              "      <td>73.523390</td>\n",
              "      <td>72.985840</td>\n",
              "      <td>66.385049</td>\n",
              "      <td>68.927622</td>\n",
              "      <td>68.367136</td>\n",
              "      <td>53.513491</td>\n",
              "      <td>75.332546</td>\n",
              "      <td>74.130625</td>\n",
              "      <td>71.575391</td>\n",
              "      <td>88.524705</td>\n",
              "      <td>60.911018</td>\n",
              "      <td>71.346241</td>\n",
              "      <td>68.293542</td>\n",
              "      <td>72.224498</td>\n",
              "      <td>74.863398</td>\n",
              "      <td>72.767866</td>\n",
              "      <td>71.941185</td>\n",
              "      <td>73.264325</td>\n",
              "      <td>76.172227</td>\n",
              "      <td>64.452952</td>\n",
              "      <td>60.746992</td>\n",
              "      <td>71.590483</td>\n",
              "      <td>72.297430</td>\n",
              "      <td>71.659863</td>\n",
              "      <td>77.320302</td>\n",
              "      <td>67.448586</td>\n",
              "      <td>84.819227</td>\n",
              "      <td>68.363243</td>\n",
              "      <td>61.668277</td>\n",
              "      <td>61.990064</td>\n",
              "      <td>61.996752</td>\n",
              "      <td>69.304931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1414 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       age  ...  vascular_2_RGB_B3_GaussianBlur_pretrained_4\n",
              "filename                    ...                                             \n",
              "img00085008_00_1R.jpg   61  ...                                    57.933575\n",
              "img00085024_00_1R.jpg   29  ...                                    29.952043\n",
              "img00241280_10_1R.jpg   51  ...                                    48.160061\n",
              "img00265140_00_1R.jpg   29  ...                                    30.629086\n",
              "img00265140_00_2L.jpg   29  ...                                    30.726725\n",
              "...                    ...  ...                                          ...\n",
              "img76791392_10_1R.jpg   38  ...                                    36.340073\n",
              "img76843122_10_1R.jpg   49  ...                                    48.106965\n",
              "img76843122_11_1R.jpg   49  ...                                    47.122028\n",
              "img76888512_00_1R.jpg   74  ...                                    63.409376\n",
              "img76888512_00_2L.jpg   74  ...                                    69.304931\n",
              "\n",
              "[1414 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8L_f0Qdq17-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "36bad807-a5ed-4ba1-d758-dc5a3fd166b0"
      },
      "source": [
        "import sys\n",
        "\n",
        "#評価用ファイルの呼び出し\n",
        "df_dst = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv\", index_col=0, sep=\",\")\n",
        "df_dst\n",
        "\n",
        "index = df_dst.iloc[7:408,0] #画像名リスト\n",
        "cols = df.columns #modelリスト\n",
        "\n",
        "df_temp = pd.DataFrame(index=index, columns=cols)\n",
        "df_temp\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_0</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_1</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_2</th>\n",
              "      <th>cropped_CLAHE_A2_ver2_pretrained_3</th>\n",
              "      <th>...</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>disc_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>disc_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>macula_2_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>macula_2_B3_GB_L1Loss_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_A2_GB_L1Loss_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GB_L1Loss_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img76901008_06_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_06_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img77009741_01_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962800_00_1L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962810_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962820_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962830_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962840_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 155 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   age  ... vascular_2_RGB_B3_GB_L1Loss_pretrained_4\n",
              "Unnamed: 1              ...                                         \n",
              "img76901008_06_1R  NaN  ...                                      NaN\n",
              "img76901008_06_2L  NaN  ...                                      NaN\n",
              "img76901008_07_1R  NaN  ...                                      NaN\n",
              "img76901008_07_2L  NaN  ...                                      NaN\n",
              "img77009741_01_1R  NaN  ...                                      NaN\n",
              "...                ...  ...                                      ...\n",
              "img99962800_00_1L  NaN  ...                                      NaN\n",
              "img99962810_00_1R  NaN  ...                                      NaN\n",
              "img99962820_00_1R  NaN  ...                                      NaN\n",
              "img99962830_00_1R  NaN  ...                                      NaN\n",
              "img99962840_00_1R  NaN  ...                                      NaN\n",
              "\n",
              "[401 rows x 155 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGbfrHokrOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b34143e-aeb4-489a-dbd1-a34a9a09169e"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "#!pip install adabelief-pytorch==0.1.0\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "\"\"\"\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\"\"\"\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入##########改変要\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df_temp.loc[df_temp.index.str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "class Select_dataset:\n",
        "    \"\"\"\n",
        "    「name = cropped_CLAHE_A2_pretrained_2」\n",
        "    からモデルのダウンロードとdatasetの選択を行う\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.preprocess = \"\"\n",
        "        self.part = \"\"\n",
        "        self.DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "        self.dst_path = \"\"\n",
        "\n",
        "    def select_preprocess(self):\n",
        "        if \"CLAHE\" in self.name:\n",
        "            self.preprocess = \"_CLAHE\"\n",
        "        else:\n",
        "            self.preprocess = \"\"\n",
        "    \n",
        "    def select_part(self):\n",
        "        if \"disc\" in self.name:\n",
        "            self.part = \"disc\"\n",
        "        elif \"macula\" in self.name:\n",
        "            self.part = \"macula\"\n",
        "        else:\n",
        "            self.part = \"cropped\"\n",
        "\n",
        "    def output_dataset(self):\n",
        "        self.dst_path = self.DATASET_PATH + \"/test_\"+ self.part + self.preprocess +\"_img\"\n",
        "        return self.dst_path\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.2.0-py3-none-any.whl (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.2.0\n",
            "Collecting ranger-adabelief==0.1.0\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger-adabelief==0.1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (3.7.4.3)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-bfcb7f3b-6f77-3bbe-7f1e-fd007ab67df9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmiqljhz02F"
      },
      "source": [
        "import glob\n",
        "\n",
        "model_size = \"\"\n",
        "preprocess = \"\"\n",
        "for i in cols[1:]: #modelごとに結果を出す\n",
        "    print(i)\n",
        "    \n",
        "    if \"A2\" in i:\n",
        "        model_size_temp = \"A2\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    elif \"B3\" in i:\n",
        "        model_size_temp = \"B3\"\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    else:\n",
        "        print(\"A2あるいはB3で指定して下さい\")\n",
        "        sys.exit(1)\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/FundusPhoto/model/'+str(i)+\".pth\"))\n",
        "    model_ft.to(device)\n",
        "    \n",
        "    select_dataset = Select_dataset(i)\n",
        "    select_dataset.select_preprocess()\n",
        "    select_dataset.select_part()\n",
        "    data_path = select_dataset.output_dataset()\n",
        "\n",
        "    data_path = glob.glob(data_path+\"/*\")\n",
        "    print(data_path)\n",
        "\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        print(j)\n",
        "        #print(os.path.splitext(os.path.basename(m))[0])\n",
        "        #image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "        image_name = os.path.splitext(os.path.basename(j))[0]\n",
        "        image_tensor = image_transform(j)  #予測のための画像下処理\n",
        "        pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "        write_result(df_temp, image_name, pred, str(i))\n",
        "        #print(str(k)+\"/\"+str(len(df_temp)) + \" images processed! pred: \"+str(pred))\n",
        "        k+=1\n",
        "df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3Jw9LPgEgu"
      },
      "source": [
        "#save CSV file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_5_GB.csv'\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-eMHoKHnIsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedd28b6-9180-48dc-a206-b9293c019a6a"
      },
      "source": [
        "#load csv file\n",
        "temp_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_concat.csv'\n",
        "df_temp = pd.read_csv(temp_path, index_col=0, sep=\",\")\n",
        "print(df_temp)\n",
        "\n",
        "dst_path = '/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv'\n",
        "df_dst = pd.read_csv(dst_path, index_col=0, sep=\",\")\n",
        "#df_dst"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   age  ...  vascular_2_RGB_B3_GB_L1Loss_pretrained_4\n",
            "Unnamed: 1              ...                                          \n",
            "img76901008_06_1R   70  ...                                 53.131670\n",
            "img76901008_06_2L   68  ...                                 55.750787\n",
            "img76901008_07_1R   69  ...                                 52.608454\n",
            "img76901008_07_2L   66  ...                                 54.159564\n",
            "img77009741_01_1R   44  ...                                 50.823110\n",
            "...                ...  ...                                       ...\n",
            "img99962800_00_1L   29  ...                                 52.267468\n",
            "img99962810_00_1R   30  ...                                 51.456147\n",
            "img99962820_00_1R   30  ...                                 52.083141\n",
            "img99962830_00_1R   29  ...                                 51.914799\n",
            "img99962840_00_1R   30  ...                                 51.695716\n",
            "\n",
            "[401 rows x 155 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Jp4BqEhnKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76367153-8561-467b-b7c5-8d39a9cb0c60"
      },
      "source": [
        "from decimal import *\n",
        "\n",
        "#XGBoostのベストモデルを用いて予測をする\n",
        "def get_model_predicts(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "def my_round(x):\n",
        "    y = Decimal(x).quantize(Decimal('0'), rounding=ROUND_HALF_UP) \n",
        "    return int(y)\n",
        "\n",
        "FEATURE_COLS=df_temp.columns.values[1:].tolist()\n",
        "X_test = df_temp[FEATURE_COLS]\n",
        "#Y_test = df_temp[\"age\"]\n",
        "\n",
        "predictive_results = get_model_predicts(X_test, bestmodel)\n",
        "#print(predictive_results)\n",
        "\n",
        "predictive_results = [my_round(float(predictive_results[n])) for n in range(len(predictive_results))] \n",
        "print(predictive_results)\n",
        "\n",
        "df_temp.loc[:, \"age\"] = predictive_results\n",
        "df_temp.to_csv(temp_path, encoding='utf_8_sig')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[70, 70, 71, 69, 44, 34, 42, 57, 41, 39, 67, 63, 40, 67, 70, 61, 58, 59, 59, 59, 60, 61, 60, 62, 61, 63, 60, 62, 57, 61, 49, 59, 32, 70, 69, 47, 48, 65, 63, 60, 65, 61, 59, 59, 61, 58, 58, 50, 44, 60, 34, 30, 35, 31, 62, 49, 49, 59, 55, 60, 48, 54, 57, 34, 51, 60, 56, 61, 38, 36, 36, 37, 61, 61, 62, 62, 55, 46, 38, 41, 42, 59, 44, 51, 53, 48, 48, 37, 32, 33, 68, 45, 47, 35, 36, 33, 62, 72, 29, 66, 67, 35, 52, 59, 43, 69, 63, 31, 33, 31, 32, 33, 29, 30, 60, 60, 60, 60, 49, 45, 70, 61, 59, 30, 31, 34, 32, 30, 33, 71, 61, 64, 67, 63, 65, 61, 47, 55, 31, 58, 58, 65, 31, 50, 48, 59, 61, 61, 61, 63, 65, 67, 56, 65, 66, 44, 46, 60, 62, 60, 61, 71, 72, 60, 60, 58, 58, 61, 60, 53, 71, 72, 58, 60, 60, 60, 50, 33, 65, 66, 66, 61, 38, 36, 45, 62, 63, 59, 68, 57, 60, 63, 61, 57, 60, 49, 61, 54, 62, 50, 61, 60, 57, 57, 47, 31, 61, 61, 59, 60, 59, 60, 69, 64, 66, 66, 67, 42, 60, 60, 57, 67, 44, 56, 54, 59, 57, 61, 33, 58, 61, 65, 71, 71, 71, 71, 70, 38, 38, 31, 31, 34, 32, 31, 62, 46, 42, 59, 63, 61, 62, 57, 47, 56, 51, 57, 59, 42, 43, 29, 44, 60, 58, 60, 59, 30, 35, 34, 42, 60, 62, 62, 65, 61, 60, 62, 68, 31, 35, 51, 42, 40, 61, 38, 62, 60, 63, 60, 70, 68, 70, 68, 63, 61, 61, 58, 60, 63, 68, 57, 53, 61, 61, 61, 61, 67, 61, 66, 62, 64, 62, 60, 61, 61, 46, 62, 69, 59, 64, 66, 44, 46, 61, 60, 42, 43, 38, 39, 38, 38, 38, 35, 61, 62, 61, 47, 58, 44, 62, 60, 59, 29, 31, 35, 35, 35, 35, 29, 30, 61, 30, 30, 31, 30, 31, 30, 31, 32, 31, 32, 62, 63, 64, 58, 60, 60, 48, 62, 61, 61, 62, 59, 61, 41, 67, 67, 67, 68, 61, 61, 58, 51, 58, 60, 61, 68, 68, 55, 51, 65, 70, 60, 61, 29, 37, 29, 30, 29, 30, 29, 31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnvIk_wZy-PD"
      },
      "source": [
        "import os\n",
        "#目的のCSVに記載\n",
        "df_dst.iloc[3,1] = \"7_60004\"\n",
        "df_dst.iloc[4,1] = \"北口善之\"\n",
        "df_dst.iloc[7:408, 1] = predictive_results\n",
        "\n",
        "df_dst.to_csv(os.path.splitext(dst_path)[0]+\"20211028GB_concat\"+\".csv\", encoding='utf_8_sig')\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp69lCxaTN8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}