{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled69.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1JnO8G8KM3eaL7zL7IrR7NU-Q2MllCCtk",
      "authorship_tag": "ABX9TyNm6p5iE+L3sKHE+IIY5eca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/RandomForest_and_XGBoost_1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOmIegf1c6s",
        "outputId": "a1de4fe1-5c8b-4a5d-f259-3c98ab746514"
      },
      "source": [
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNbbDfQ5lid"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/result_5_GaussianBlur.csv\", index_col=0, sep=\",\")\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mqY5TnHxuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f019c3f4-5bb2-4723-bcb7-d972fe3b3552"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df.columns.values[3:].tolist()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cropped_2_A2_GaussianBlur_pretrained_2', 'cropped_2_A2_GaussianBlur_pretrained_3', 'cropped_2_A2_GaussianBlur_pretrained_4', 'disc_2_A2_GaussianBlur_pretrained_0', 'disc_2_A2_GaussianBlur_pretrained_1', 'disc_2_A2_GaussianBlur_pretrained_2', 'disc_2_A2_GaussianBlur_pretrained_3', 'disc_2_A2_GaussianBlur_pretrained_4', 'macula_2_A2_GaussianBlur_pretrained_0', 'macula_2_A2_GaussianBlur_pretrained_1', 'macula_2_A2_GaussianBlur_pretrained_2', 'macula_2_A2_GaussianBlur_pretrained_3', 'macula_2_A2_GaussianBlur_pretrained_4', 'cropped_2_B3_GaussianBlur_pretrained_0', 'cropped_2_B3_GaussianBlur_pretrained_1', 'cropped_2_B3_GaussianBlur_pretrained_2', 'cropped_2_B3_GaussianBlur_pretrained_3', 'cropped_2_B3_GaussianBlur_pretrained_4', 'disc_2_B3_GaussianBlur_pretrained_0', 'disc_2_B3_GaussianBlur_pretrained_1', 'disc_2_B3_GaussianBlur_pretrained_2', 'disc_2_B3_GaussianBlur_pretrained_3', 'disc_2_B3_GaussianBlur_pretrained_4', 'macula_2_B3_GaussianBlur_pretrained_0', 'macula_2_B3_GaussianBlur_pretrained_1', 'macula_2_B3_GaussianBlur_pretrained_2', 'macula_2_B3_GaussianBlur_pretrained_3', 'macula_2_B3_GaussianBlur_pretrained_4', 'vascular_2_RGB_B3_GaussianBlur_pretrained_0', 'vascular_2_RGB_B3_GaussianBlur_pretrained_1', 'vascular_2_RGB_B3_GaussianBlur_pretrained_2', 'vascular_2_RGB_B3_GaussianBlur_pretrained_3', 'vascular_2_RGB_B3_GaussianBlur_pretrained_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzK-7A7RRXiu"
      },
      "source": [
        "#**Prediction accuracy for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZej9BelRsro"
      },
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"age\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"age\"]\n",
        "    print(str(i))\n",
        "    get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    print(\"\")\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS]\n",
        "Y_train = train[\"age\"]\n",
        "X_test = test[FEATURE_COLS]\n",
        "Y_test = test[\"age\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpy4m8XyRKtV"
      },
      "source": [
        "#**Analysis using XGBoost**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/12/07/000022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20JJ1H4Nmva"
      },
      "source": [
        "# Grid Search用のパラメータ作成。\n",
        "# あまり組み合わせが多いと時間がかかる(time consuming)\n",
        "params = {\n",
        "        'eta': [0.01],             # default = 0.3      \n",
        "        'gamma': [1,2,3],            # default = 0\n",
        "        'max_depth': [7,8,9],      # default = 6\n",
        "        'min_child_weight': [1],   # default = 1\n",
        "        'subsample': [0.8,1.0],        # default = 1\n",
        "        'colsample_bytree': [0.8,1.0], # default = 1\n",
        "        }\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 1)\n",
        "\n",
        "#最適解探索\n",
        "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, scoring='neg_mean_squared_error', n_jobs=2, cv=kf.split(X_train,Y_train), verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXBzlSIrNu3u"
      },
      "source": [
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d966OQgNzX9",
        "outputId": "3aa488df-84d6-4b4d-f3a8-e621e067d269"
      },
      "source": [
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('adjusted_r2(train)     :0.999519816795176',\n",
              " 'adjusted_r2(test)      :0.9935622299415179',\n",
              " '平均誤差率(test)       :0.015283037038344357',\n",
              " 'MAE(test)              :0.79829185000578',\n",
              " 'MedianAE(test)         :0.5349807739257812',\n",
              " 'RMSE(test)             :1.1513165978291806',\n",
              " 'RMSE(test) / MAE(test) :1.4422251684278684')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wq2xWzPPEln"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=bestmodel.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"CMEDV\")\n",
        "ax.set_ylabel(u\"(Predicted) CMEDV\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AseFYOzD8mV7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = bestmodel.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIobiMOEPGKc"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='gain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnbP5EF_6pc9"
      },
      "source": [
        "xgb.plot_importance(bestmodel, importance_type='weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpEpFczPHkK"
      },
      "source": [
        "xgb.to_graphviz(bestmodel, num_trees=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-Kj_RHRQ-9"
      },
      "source": [
        "#**Analysis using RandomForest**\n",
        "https://hinomaruc.hatenablog.com/entry/2019/11/14/200857"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSyqmEyGRfHU"
      },
      "source": [
        "#Create model\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=10)\n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\"\"\"\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "           oob_score=False, random_state=2525, verbose=0, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "def get_model_result(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW6HVmKTUWsB"
      },
      "source": [
        "#Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(X_train,Y_train)\n",
        "\n",
        "\n",
        "\n",
        "print('ベストスコア:',grid.best_score_, sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストestimator:',grid.best_estimator_,sep=\"\\n\")\n",
        "print('\\n')\n",
        "print('ベストparams:',grid.best_params_,sep=\"\\n\")\n",
        "\n",
        "print(pd.DataFrame(grid.cv_results_))\n",
        "\n",
        "# Grid Searchで一番精度が良かったモデル\n",
        "bestmodel = grid.best_estimator_\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,bestmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkW5oubR4MJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), features[indices])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "feature_importances = pd.DataFrame([features, importances]).T\n",
        "feature_importances.columns = ['features', 'importances']\n",
        "df_s = feature_importances.sort_values('importances', ascending=False).reset_index(drop=True)\n",
        "df_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rci5gcXQQ9XG"
      },
      "source": [
        "\"\"\"\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title('Importances')\n",
        "plt.rcParams['font.size']=10\n",
        "sns.barplot(y='features', x='importances', data=df_s, palette='viridis')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DihmVVSbKI"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3Qw-hrjFi-"
      },
      "source": [
        "#**Analysis using neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwwcmwczMwfE"
      },
      "source": [
        "#正規化する\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#モデル作成\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "model = MLPRegressor(alpha=0.1, hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive', max_iter=500, random_state=42, solver=\"lbfgs\", early_stopping=True) \n",
        "model.fit(X_train,Y_train) \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "初期設定：\n",
        "\n",
        "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
        "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
        "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
        "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
        "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
        "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
        "       verbose=False, warm_start=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y,model):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, model.predict(X))\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-X.shape[1]-1)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test,model):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return \"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train,model)) \\\n",
        "         , \"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test,model)) \\\n",
        "         , \"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1))) \\\n",
        "         , \"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)) \\\n",
        "         , \"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))) \\\n",
        "         , \"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test)) #better if result = 1.253\n",
        "\n",
        "get_model_evaluations(X_train,Y_train,X_test,Y_test,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcqR8-Nj1E9"
      },
      "source": [
        "# 描画設定\n",
        "from matplotlib import rcParams\n",
        "rcParams['xtick.labelsize'] = 12       # x軸のラベルのフォントサイズ\n",
        "rcParams['ytick.labelsize'] = 12       # y軸のラベルのフォントサイズ\n",
        "rcParams['figure.figsize'] = 8,8      # 画像サイズの変更(inch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "sns.set_style(\"whitegrid\")             # seabornのスタイルセットの一つ\n",
        "sns.set_color_codes()                  # デフォルトカラー設定 (deepになってる)\n",
        "\n",
        "plt.figure()\n",
        "ax = sns.regplot(x=Y_test, y=model.predict(X_test), fit_reg=False,color='#4F81BD')\n",
        "ax.set_xlabel(u\"True Age\")\n",
        "ax.set_ylabel(u\"Predicted Age\")\n",
        "ax.get_xaxis().set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
        "ax.plot([0,10,20,30,40,50],[0,10,20,30,40,50], linewidth=2, color=\"#C0504D\",ls=\"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlExOBk8fCoE"
      },
      "source": [
        "#**Predict age from test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zC8VftCfIcr"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "b8L_f0Qdq17-",
        "outputId": "dd67cc88-b107-4ba4-924f-f4449dabc599"
      },
      "source": [
        "import sys\n",
        "\n",
        "#評価用ファイルの呼び出し\n",
        "df_dst = pd.read_csv(\"/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム.csv\", index_col=0, sep=\",\")\n",
        "df_dst\n",
        "\n",
        "index = df_dst.iloc[7:407,0] #画像名リスト\n",
        "cols = df.columns #modelリスト\n",
        "\n",
        "df_temp = pd.DataFrame(index=index, columns=cols)\n",
        "df_temp\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img76901008_06_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_06_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_2L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img77009741_01_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962790_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962800_00_1L</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962810_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962820_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962830_00_1R</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   age  ... vascular_2_RGB_B3_GaussianBlur_pretrained_4\n",
              "Unnamed: 1              ...                                            \n",
              "img76901008_06_1R  NaN  ...                                         NaN\n",
              "img76901008_06_2L  NaN  ...                                         NaN\n",
              "img76901008_07_1R  NaN  ...                                         NaN\n",
              "img76901008_07_2L  NaN  ...                                         NaN\n",
              "img77009741_01_1R  NaN  ...                                         NaN\n",
              "...                ...  ...                                         ...\n",
              "img99962790_00_1R  NaN  ...                                         NaN\n",
              "img99962800_00_1L  NaN  ...                                         NaN\n",
              "img99962810_00_1R  NaN  ...                                         NaN\n",
              "img99962820_00_1R  NaN  ...                                         NaN\n",
              "img99962830_00_1R  NaN  ...                                         NaN\n",
              "\n",
              "[400 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGbfrHokrOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a75cf2-d451-4caf-928a-5405772f9e7c"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "#!pip install adabelief-pytorch==0.1.0\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "\"\"\"\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\"\"\"\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入##########改変要\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df_temp.loc[df_temp.index.str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "class Select_dataset:\n",
        "    \"\"\"\n",
        "    「name = cropped_CLAHE_A2_pretrained_2」\n",
        "    からモデルのダウンロードとdatasetの選択を行う\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.preprocess = \"\"\n",
        "        self.part = \"\"\n",
        "        self.DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "        self.dst_path = \"\"\n",
        "\n",
        "    def select_preprocess(self):\n",
        "        if \"CLAHE\" in self.name:\n",
        "            self.preprocess = \"_CLAHE\"\n",
        "        else:\n",
        "            self.preprocess = \"\"\n",
        "    \n",
        "    def select_part(self):\n",
        "        if \"disc\" in self.name:\n",
        "            self.part = \"disc\"\n",
        "        elif \"macula\" in self.name:\n",
        "            self.part = \"macula\"\n",
        "        else:\n",
        "            self.part = \"cropped\"\n",
        "\n",
        "    def output_dataset(self):\n",
        "        self.dst_path = self.DATASET_PATH + \"/test_\"+ self.part + self.preprocess +\"_img\"\n",
        "        return self.dst_path\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
            "Requirement already satisfied: ranger-adabelief==0.1.0 in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger-adabelief==0.1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (3.7.4.3)\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-7850782a-c993-8077-756c-80732f74f99a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmiqljhz02F"
      },
      "source": [
        "import glob\n",
        "\n",
        "model_size = \"\"\n",
        "preprocess = \"\"\n",
        "for i in cols[1:]: #modelごとに結果を出す\n",
        "    print(i)\n",
        "    \n",
        "    if \"A2\" in i:\n",
        "        model_size_temp = \"A2\"\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    elif \"B3\" in i:\n",
        "        model_size_temp = \"B3\"\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        model_ft =  mod_RepVGG()\n",
        "    else:\n",
        "        print(\"A2あるいはB3で指定して下さい\")\n",
        "        sys.exit(1)\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/FundusPhoto/model/'+str(i)+\".pth\"))\n",
        "    model_ft.to(device)\n",
        "    \n",
        "    select_dataset = Select_dataset(i)\n",
        "    select_dataset.select_preprocess()\n",
        "    select_dataset.select_part()\n",
        "    data_path = select_dataset.output_dataset()\n",
        "\n",
        "    data_path = glob.glob(data_path+\"/*\")\n",
        "    print(data_path)\n",
        "\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        print(j)\n",
        "        #print(os.path.splitext(os.path.basename(m))[0])\n",
        "        #image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "        image_name = os.path.splitext(os.path.basename(j))[0]\n",
        "        image_tensor = image_transform(j)  #予測のための画像下処理\n",
        "        pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "        write_result(df_temp, image_name, pred, str(i))\n",
        "        #print(str(k)+\"/\"+str(len(df_temp)) + \" images processed! pred: \"+str(pred))\n",
        "        k+=1\n",
        "df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3Jw9LPgEgu"
      },
      "source": [
        "df_temp.to_csv('/content/drive/MyDrive/Deep_learning/FundusPhoto/【眼科AIコンテスト】本番用データ提出フォーム_result_5.csv', encoding='utf_8_sig')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-eMHoKHnIsX",
        "outputId": "5930dd2a-8db3-46de-a5f2-ec269f11c9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_A2_GaussianBlur_pretrained_4</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>cropped_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>disc_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>macula_2_B3_GaussianBlur_pretrained_4</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_0</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_1</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_2</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_3</th>\n",
              "      <th>vascular_2_RGB_B3_GaussianBlur_pretrained_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>img76901008_06_1R</th>\n",
              "      <td>64.328</td>\n",
              "      <td>65.2753</td>\n",
              "      <td>65.7381</td>\n",
              "      <td>69.9623</td>\n",
              "      <td>66.557</td>\n",
              "      <td>59.8738</td>\n",
              "      <td>67.2174</td>\n",
              "      <td>64.7275</td>\n",
              "      <td>62.5567</td>\n",
              "      <td>62.7894</td>\n",
              "      <td>56.721</td>\n",
              "      <td>63.1203</td>\n",
              "      <td>60.6983</td>\n",
              "      <td>64.4756</td>\n",
              "      <td>56.6755</td>\n",
              "      <td>62.7821</td>\n",
              "      <td>68.2769</td>\n",
              "      <td>72.4198</td>\n",
              "      <td>69.8063</td>\n",
              "      <td>64.9783</td>\n",
              "      <td>66.8128</td>\n",
              "      <td>66.1782</td>\n",
              "      <td>66.2617</td>\n",
              "      <td>61.5974</td>\n",
              "      <td>65.0738</td>\n",
              "      <td>67.0684</td>\n",
              "      <td>64.9797</td>\n",
              "      <td>61.7556</td>\n",
              "      <td>63.0127</td>\n",
              "      <td>62.843</td>\n",
              "      <td>57.357</td>\n",
              "      <td>62.0691</td>\n",
              "      <td>54.5635</td>\n",
              "      <td>54.1628</td>\n",
              "      <td>61.2444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_06_2L</th>\n",
              "      <td>64.3925</td>\n",
              "      <td>63.2253</td>\n",
              "      <td>68.8811</td>\n",
              "      <td>69.4216</td>\n",
              "      <td>67.365</td>\n",
              "      <td>63.5673</td>\n",
              "      <td>65.7667</td>\n",
              "      <td>62.8149</td>\n",
              "      <td>63.6209</td>\n",
              "      <td>64.1283</td>\n",
              "      <td>61.5125</td>\n",
              "      <td>63.4276</td>\n",
              "      <td>61.9507</td>\n",
              "      <td>63.2903</td>\n",
              "      <td>49.6284</td>\n",
              "      <td>62.9903</td>\n",
              "      <td>66.7851</td>\n",
              "      <td>70.7976</td>\n",
              "      <td>67.9981</td>\n",
              "      <td>64.6697</td>\n",
              "      <td>66.5422</td>\n",
              "      <td>65.1295</td>\n",
              "      <td>64.0213</td>\n",
              "      <td>63.3178</td>\n",
              "      <td>66.5517</td>\n",
              "      <td>63.4389</td>\n",
              "      <td>62.3443</td>\n",
              "      <td>60.6468</td>\n",
              "      <td>62.4902</td>\n",
              "      <td>64.3054</td>\n",
              "      <td>53.2443</td>\n",
              "      <td>61.5416</td>\n",
              "      <td>51.7881</td>\n",
              "      <td>55.0922</td>\n",
              "      <td>57.4353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_1R</th>\n",
              "      <td>64.5158</td>\n",
              "      <td>65.4376</td>\n",
              "      <td>67.2894</td>\n",
              "      <td>69.0458</td>\n",
              "      <td>65.2166</td>\n",
              "      <td>59.8298</td>\n",
              "      <td>68.1809</td>\n",
              "      <td>64.6935</td>\n",
              "      <td>62.3264</td>\n",
              "      <td>61.6005</td>\n",
              "      <td>54.9972</td>\n",
              "      <td>62.5085</td>\n",
              "      <td>60.3612</td>\n",
              "      <td>61.1067</td>\n",
              "      <td>53.505</td>\n",
              "      <td>62.2667</td>\n",
              "      <td>65.0073</td>\n",
              "      <td>72.1348</td>\n",
              "      <td>67.6866</td>\n",
              "      <td>64.2876</td>\n",
              "      <td>65.6708</td>\n",
              "      <td>66.9597</td>\n",
              "      <td>65.7677</td>\n",
              "      <td>62.9983</td>\n",
              "      <td>64.8363</td>\n",
              "      <td>64.7576</td>\n",
              "      <td>63.1945</td>\n",
              "      <td>61.4843</td>\n",
              "      <td>64.0146</td>\n",
              "      <td>61.6442</td>\n",
              "      <td>50.1211</td>\n",
              "      <td>60.6532</td>\n",
              "      <td>52.4083</td>\n",
              "      <td>54.1735</td>\n",
              "      <td>56.6585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img76901008_07_2L</th>\n",
              "      <td>64.19</td>\n",
              "      <td>61.3358</td>\n",
              "      <td>67.1958</td>\n",
              "      <td>65.4612</td>\n",
              "      <td>67.117</td>\n",
              "      <td>63.0195</td>\n",
              "      <td>67.4157</td>\n",
              "      <td>65.4643</td>\n",
              "      <td>63.6042</td>\n",
              "      <td>64.7498</td>\n",
              "      <td>62.1044</td>\n",
              "      <td>65.6733</td>\n",
              "      <td>61.1765</td>\n",
              "      <td>63.8012</td>\n",
              "      <td>48.3604</td>\n",
              "      <td>63.1098</td>\n",
              "      <td>65.9346</td>\n",
              "      <td>68.0221</td>\n",
              "      <td>66.8583</td>\n",
              "      <td>64.4492</td>\n",
              "      <td>67.9623</td>\n",
              "      <td>64.8329</td>\n",
              "      <td>61.943</td>\n",
              "      <td>62.6039</td>\n",
              "      <td>67.0516</td>\n",
              "      <td>66.4913</td>\n",
              "      <td>65.1031</td>\n",
              "      <td>61.204</td>\n",
              "      <td>62.4109</td>\n",
              "      <td>66.62</td>\n",
              "      <td>53.6835</td>\n",
              "      <td>60.7543</td>\n",
              "      <td>50.4871</td>\n",
              "      <td>54.6796</td>\n",
              "      <td>56.8334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img77009741_01_1R</th>\n",
              "      <td>52.5857</td>\n",
              "      <td>47.4697</td>\n",
              "      <td>38.8343</td>\n",
              "      <td>44.2703</td>\n",
              "      <td>51.9229</td>\n",
              "      <td>46.5006</td>\n",
              "      <td>41.4523</td>\n",
              "      <td>38.8991</td>\n",
              "      <td>55.1931</td>\n",
              "      <td>41.4991</td>\n",
              "      <td>39.1346</td>\n",
              "      <td>42.545</td>\n",
              "      <td>49.394</td>\n",
              "      <td>45.4565</td>\n",
              "      <td>41.9883</td>\n",
              "      <td>46.3112</td>\n",
              "      <td>46.7</td>\n",
              "      <td>43.4624</td>\n",
              "      <td>40.0323</td>\n",
              "      <td>58.4112</td>\n",
              "      <td>49.6565</td>\n",
              "      <td>46.461</td>\n",
              "      <td>49.4135</td>\n",
              "      <td>49.2915</td>\n",
              "      <td>55.7587</td>\n",
              "      <td>45.4826</td>\n",
              "      <td>52.9361</td>\n",
              "      <td>53.1113</td>\n",
              "      <td>53.379</td>\n",
              "      <td>56.2938</td>\n",
              "      <td>44.7818</td>\n",
              "      <td>54.118</td>\n",
              "      <td>53.7639</td>\n",
              "      <td>55.7227</td>\n",
              "      <td>51.8576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962790_00_1R</th>\n",
              "      <td>31.8044</td>\n",
              "      <td>30.7122</td>\n",
              "      <td>26.997</td>\n",
              "      <td>30.2793</td>\n",
              "      <td>33.0143</td>\n",
              "      <td>43.6807</td>\n",
              "      <td>22.2</td>\n",
              "      <td>28.448</td>\n",
              "      <td>35.671</td>\n",
              "      <td>40.8811</td>\n",
              "      <td>32.8492</td>\n",
              "      <td>37.6203</td>\n",
              "      <td>34.1763</td>\n",
              "      <td>34.8982</td>\n",
              "      <td>35.2284</td>\n",
              "      <td>35.8558</td>\n",
              "      <td>36.5666</td>\n",
              "      <td>31.1195</td>\n",
              "      <td>31.7431</td>\n",
              "      <td>37.0986</td>\n",
              "      <td>40.3018</td>\n",
              "      <td>40.7381</td>\n",
              "      <td>36.7378</td>\n",
              "      <td>44.2393</td>\n",
              "      <td>32.8616</td>\n",
              "      <td>30.9074</td>\n",
              "      <td>40.7837</td>\n",
              "      <td>38.9607</td>\n",
              "      <td>42.6047</td>\n",
              "      <td>45.2461</td>\n",
              "      <td>44.8208</td>\n",
              "      <td>55.6277</td>\n",
              "      <td>53.8298</td>\n",
              "      <td>53.3044</td>\n",
              "      <td>55.6983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962800_00_1L</th>\n",
              "      <td>30.7482</td>\n",
              "      <td>32.9219</td>\n",
              "      <td>26.519</td>\n",
              "      <td>30.8323</td>\n",
              "      <td>36.1355</td>\n",
              "      <td>39.422</td>\n",
              "      <td>31.9886</td>\n",
              "      <td>31.4705</td>\n",
              "      <td>42.4812</td>\n",
              "      <td>42.1675</td>\n",
              "      <td>37.3365</td>\n",
              "      <td>35.6805</td>\n",
              "      <td>35.4879</td>\n",
              "      <td>36.8462</td>\n",
              "      <td>33.36</td>\n",
              "      <td>36.3723</td>\n",
              "      <td>37.8154</td>\n",
              "      <td>30.3673</td>\n",
              "      <td>30.5998</td>\n",
              "      <td>45.2218</td>\n",
              "      <td>39.0256</td>\n",
              "      <td>43.4761</td>\n",
              "      <td>38.7982</td>\n",
              "      <td>50.6227</td>\n",
              "      <td>35.4412</td>\n",
              "      <td>32.2052</td>\n",
              "      <td>39.7582</td>\n",
              "      <td>36.6195</td>\n",
              "      <td>44.0242</td>\n",
              "      <td>44.2194</td>\n",
              "      <td>50.7572</td>\n",
              "      <td>52.3072</td>\n",
              "      <td>52.5478</td>\n",
              "      <td>54.1212</td>\n",
              "      <td>53.4268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962810_00_1R</th>\n",
              "      <td>31.1202</td>\n",
              "      <td>32.0284</td>\n",
              "      <td>25.8808</td>\n",
              "      <td>30.6632</td>\n",
              "      <td>36.5641</td>\n",
              "      <td>41.3123</td>\n",
              "      <td>28.9724</td>\n",
              "      <td>31.0496</td>\n",
              "      <td>38.9981</td>\n",
              "      <td>43.9221</td>\n",
              "      <td>38.3281</td>\n",
              "      <td>33.6329</td>\n",
              "      <td>36.1467</td>\n",
              "      <td>35.2195</td>\n",
              "      <td>26.1516</td>\n",
              "      <td>33.9592</td>\n",
              "      <td>35.8811</td>\n",
              "      <td>30.7761</td>\n",
              "      <td>30.9631</td>\n",
              "      <td>36.1276</td>\n",
              "      <td>38.4623</td>\n",
              "      <td>40.6253</td>\n",
              "      <td>36.229</td>\n",
              "      <td>46.5355</td>\n",
              "      <td>34.8578</td>\n",
              "      <td>33.312</td>\n",
              "      <td>35.2708</td>\n",
              "      <td>34.8864</td>\n",
              "      <td>42.0231</td>\n",
              "      <td>40.0244</td>\n",
              "      <td>50.2898</td>\n",
              "      <td>54.9954</td>\n",
              "      <td>51.7415</td>\n",
              "      <td>54.7413</td>\n",
              "      <td>51.6813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962820_00_1R</th>\n",
              "      <td>32.769</td>\n",
              "      <td>31.6908</td>\n",
              "      <td>28.5691</td>\n",
              "      <td>32.1689</td>\n",
              "      <td>33.0168</td>\n",
              "      <td>44.9759</td>\n",
              "      <td>24.4489</td>\n",
              "      <td>26.3977</td>\n",
              "      <td>35.0818</td>\n",
              "      <td>40.7266</td>\n",
              "      <td>38.0796</td>\n",
              "      <td>38.6605</td>\n",
              "      <td>36.5424</td>\n",
              "      <td>34.6788</td>\n",
              "      <td>37.8834</td>\n",
              "      <td>36.0419</td>\n",
              "      <td>36.8318</td>\n",
              "      <td>31.8481</td>\n",
              "      <td>31.8416</td>\n",
              "      <td>38.2334</td>\n",
              "      <td>36.1154</td>\n",
              "      <td>39.0642</td>\n",
              "      <td>39.1646</td>\n",
              "      <td>43.7497</td>\n",
              "      <td>33.2054</td>\n",
              "      <td>30.6591</td>\n",
              "      <td>37.4845</td>\n",
              "      <td>40.058</td>\n",
              "      <td>41.6194</td>\n",
              "      <td>44.0163</td>\n",
              "      <td>50.2518</td>\n",
              "      <td>60.1867</td>\n",
              "      <td>53.6891</td>\n",
              "      <td>53.0785</td>\n",
              "      <td>54.9272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>img99962830_00_1R</th>\n",
              "      <td>31.1436</td>\n",
              "      <td>31.1356</td>\n",
              "      <td>24.9834</td>\n",
              "      <td>30.6542</td>\n",
              "      <td>32.4025</td>\n",
              "      <td>44.4821</td>\n",
              "      <td>31.5723</td>\n",
              "      <td>30.9589</td>\n",
              "      <td>38.4208</td>\n",
              "      <td>44.5832</td>\n",
              "      <td>34.5738</td>\n",
              "      <td>37.4836</td>\n",
              "      <td>34.2948</td>\n",
              "      <td>36.4286</td>\n",
              "      <td>33.9141</td>\n",
              "      <td>35.251</td>\n",
              "      <td>35.3761</td>\n",
              "      <td>30.6507</td>\n",
              "      <td>30.5046</td>\n",
              "      <td>38.9639</td>\n",
              "      <td>36.2199</td>\n",
              "      <td>40.4931</td>\n",
              "      <td>35.6551</td>\n",
              "      <td>44.5004</td>\n",
              "      <td>33.6637</td>\n",
              "      <td>31.8485</td>\n",
              "      <td>39.2566</td>\n",
              "      <td>39.4276</td>\n",
              "      <td>44.324</td>\n",
              "      <td>45.1161</td>\n",
              "      <td>42.5368</td>\n",
              "      <td>52.3033</td>\n",
              "      <td>54.8822</td>\n",
              "      <td>53.5313</td>\n",
              "      <td>49.0361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  cropped_2_A2_GaussianBlur_pretrained_0  ... vascular_2_RGB_B3_GaussianBlur_pretrained_4\n",
              "Unnamed: 1                                                ...                                            \n",
              "img76901008_06_1R                                 64.328  ...                                     61.2444\n",
              "img76901008_06_2L                                64.3925  ...                                     57.4353\n",
              "img76901008_07_1R                                64.5158  ...                                     56.6585\n",
              "img76901008_07_2L                                  64.19  ...                                     56.8334\n",
              "img77009741_01_1R                                52.5857  ...                                     51.8576\n",
              "...                                                  ...  ...                                         ...\n",
              "img99962790_00_1R                                31.8044  ...                                     55.6983\n",
              "img99962800_00_1L                                30.7482  ...                                     53.4268\n",
              "img99962810_00_1R                                31.1202  ...                                     51.6813\n",
              "img99962820_00_1R                                 32.769  ...                                     54.9272\n",
              "img99962830_00_1R                                31.1436  ...                                     49.0361\n",
              "\n",
              "[400 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "w0Jp4BqEhnKe",
        "outputId": "061a4f32-d96a-4119-a4c4-cf7ea4b2de8b"
      },
      "source": [
        "#XGBoostのベストモデルを用いて予測をする\n",
        "def get_model_result(X_test, model):\n",
        "    yhat_test = model.predict(X_test)\n",
        "    return yhat_test\n",
        "\n",
        "FEATURE_COLS=df_temp.columns.values[1:].tolist()\n",
        "X_test = df_temp[FEATURE_COLS]\n",
        "Y_test = df_temp[\"age\"]\n",
        "\n",
        "bestmodel = grid.best_estimator_\n",
        "predictive_results = get_model_result(X_test, bestmodel)\n",
        "print(predictive_results)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-2a57c28a46af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbestmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredictive_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictive_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-2a57c28a46af>\u001b[0m in \u001b[0;36mget_model_result\u001b[0;34m(X_test, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#XGBoostのベストモデルを用いて予測をする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0myhat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0myhat_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# pylint: disable=missing-docstring,invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mtest_dmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;31m# get ntree_limit to use - if none specified, default to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# best_ntree_limit if defined, otherwise 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    378\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    379\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    237\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    238\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields cropped_2_A2_GaussianBlur_pretrained_0, cropped_2_A2_GaussianBlur_pretrained_1, cropped_2_A2_GaussianBlur_pretrained_2, cropped_2_A2_GaussianBlur_pretrained_3, cropped_2_A2_GaussianBlur_pretrained_4, disc_2_A2_GaussianBlur_pretrained_0, disc_2_A2_GaussianBlur_pretrained_1, disc_2_A2_GaussianBlur_pretrained_2, disc_2_A2_GaussianBlur_pretrained_3, disc_2_A2_GaussianBlur_pretrained_4, macula_2_A2_GaussianBlur_pretrained_0, macula_2_A2_GaussianBlur_pretrained_1, macula_2_A2_GaussianBlur_pretrained_2, macula_2_A2_GaussianBlur_pretrained_3, macula_2_A2_GaussianBlur_pretrained_4, cropped_2_B3_GaussianBlur_pretrained_0, cropped_2_B3_GaussianBlur_pretrained_1, cropped_2_B3_GaussianBlur_pretrained_2, cropped_2_B3_GaussianBlur_pretrained_3, cropped_2_B3_GaussianBlur_pretrained_4, disc_2_B3_GaussianBlur_pretrained_0, disc_2_B3_GaussianBlur_pretrained_1, disc_2_B3_GaussianBlur_pretrained_2, disc_2_B3_GaussianBlur_pretrained_3, disc_2_B3_GaussianBlur_pretrained_4, macula_2_B3_GaussianBlur_pretrained_0, macula_2_B3_GaussianBlur_pretrained_1, macula_2_B3_GaussianBlur_pretrained_2, macula_2_B3_GaussianBlur_pretrained_3, macula_2_B3_GaussianBlur_pretrained_4, vascular_2_RGB_B3_GaussianBlur_pretrained_0, vascular_2_RGB_B3_GaussianBlur_pretrained_1, vascular_2_RGB_B3_GaussianBlur_pretrained_2, vascular_2_RGB_B3_GaussianBlur_pretrained_3, vascular_2_RGB_B3_GaussianBlur_pretrained_4"
          ]
        }
      ]
    }
  ]
}