{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled90.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/FundusPhoto_crossvalidation1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4vbMuKXy9W6",
        "outputId": "a3aa6e69-53ec-4eee-da56-929b145dc2f5"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.1.0-py3-none-any.whl (72 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 71 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.1.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-0de48276-9dd3-0e79-fc02-c36e6bc71abb)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "lV9UyGl4BL3c",
        "outputId": "247f41e3-3ee4-4e35-e288-595568b98209"
      },
      "source": [
        "name = \"cropped_2\"\n",
        "model = \"A2\"\n",
        "\n",
        "MODEL_NAME = name +\"_\"+model+\"_pretrained\"\n",
        "DATASET_NAME = name+'_img_trainval'\n",
        "DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "NET_NAME = \"RepVGG_\" +model  #RepVGG_A2 or RepVGG_B3\n",
        "PRETRAINED = True\n",
        "\n",
        "os.chdir(DATASET_PATH)\n",
        "\n",
        "TRAIN_FOLDER_NAME = 'train' #TRAINイメージのフォルダ\n",
        "VAL_FOLDER_NAME = 'val' #VALイメージのフォルダ\n",
        "\n",
        "FILENAME_LABELCSV = 'name_age.csv' #年齢の値のcsv\n",
        "FILENAME_RESULTCSV = 'result_2.csv' #年齢推定結果を書き出すcsv\n",
        "FILENAME_RESULT_ANALYSISCSV = 'result_analysis_2.csv' #推定結果の解析結果を書き出すcsv\n",
        "\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto/model'\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "LOG_PATH = \"./log_multi.txt\"\n",
        "ROC_PATH = \"./roc_multi.png\"\n",
        "CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "PATIENCE = 20 #early stopping patience; how long to wait after last time validation loss improved.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "\n",
        "# transforms param\n",
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.75,1.0)\n",
        "TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "TRAIN_CONTRAST_PARAM = 0.1\n",
        "TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "\n",
        "#csvファイルを開く\n",
        "df_labelcsv = pd.read_csv(FILENAME_LABELCSV)\n",
        "\n",
        "#csvファイルを表示\n",
        "print(df_labelcsv)\n",
        "\n",
        "#ID,ageの列の値をリストとして取り出す\n",
        "df_filename = df_labelcsv['filename'].values\n",
        "df_age = df_labelcsv['age'].values\n",
        "\n",
        "#CSVファイル内の画像数\n",
        "print(len(df_labelcsv))\n",
        "\n",
        "\"\"\"\n",
        "#画像フォルダ内の画像数\n",
        "print(len(os.listdir(DATASET_NAME +\"/\"+ TRAIN_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_NAME +\"/\"+ VAL_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_NAME +\"/\"+ TEST_FOLDER_NAME)))\n",
        "\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   filename  age\n",
            "0     img00085008_00_1R.jpg   61\n",
            "1     img00085024_00_1R.jpg   29\n",
            "2     img00241280_10_1R.jpg   51\n",
            "3     img00265140_00_1R.jpg   29\n",
            "4     img00265140_00_2L.jpg   29\n",
            "...                     ...  ...\n",
            "1409  img76791392_10_1R.jpg   38\n",
            "1410  img76843122_10_1R.jpg   49\n",
            "1411  img76843122_11_1R.jpg   49\n",
            "1412  img76888512_00_1R.jpg   74\n",
            "1413  img76888512_00_2L.jpg   74\n",
            "\n",
            "[1414 rows x 2 columns]\n",
            "1414\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#画像フォルダ内の画像数\\nprint(len(os.listdir(DATASET_NAME +\"/\"+ TRAIN_FOLDER_NAME))\\n+len(os.listdir(DATASET_NAME +\"/\"+ VAL_FOLDER_NAME))\\n+len(os.listdir(DATASET_NAME +\"/\"+ TEST_FOLDER_NAME)))\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ejg4rneA3qI"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srdzPaN3A1nr"
      },
      "source": [
        "####################################\n",
        "#Test with early-stopping\n",
        "####################################\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor)\n",
        "            # calculate the loss\n",
        "            loss = loss_func(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor)\n",
        "            # calculate the loss\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "##################################\n",
        "#Define RepVGG-B3\n",
        "##################################\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "class mod_RepVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(mod_RepVGG, self).__init__()\n",
        "        repVGG = model_ft\n",
        "        num_ftrs = model_ft.linear.in_features  #in_featureはA2では1408、B3では2560\n",
        "        self.repVGG = nn.Sequential(*list(model_ft.children())[:-1])\n",
        "        self.fc = nn.Linear(in_features=num_ftrs, out_features=1)  #out_featuresを1に\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.repVGG(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "#####################################\n",
        "##### Datasets and Dataloader ############\n",
        "#####################################\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, folder_path, csv_path, transform):\n",
        "        self.transform = transform\n",
        "        self.folder_path = folder_path\n",
        "        self.item_paths = []\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "\n",
        "        for i in range(len(os.listdir(folder_path))):\n",
        "              img_name = os.listdir(self.folder_path)[i]\n",
        "              name = os.path.split(img_name)[0] #拡張子を削除したもの\n",
        "              age_temp = df_labelcsv[df_labelcsv['filename'].str.contains(name)].iloc[0,1] #age\n",
        "              self.age.append(float(age_temp)/100)\n",
        "\n",
        "              img_path = os.path.join(self.folder_path, img_name)\n",
        "              self.item_paths.append(img_path)\n",
        "              #self.item_dict[image_path] = self.age\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.item_paths[idx]\n",
        "        #pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        pilr_image = read_image(image_path)\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor([self.age[idx]])      \n",
        "        return tensor_image, target\n",
        "\n",
        "\n",
        "train_data_transforms = nn.Sequential(\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),\n",
        "                transforms.RandomRotation(degrees=10),\n",
        "                transforms.ConvertImageDtype(torch.float),\n",
        "                ).to(device)\n",
        "val_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),\n",
        "                transforms.ConvertImageDtype(torch.float),\n",
        "                ).to(device)\n",
        "test_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ConvertImageDtype(torch.float),\n",
        "                ).to(device)\n",
        "\n",
        "\"\"\"\n",
        "#水増し後の画像を可視化する関数\n",
        "def show_img(dataset):\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(5):\n",
        "        image, label = dataset[i]\n",
        "        image = image.permute(1, 2, 0)\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
        "        plt.tick_params(bottom=False, left=False, right=False, top=False)\n",
        "        plt.imshow(image)\n",
        "        \n",
        "\n",
        "#画像の可視化\n",
        "show_img(train_dataset)\n",
        "\n",
        "#print(train_dataset[1])\n",
        "\"\"\"\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0] == image_name].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df.loc[df_result.iloc[:,0].str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKFWkJs5zGgb"
      },
      "source": [
        "#**Data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM3zE1Ft0exa"
      },
      "source": [
        "#ここからがメイン\n",
        "process = [0,1,2,3,4]\n",
        "for i in process:\n",
        "    print(\"Start \"+ str(i) + \" th analysis!\")\n",
        "\n",
        "    train_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, \"1\", TRAIN_FOLDER_NAME), FILENAME_LABELCSV, train_data_transforms)\n",
        "    val_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, \"1\", VAL_FOLDER_NAME), FILENAME_LABELCSV,  val_data_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
        "\n",
        "    #print(TRAIN_FOLDER_NAME + \"_dataset_size：\" + str(len(train_dataset)))\n",
        "    #print(VAL_FOLDER_NAME + \"_dataset_size：\" + str(len(val_dataset)))\n",
        "\n",
        "    ####################################\n",
        "    #ConvNetの調整\n",
        "    ####################################\n",
        "\n",
        "    if NET_NAME == \"RepVGG_A2\":\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        if PRETRAINED == True:\n",
        "            model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))\n",
        "            print(\"Pretrained model downloaded\")\n",
        "        elif PRETRAINED == False:\n",
        "            pass\n",
        "        else:\n",
        "            print(\"TrueあるいはFalseで指定して下さい\")\n",
        "            sys.exit(1)\n",
        "\n",
        "    elif NET_NAME == \"RepVGG_B3\":\n",
        "        model_ft = create_RepVGG_B3(deploy=False)\n",
        "        if PRETRAINED == True:\n",
        "            model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-B3-200epochs-train.pth'))\n",
        "            print(\"Pretrained model downloaded\")\n",
        "        elif PRETRAINED == False:\n",
        "            pass\n",
        "        else:\n",
        "            print(\"TrueあるいはFalseで指定して下さい\")\n",
        "            sys.exit(1)\n",
        "    else:\n",
        "        print(\"RepVGG_A2あるいはRepVGG_B3を指定して下さい\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    #model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "    model_ft = mod_RepVGG()\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    loss_func = nn.MSELoss()\n",
        "\n",
        "    #Optimizer\n",
        "    optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "\n",
        "    ####################################\n",
        "    # Train and Save network\n",
        "    ####################################\n",
        "\n",
        "    model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n",
        "\n",
        "    #ネットワークの保存\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    torch.save(model_ft.state_dict(), PATH)\n",
        "\n",
        "    ####################################\n",
        "    # Result Analysis\n",
        "    ####################################\n",
        "\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append((output[0]*100).item())      \n",
        "          targets.append((target[0]*100).item())\n",
        "          #print('estimate R:'+str(my_round(output[0,0].item()))+'mm, L:'+str(my_round(output[0,1].item()))+'mm / target R:'+str(target[0,0].item())+'mm, L:'+str(target[0,1].item())+'mm')\n",
        "\n",
        "          errors.append((output[0]*100).item()-(target[0]*100).item())\n",
        "    \n",
        "    AbsError = [abs(i) for i in errors]\n",
        "    MeanError = str(statistics.mean(errors))\n",
        "    StdError = str(statistics.stdev(errors))\n",
        "    MeanAbsError = str(statistics.mean(AbsError))\n",
        "    StdAbsError = str(statistics.stdev(AbsError))\n",
        "\n",
        "    print('MeanError: '+MeanError)\n",
        "    print('StdError: '+StdError)\n",
        "    print('MeanAbsError: '+MeanAbsError)\n",
        "    print('StdAbsError: '+StdAbsError)\n",
        "\n",
        "    \n",
        "    #result_analysis.csv作成（ファイルがなければ）\n",
        "    if os.path.exists(FILENAME_RESULT_ANALYSISCSV) == False:\n",
        "        columns = []\n",
        "        index = [\"AveError\", \"StdError\", \"AveAbsError\", \"StdAbsError\"]\n",
        "        df_result_analysis = pd.DataFrame(index=index, columns=columns)\n",
        "        df_result_analysis.to_csv(FILENAME_RESULT_ANALYSISCSV)\n",
        "    else:\n",
        "        print(FILENAME_RESULT_ANALYSISCSV + \" already exists!\")\n",
        "\n",
        "    df_result_analysis = pd.read_csv(FILENAME_RESULT_ANALYSISCSV, index_col=0)\n",
        "    df_result_analysis[MODEL_NAME+\"_\"+str(i)] = [MeanError, StdError, MeanAbsError, StdAbsError]\n",
        "\n",
        "\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'.csv'\n",
        "    df_result_analysis.to_csv(FILENAME_RESULT_ANALYSISCSV, index=True)\n",
        "    \n",
        "\n",
        "\n",
        "    #result.csv作成（ファイルがなければ）\n",
        "    if os.path.exists(FILENAME_RESULTCSV) == False:\n",
        "        df_result = df_labelcsv.copy()\n",
        "        df_result.to_csv(FILENAME_RESULTCSV)\n",
        "    else:\n",
        "        print(FILENAME_RESULTCSV + \" already exists!\")\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    #print(df_result)\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    #valフォルダ内のファイル名を取得\n",
        "    train_data_path = glob.glob(DATASET_NAME + \"/\" +str(i) + \"/\" + TRAIN_FOLDER_NAME+\"/*\")\n",
        "    val_data_path = glob.glob(DATASET_NAME + \"/\" + str(i) + \"/\" + VAL_FOLDER_NAME+\"/*\")\n",
        "\n",
        "    data_path = [train_data_path, val_data_path]\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        for m in j:\n",
        "              image_name, label = getlabel(df_result, os.path.split(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "              image_tensor = image_transform(m)  #予測のための画像下処理\n",
        "              pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "              write_result(df_result, image_name, pred, MODEL_NAME+\"_\"+str(i))\n",
        "              print(str(k)+\"/\"+str(len(df_result)) + \" images processed! Predicted age is \"+str(pred))\n",
        "              k+=1\n",
        "    #print(df_result)\n",
        "\n",
        "    #Resultファイルを書き出し\n",
        "    df_result.to_csv(FILENAME_RESULTCSV, index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZcTvXUa9hoP",
        "outputId": "bb82f107-f790-46ab-f93d-cffadbdbf9dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data_path = glob.glob(DATASET_NAME + \"/\" +\"1\" + \"/\" + TRAIN_FOLDER_NAME+\"/*\")\n",
        "print(train_data_path)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cropped_img_trainval/1/train/img33333060_05_1R.jpg', 'cropped_img_trainval/1/train/img36161200_01_2L.jpg', 'cropped_img_trainval/1/train/img52791132_00_1R.jpg', 'cropped_img_trainval/1/train/img07866713_04_2L.jpg', 'cropped_img_trainval/1/train/img07866713_04_1R.jpg', 'cropped_img_trainval/1/train/img15444975_00_2L.jpg', 'cropped_img_trainval/1/train/img46080389_09_2L.jpg', 'cropped_img_trainval/1/train/img66993260_10_1R.jpg', 'cropped_img_trainval/1/train/img70846819_07_2L.jpg', 'cropped_img_trainval/1/train/img37390443_00_1R.jpg', 'cropped_img_trainval/1/train/img12947476_10_1R.jpg', 'cropped_img_trainval/1/train/img36161200_01_1R.jpg', 'cropped_img_trainval/1/train/img69182628_10_1R.jpg', 'cropped_img_trainval/1/train/img62110559_01_1R.jpg', 'cropped_img_trainval/1/train/img44911443_11_4L.jpg', 'cropped_img_trainval/1/train/img30015370_03_1R.jpg', 'cropped_img_trainval/1/train/img64959882_12_1R.jpg', 'cropped_img_trainval/1/train/img36421308_00_2L.jpg', 'cropped_img_trainval/1/train/img48881191_09_1R.jpg', 'cropped_img_trainval/1/train/img47701062_03_3L.jpg', 'cropped_img_trainval/1/train/img44368864_05_1R.jpg', 'cropped_img_trainval/1/train/img33248707_08_2L.jpg', 'cropped_img_trainval/1/train/img09156423_05_1R.jpg', 'cropped_img_trainval/1/train/img26927560_04_2L.jpg', 'cropped_img_trainval/1/train/img24356572_06_2R.jpg', 'cropped_img_trainval/1/train/img51196227_03_3L.jpg', 'cropped_img_trainval/1/train/img30015370_03_3L.jpg', 'cropped_img_trainval/1/train/img44911443_11_1R.jpg', 'cropped_img_trainval/1/train/img29059152_04_2L.jpg', 'cropped_img_trainval/1/train/img43834009_03_1R.jpg', 'cropped_img_trainval/1/train/img51196227_03_1R.jpg', 'cropped_img_trainval/1/train/img64959882_12_3L.jpg', 'cropped_img_trainval/1/train/img46080389_09_1R.jpg', 'cropped_img_trainval/1/train/img36548197_02_2L.jpg', 'cropped_img_trainval/1/train/img66134736_06_2L.jpg', 'cropped_img_trainval/1/train/img17910317_07_1R.jpg', 'cropped_img_trainval/1/train/img11171803_05_3L.jpg', 'cropped_img_trainval/1/train/img17910317_07_2L.jpg', 'cropped_img_trainval/1/train/img33248707_08_1R.jpg', 'cropped_img_trainval/1/train/img45775666_06_2L.jpg', 'cropped_img_trainval/1/train/img64698554_00_3L.jpg', 'cropped_img_trainval/1/train/img48041030_00_2L.jpg', 'cropped_img_trainval/1/train/img34778963_08_1R.jpg', 'cropped_img_trainval/1/train/img38375095_00_3L.jpg', 'cropped_img_trainval/1/train/img76665880_03_1R.jpg', 'cropped_img_trainval/1/train/img36313067_00_1R.jpg', 'cropped_img_trainval/1/train/img57508246_02_1R.jpg', 'cropped_img_trainval/1/train/img70143185_06_2L.jpg', 'cropped_img_trainval/1/train/img40594005_01_2L.jpg', 'cropped_img_trainval/1/train/img64698554_00_1R.jpg', 'cropped_img_trainval/1/train/img47398948_03_1R.jpg', 'cropped_img_trainval/1/train/img11240179_10_2L.jpg', 'cropped_img_trainval/1/train/img37242516_00_1R.jpg', 'cropped_img_trainval/1/train/img03402972_02_2L.jpg', 'cropped_img_trainval/1/train/img67479127_12_2L.jpg', 'cropped_img_trainval/1/train/img45379575_10_1R.jpg', 'cropped_img_trainval/1/train/img21904149_01_1R.jpg', 'cropped_img_trainval/1/train/img68507336_03_2R.jpg', 'cropped_img_trainval/1/train/img51946336_11_2L.jpg', 'cropped_img_trainval/1/train/img35520414_01_1R.jpg', 'cropped_img_trainval/1/train/img51946336_11_1R.jpg', 'cropped_img_trainval/1/train/img34491694_05_1R.jpg', 'cropped_img_trainval/1/train/img21221748_12_1R.jpg', 'cropped_img_trainval/1/train/img53325507_00_1R.jpg', 'cropped_img_trainval/1/train/img32015480_00_2L.jpg', 'cropped_img_trainval/1/train/img44796339_03_1R.jpg', 'cropped_img_trainval/1/train/img33833109_01_3L.jpg', 'cropped_img_trainval/1/train/img12415435_11_3L.jpg', 'cropped_img_trainval/1/train/img64338327_05_1R.jpg', 'cropped_img_trainval/1/train/img43834009_03_2L.jpg', 'cropped_img_trainval/1/train/img21904149_01_2L.jpg', 'cropped_img_trainval/1/train/img45047024_00_2L.jpg', 'cropped_img_trainval/1/train/img12415435_11_1R.jpg', 'cropped_img_trainval/1/train/img59046972_02_1R.jpg', 'cropped_img_trainval/1/train/img32974260_05_2L.jpg', 'cropped_img_trainval/1/train/img58841289_00_2L.jpg', 'cropped_img_trainval/1/train/img53325507_00_2L.jpg', 'cropped_img_trainval/1/train/img68507336_02_2L.jpg', 'cropped_img_trainval/1/train/img08262686_05_1R.jpg', 'cropped_img_trainval/1/train/img67457175_06_2L.jpg', 'cropped_img_trainval/1/train/img64338327_05_2L.jpg', 'cropped_img_trainval/1/train/img68687854_08_2L.jpg', 'cropped_img_trainval/1/train/img52922738_06_2L.jpg', 'cropped_img_trainval/1/train/img56936375_03_1R.jpg', 'cropped_img_trainval/1/train/img45775666_06_1R.jpg', 'cropped_img_trainval/1/train/img03402972_02_1R.jpg', 'cropped_img_trainval/1/train/img68687854_07_1R.jpg', 'cropped_img_trainval/1/train/img68687854_08_1R.jpg', 'cropped_img_trainval/1/train/img37899455_01_2L.jpg', 'cropped_img_trainval/1/train/img45162624_06_1R.jpg', 'cropped_img_trainval/1/train/img45379575_11_2L.jpg', 'cropped_img_trainval/1/train/img50844685_03_3L.jpg', 'cropped_img_trainval/1/train/img47783837_11_1R.jpg', 'cropped_img_trainval/1/train/img38028038_05_2L.jpg', 'cropped_img_trainval/1/train/img47398948_04_3L.jpg', 'cropped_img_trainval/1/train/img45047024_00_1R.jpg', 'cropped_img_trainval/1/train/img58096578_01_1R.jpg', 'cropped_img_trainval/1/train/img14393235_06_1R.jpg', 'cropped_img_trainval/1/train/img54568372_06_1R.jpg', 'cropped_img_trainval/1/train/img67479127_11_1R.jpg', 'cropped_img_trainval/1/train/img32974260_05_1R.jpg', 'cropped_img_trainval/1/train/img00879242_08_2L.jpg', 'cropped_img_trainval/1/train/img58096578_01_2L.jpg', 'cropped_img_trainval/1/train/img43040884_05_2L.jpg', 'cropped_img_trainval/1/train/img57508246_02_2L.jpg', 'cropped_img_trainval/1/train/img38028038_05_1R.jpg', 'cropped_img_trainval/1/train/img30694868_10_1R.jpg', 'cropped_img_trainval/1/train/img45916965_02_1R.jpg', 'cropped_img_trainval/1/train/img34491694_05_2L.jpg', 'cropped_img_trainval/1/train/img41780706_02_2L.jpg', 'cropped_img_trainval/1/train/img33833109_01_1R.jpg', 'cropped_img_trainval/1/train/img37899455_01_1R.jpg', 'cropped_img_trainval/1/train/img58841289_00_1R.jpg', 'cropped_img_trainval/1/train/img48041030_00_1R.jpg', 'cropped_img_trainval/1/train/img67457175_06_1R.jpg', 'cropped_img_trainval/1/train/img38375095_00_1R.jpg', 'cropped_img_trainval/1/train/img08580395_03_1R.jpg', 'cropped_img_trainval/1/train/img59046972_02_2L.jpg', 'cropped_img_trainval/1/train/img11240179_10_1R.jpg', 'cropped_img_trainval/1/train/img00879242_08_1R.jpg', 'cropped_img_trainval/1/train/img06489887_01_1R.jpg', 'cropped_img_trainval/1/train/img58160025_03_2L.jpg', 'cropped_img_trainval/1/train/img31108656_00_2L.jpg', 'cropped_img_trainval/1/train/img27582884_00_2L.jpg', 'cropped_img_trainval/1/train/img31108656_00_1R.jpg', 'cropped_img_trainval/1/train/img37848019_06_1R.jpg', 'cropped_img_trainval/1/train/img21221748_12_2L.jpg', 'cropped_img_trainval/1/train/img32396165_09_1R.jpg', 'cropped_img_trainval/1/train/img35520414_00_2L.jpg', 'cropped_img_trainval/1/train/img41780706_02_1R.jpg', 'cropped_img_trainval/1/train/img38867427_04_1R.jpg', 'cropped_img_trainval/1/train/img02534901_06_2L.jpg', 'cropped_img_trainval/1/train/img06799851_08_1R.jpg', 'cropped_img_trainval/1/train/img19531989_01_1R.jpg', 'cropped_img_trainval/1/train/img21480118_11_2L.jpg', 'cropped_img_trainval/1/train/img66807511_01_2L.jpg', 'cropped_img_trainval/1/train/img06799851_08_2L.jpg', 'cropped_img_trainval/1/train/img21480118_11_1R.jpg', 'cropped_img_trainval/1/train/img55737385_04_2L.jpg', 'cropped_img_trainval/1/train/img54977932_00_3L.jpg', 'cropped_img_trainval/1/train/img02534901_05_1R.jpg', 'cropped_img_trainval/1/train/img38867427_05_2L.jpg', 'cropped_img_trainval/1/train/img54977932_00_1R.jpg', 'cropped_img_trainval/1/train/img42867468_06_1R.jpg', 'cropped_img_trainval/1/train/img09876168_03_2R.jpg', 'cropped_img_trainval/1/train/img12034939_03_1R.jpg', 'cropped_img_trainval/1/train/img24590673_11_1R.jpg', 'cropped_img_trainval/1/train/img10117692_00_2L.jpg', 'cropped_img_trainval/1/train/img14093268_05_1R.jpg', 'cropped_img_trainval/1/train/img26935391_05_1R.jpg', 'cropped_img_trainval/1/train/img72588597_09_1R.jpg', 'cropped_img_trainval/1/train/img21024794_05_1R.jpg', 'cropped_img_trainval/1/train/img75705547_00_2L.jpg', 'cropped_img_trainval/1/train/img49053437_04_1R.jpg', 'cropped_img_trainval/1/train/img12501160_04_1R.jpg', 'cropped_img_trainval/1/train/img10117692_01_1R.jpg', 'cropped_img_trainval/1/train/img67994073_06_1R.jpg', 'cropped_img_trainval/1/train/img64520023_05_4L.jpg', 'cropped_img_trainval/1/train/img21189040_04_2R.jpg', 'cropped_img_trainval/1/train/img55496765_08_2R.jpg', 'cropped_img_trainval/1/train/img21945469_00_1R.jpg', 'cropped_img_trainval/1/train/img10117692_00_1R.jpg', 'cropped_img_trainval/1/train/img13703167_10_2L.jpg', 'cropped_img_trainval/1/train/img21945469_00_2L.jpg', 'cropped_img_trainval/1/train/img12034939_04_2L.jpg', 'cropped_img_trainval/1/train/img66075614_04_2L.jpg', 'cropped_img_trainval/1/train/img39693360_05_1R.jpg', 'cropped_img_trainval/1/train/img10117692_03_2L.jpg', 'cropped_img_trainval/1/train/img51111622_06_1R.jpg', 'cropped_img_trainval/1/train/img04309922_01_1R.jpg', 'cropped_img_trainval/1/train/img70136111_05_4L.jpg', 'cropped_img_trainval/1/train/img03510031_05_2L.jpg', 'cropped_img_trainval/1/train/img58758890_05_2L.jpg', 'cropped_img_trainval/1/train/img43450896_09_1R.jpg', 'cropped_img_trainval/1/train/img05851712_02_1R.jpg', 'cropped_img_trainval/1/train/img21189040_03_1R.jpg', 'cropped_img_trainval/1/train/img65232804_05_1R.jpg', 'cropped_img_trainval/1/train/img29091321_09_1R.jpg', 'cropped_img_trainval/1/train/img34827875_10_1R.jpg', 'cropped_img_trainval/1/train/img61591952_02_1R.jpg', 'cropped_img_trainval/1/train/img10117692_03_1R.jpg', 'cropped_img_trainval/1/train/img74039553_00_1R.jpg', 'cropped_img_trainval/1/train/img67361603_02_1R.jpg', 'cropped_img_trainval/1/train/img70436241_04_1R.jpg', 'cropped_img_trainval/1/train/img68237122_07_1R.jpg', 'cropped_img_trainval/1/train/img64520023_05_2R.jpg', 'cropped_img_trainval/1/train/img00265140_00_1R.jpg', 'cropped_img_trainval/1/train/img48321148_01_1R.jpg', 'cropped_img_trainval/1/train/img51989034_01_1R.jpg', 'cropped_img_trainval/1/train/img02016803_02_1R.jpg', 'cropped_img_trainval/1/train/img63360278_03_1R.jpg', 'cropped_img_trainval/1/train/img66075614_05_1R.jpg', 'cropped_img_trainval/1/train/img31780049_04_3R.jpg', 'cropped_img_trainval/1/train/img40413981_01_2L.jpg', 'cropped_img_trainval/1/train/img31780049_03_1R.jpg', 'cropped_img_trainval/1/train/img28278415_03_1R.jpg', 'cropped_img_trainval/1/train/img58758890_04_1R.jpg', 'cropped_img_trainval/1/train/img46168867_08_1R.jpg', 'cropped_img_trainval/1/train/img06457849_03_2L.jpg', 'cropped_img_trainval/1/train/img13331412_01_1R.jpg', 'cropped_img_trainval/1/train/img61480931_02_2L.jpg', 'cropped_img_trainval/1/train/img67762668_10_1R.jpg', 'cropped_img_trainval/1/train/img15409157_05_1R.jpg', 'cropped_img_trainval/1/train/img70136111_06_1R.jpg', 'cropped_img_trainval/1/train/img40413981_02_1R.jpg', 'cropped_img_trainval/1/train/img21443464_02_2L.jpg', 'cropped_img_trainval/1/train/img59313873_00_1R.jpg', 'cropped_img_trainval/1/train/img71925591_02_1R.jpg', 'cropped_img_trainval/1/train/img30395153_10_1R.jpg', 'cropped_img_trainval/1/train/img43450896_08_1R.jpg', 'cropped_img_trainval/1/train/img43040884_05_1R.jpg', 'cropped_img_trainval/1/train/img26258546_02_2L.jpg', 'cropped_img_trainval/1/train/img65965878_05_1L.jpg', 'cropped_img_trainval/1/train/img63197510_01_2L.jpg', 'cropped_img_trainval/1/train/img28189064_01_2L.jpg', 'cropped_img_trainval/1/train/img29035144_00_1L.jpg', 'cropped_img_trainval/1/train/img45351256_00_1R.jpg', 'cropped_img_trainval/1/train/img08566836_02_3L.jpg', 'cropped_img_trainval/1/train/img01324840_01_1R.jpg', 'cropped_img_trainval/1/train/img68183296_10_1R.jpg', 'cropped_img_trainval/1/train/img01324840_00_1R.jpg', 'cropped_img_trainval/1/train/img68183296_09_1L.jpg', 'cropped_img_trainval/1/train/img16567107_02_1R.jpg', 'cropped_img_trainval/1/train/img16567107_02_2L.jpg', 'cropped_img_trainval/1/train/img71515510_00_1R.jpg', 'cropped_img_trainval/1/train/img64054519_00_1R.jpg', 'cropped_img_trainval/1/train/img64054519_00_2L.jpg', 'cropped_img_trainval/1/train/img69235823_00_1R.jpg', 'cropped_img_trainval/1/train/img71739256_00_2L.jpg', 'cropped_img_trainval/1/train/img71739256_00_1R.jpg', 'cropped_img_trainval/1/train/img43808704_09_2L.jpg', 'cropped_img_trainval/1/train/img42124709_00_1R.jpg', 'cropped_img_trainval/1/train/img34706273_09_1R.jpg', 'cropped_img_trainval/1/train/img34706273_09_2L.jpg', 'cropped_img_trainval/1/train/img69630935_00_1R.jpg', 'cropped_img_trainval/1/train/img75351567_02_1R.jpg', 'cropped_img_trainval/1/train/img75351567_02_2L.jpg', 'cropped_img_trainval/1/train/img46695841_04_2L.jpg', 'cropped_img_trainval/1/train/img08966301_00_1R.jpg', 'cropped_img_trainval/1/train/img46695841_04_1R.jpg', 'cropped_img_trainval/1/train/img65174985_00_2L.jpg', 'cropped_img_trainval/1/train/img38798628_00_1R.jpg', 'cropped_img_trainval/1/train/img65174985_00_1R.jpg', 'cropped_img_trainval/1/train/img14315050_07_1R.jpg', 'cropped_img_trainval/1/train/img60395582_00_1R.jpg', 'cropped_img_trainval/1/train/img25330582_07_1R.jpg', 'cropped_img_trainval/1/train/img63197510_01_1R.jpg', 'cropped_img_trainval/1/train/img15495677_10_1R.jpg', 'cropped_img_trainval/1/train/img04599923_00_1R.jpg', 'cropped_img_trainval/1/train/img15495677_11_2L.jpg', 'cropped_img_trainval/1/train/img15495677_10_2L.jpg', 'cropped_img_trainval/1/train/img35667455_08_1R.jpg', 'cropped_img_trainval/1/train/img35667455_09_1R.jpg', 'cropped_img_trainval/1/train/img35667455_09_2L.jpg', 'cropped_img_trainval/1/train/img39577628_03_1R.jpg', 'cropped_img_trainval/1/train/img39577628_04_1R.jpg', 'cropped_img_trainval/1/train/img39577628_04_2L.jpg', 'cropped_img_trainval/1/train/img18637655_00_1R.jpg', 'cropped_img_trainval/1/train/img60198224_00_1R.jpg', 'cropped_img_trainval/1/train/img10629369_05_1R.jpg', 'cropped_img_trainval/1/train/img18637655_00_2L.jpg', 'cropped_img_trainval/1/train/img43082764_00_1R.jpg', 'cropped_img_trainval/1/train/img15273300_10_1R.jpg', 'cropped_img_trainval/1/train/img53009439_02_1R.jpg', 'cropped_img_trainval/1/train/img20873247_00_1R.jpg', 'cropped_img_trainval/1/train/img20873247_00_2L.jpg', 'cropped_img_trainval/1/train/img08202710_00_1R.jpg', 'cropped_img_trainval/1/train/img64402592_00_2L.jpg', 'cropped_img_trainval/1/train/img56626999_00_1R.jpg', 'cropped_img_trainval/1/train/img56626999_01_1R.jpg', 'cropped_img_trainval/1/train/img56626999_00_2L.jpg', 'cropped_img_trainval/1/train/img56626999_01_2L.jpg', 'cropped_img_trainval/1/train/img05496329_10_1R.jpg', 'cropped_img_trainval/1/train/img65842793_00_1R.jpg', 'cropped_img_trainval/1/train/img38774257_10_2L.jpg', 'cropped_img_trainval/1/train/img29931625_05_1R.jpg', 'cropped_img_trainval/1/train/img29931625_06_2L.jpg', 'cropped_img_trainval/1/train/img29931625_05_3L.jpg', 'cropped_img_trainval/1/train/img29931625_06_1R.jpg', 'cropped_img_trainval/1/train/img64148506_00_1R.jpg', 'cropped_img_trainval/1/train/img70036738_00_1R.jpg', 'cropped_img_trainval/1/train/img70036738_00_2L.jpg', 'cropped_img_trainval/1/train/img29059929_01_1R.jpg', 'cropped_img_trainval/1/train/img47407177_05_1R.jpg', 'cropped_img_trainval/1/train/img47407177_05_2L.jpg', 'cropped_img_trainval/1/train/img13850152_00_1R.jpg', 'cropped_img_trainval/1/train/img02285882_00_2L.jpg', 'cropped_img_trainval/1/train/img02285882_00_1R.jpg', 'cropped_img_trainval/1/train/img40731228_07_1R.jpg', 'cropped_img_trainval/1/train/img04456289_00_2L.jpg', 'cropped_img_trainval/1/train/img23543433_03_1R.jpg', 'cropped_img_trainval/1/train/img04456289_00_1R.jpg', 'cropped_img_trainval/1/train/img72456862_01_1R.jpg', 'cropped_img_trainval/1/train/img33131611_00_1R.jpg', 'cropped_img_trainval/1/train/img33131611_00_2L.jpg', 'cropped_img_trainval/1/train/img07429024_11_1R.jpg', 'cropped_img_trainval/1/train/img08205079_00_2L.jpg', 'cropped_img_trainval/1/train/img08205079_00_1R.jpg', 'cropped_img_trainval/1/train/img42133484_00_1R.jpg', 'cropped_img_trainval/1/train/img42195177_00_1R.jpg', 'cropped_img_trainval/1/train/img46724345_00_1R.jpg', 'cropped_img_trainval/1/train/img01810498_00_1R.jpg', 'cropped_img_trainval/1/train/img50417116_00_1R.jpg', 'cropped_img_trainval/1/train/img73236885_11_1R.jpg', 'cropped_img_trainval/1/train/img12449504_01_1R.jpg', 'cropped_img_trainval/1/train/img59160703_06_2L.jpg', 'cropped_img_trainval/1/train/img59160703_07_1R.jpg', 'cropped_img_trainval/1/train/img12449504_02_1R.jpg', 'cropped_img_trainval/1/train/img01048767_10_1R.jpg', 'cropped_img_trainval/1/train/img19258094_00_1R.jpg', 'cropped_img_trainval/1/train/img61744649_01_2L.jpg', 'cropped_img_trainval/1/train/img61744649_01_1R.jpg', 'cropped_img_trainval/1/train/img52918763_01_1R.jpg', 'cropped_img_trainval/1/train/img52918763_00_1R.jpg', 'cropped_img_trainval/1/train/img00241280_10_1R.jpg', 'cropped_img_trainval/1/train/img52918763_00_2L.jpg', 'cropped_img_trainval/1/train/img50309961_02_1R.jpg', 'cropped_img_trainval/1/train/img60532105_00_2L.jpg', 'cropped_img_trainval/1/train/img60532105_00_1R.jpg', 'cropped_img_trainval/1/train/img71971845_07_2L.jpg', 'cropped_img_trainval/1/train/img71971845_06_1R.jpg', 'cropped_img_trainval/1/train/img02790531_05_1R.jpg', 'cropped_img_trainval/1/train/img71116744_00_2L.jpg', 'cropped_img_trainval/1/train/img28439168_01_1R.jpg', 'cropped_img_trainval/1/train/img28439168_00_1R.jpg', 'cropped_img_trainval/1/train/img28439168_00_3L.jpg', 'cropped_img_trainval/1/train/img28439168_01_3L.jpg', 'cropped_img_trainval/1/train/img66572645_01_1R.jpg', 'cropped_img_trainval/1/train/img24530209_00_1R.jpg', 'cropped_img_trainval/1/train/img67198698_01_1R.jpg', 'cropped_img_trainval/1/train/img24530209_00_2L.jpg', 'cropped_img_trainval/1/train/img69881662_00_2L.jpg', 'cropped_img_trainval/1/train/img69881662_00_1R.jpg', 'cropped_img_trainval/1/train/img45891310_03_1R.jpg', 'cropped_img_trainval/1/train/img56315643_03_1R.jpg', 'cropped_img_trainval/1/train/img24966086_01_1R.jpg', 'cropped_img_trainval/1/train/img53482703_00_2L.jpg', 'cropped_img_trainval/1/train/img53482703_01_2L.jpg', 'cropped_img_trainval/1/train/img53482703_01_1R.jpg', 'cropped_img_trainval/1/train/img53482703_00_1R.jpg', 'cropped_img_trainval/1/train/img29187515_00_2L.jpg', 'cropped_img_trainval/1/train/img29187515_00_1R.jpg', 'cropped_img_trainval/1/train/img12777278_10_2L.jpg', 'cropped_img_trainval/1/train/img12777278_11_1R.jpg', 'cropped_img_trainval/1/train/img12777278_10_1R.jpg', 'cropped_img_trainval/1/train/img17309647_00_2L.jpg', 'cropped_img_trainval/1/train/img54887427_04_1R.jpg', 'cropped_img_trainval/1/train/img17309647_00_1R.jpg', 'cropped_img_trainval/1/train/img05846150_00_1R.jpg', 'cropped_img_trainval/1/train/img62930460_00_1R.jpg', 'cropped_img_trainval/1/train/img48740957_01_1R.jpg', 'cropped_img_trainval/1/train/img21271278_00_1R.jpg', 'cropped_img_trainval/1/train/img48740957_00_1R.jpg', 'cropped_img_trainval/1/train/img29349299_11_1R.jpg', 'cropped_img_trainval/1/train/img29349299_12_1R.jpg', 'cropped_img_trainval/1/train/img63855436_00_1R.jpg', 'cropped_img_trainval/1/train/img40704062_01_1R.jpg', 'cropped_img_trainval/1/train/img67665685_00_1R.jpg', 'cropped_img_trainval/1/train/img54806465_00_1R.jpg', 'cropped_img_trainval/1/train/img40073046_11_1R.jpg', 'cropped_img_trainval/1/train/img40073046_11_2L.jpg', 'cropped_img_trainval/1/train/img40073046_10_1R.jpg', 'cropped_img_trainval/1/train/img40073046_10_2L.jpg', 'cropped_img_trainval/1/train/img72783247_00_1R.jpg', 'cropped_img_trainval/1/train/img05322559_04_1R.jpg', 'cropped_img_trainval/1/train/img47190507_00_1R.jpg', 'cropped_img_trainval/1/train/img47190507_00_2L.jpg', 'cropped_img_trainval/1/train/img45591917_10_1R.jpg', 'cropped_img_trainval/1/train/img45591917_10_2L.jpg', 'cropped_img_trainval/1/train/img76046907_02_1R.jpg', 'cropped_img_trainval/1/train/img63437486_00_1R.jpg', 'cropped_img_trainval/1/train/img18700290_00_1R.jpg', 'cropped_img_trainval/1/train/img63437486_01_3L.jpg', 'cropped_img_trainval/1/train/img55608415_00_1R.jpg', 'cropped_img_trainval/1/train/img18700290_00_2L.jpg', 'cropped_img_trainval/1/train/img17392648_01_1R.jpg', 'cropped_img_trainval/1/train/img17392648_01_2L.jpg', 'cropped_img_trainval/1/train/img28414860_00_2L.jpg', 'cropped_img_trainval/1/train/img28414860_01_2L.jpg', 'cropped_img_trainval/1/train/img31605427_06_1R.jpg', 'cropped_img_trainval/1/train/img28414860_01_1R.jpg', 'cropped_img_trainval/1/train/img09784131_00_3L.jpg', 'cropped_img_trainval/1/train/img19104188_00_1R.jpg', 'cropped_img_trainval/1/train/img09784131_00_1R.jpg', 'cropped_img_trainval/1/train/img35991191_06_1R.jpg', 'cropped_img_trainval/1/train/img04836563_09_1R.jpg', 'cropped_img_trainval/1/train/img04836563_10_1R.jpg', 'cropped_img_trainval/1/train/img04836563_09_2L.jpg', 'cropped_img_trainval/1/train/img35991191_07_2L.jpg', 'cropped_img_trainval/1/train/img10486789_11_2L.jpg', 'cropped_img_trainval/1/train/img10486789_10_1R.jpg', 'cropped_img_trainval/1/train/img08729842_05_1R.jpg', 'cropped_img_trainval/1/train/img02505380_00_1R.jpg', 'cropped_img_trainval/1/train/img30573546_00_1R.jpg', 'cropped_img_trainval/1/train/img02505380_00_2L.jpg', 'cropped_img_trainval/1/train/img61897087_00_1R.jpg', 'cropped_img_trainval/1/train/img61897087_00_2L.jpg', 'cropped_img_trainval/1/train/img35507527_00_1R.jpg', 'cropped_img_trainval/1/train/img35507527_00_2L.jpg', 'cropped_img_trainval/1/train/img43909203_00_1R.jpg', 'cropped_img_trainval/1/train/img43909203_00_2L.jpg', 'cropped_img_trainval/1/train/img24476766_04_1R.jpg', 'cropped_img_trainval/1/train/img24476766_04_2L.jpg', 'cropped_img_trainval/1/train/img28858490_00_1R.jpg', 'cropped_img_trainval/1/train/img17860874_11_2L.jpg', 'cropped_img_trainval/1/train/img17860874_10_2L.jpg', 'cropped_img_trainval/1/train/img20996327_00_1R.jpg', 'cropped_img_trainval/1/train/img17860874_10_1R.jpg', 'cropped_img_trainval/1/train/img17860874_11_1R.jpg', 'cropped_img_trainval/1/train/img20209529_00_1R.jpg', 'cropped_img_trainval/1/train/img73890552_07_2L.jpg', 'cropped_img_trainval/1/train/img73890552_07_1R.jpg', 'cropped_img_trainval/1/train/img73890552_06_1R.jpg', 'cropped_img_trainval/1/train/img43451412_08_1R.jpg', 'cropped_img_trainval/1/train/img72048139_01_2L.jpg', 'cropped_img_trainval/1/train/img68936284_03_1R.jpg', 'cropped_img_trainval/1/train/img72048139_01_1R.jpg', 'cropped_img_trainval/1/train/img68936284_02_1R.jpg', 'cropped_img_trainval/1/train/img29303841_00_1R.jpg', 'cropped_img_trainval/1/train/img29303841_00_2L.jpg', 'cropped_img_trainval/1/train/img16639803_00_1R.jpg', 'cropped_img_trainval/1/train/img46577880_08_1R.jpg', 'cropped_img_trainval/1/train/img10638445_04_2L.jpg', 'cropped_img_trainval/1/train/img10638445_03_1R.jpg', 'cropped_img_trainval/1/train/img10638445_00_2L.jpg', 'cropped_img_trainval/1/train/img10638445_04_1R.jpg', 'cropped_img_trainval/1/train/img10638445_00_1R.jpg', 'cropped_img_trainval/1/train/img46577880_07_1R.jpg', 'cropped_img_trainval/1/train/img23797119_07_2L.jpg', 'cropped_img_trainval/1/train/img50075589_00_1R.jpg', 'cropped_img_trainval/1/train/img23797119_07_1R.jpg', 'cropped_img_trainval/1/train/img67180094_10_1R.jpg', 'cropped_img_trainval/1/train/img67180094_09_1R.jpg', 'cropped_img_trainval/1/train/img76679324_00_1R.jpg', 'cropped_img_trainval/1/train/img26362716_00_1R.jpg', 'cropped_img_trainval/1/train/img74254654_00_1R.jpg', 'cropped_img_trainval/1/train/img74254654_00_2L.jpg', 'cropped_img_trainval/1/train/img09468788_01_1R.jpg', 'cropped_img_trainval/1/train/img09468788_01_2L.jpg', 'cropped_img_trainval/1/train/img27909713_10_1R.jpg', 'cropped_img_trainval/1/train/img50587134_01_1R.jpg', 'cropped_img_trainval/1/train/img50587134_01_2L.jpg', 'cropped_img_trainval/1/train/img09468788_00_2L.jpg', 'cropped_img_trainval/1/train/img09468788_00_1R.jpg', 'cropped_img_trainval/1/train/img27909713_11_2L.jpg', 'cropped_img_trainval/1/train/img31297388_00_1R.jpg', 'cropped_img_trainval/1/train/img31297388_00_2L.jpg', 'cropped_img_trainval/1/train/img27909713_11_1R.jpg', 'cropped_img_trainval/1/train/img27909713_10_3L.jpg', 'cropped_img_trainval/1/train/img62390695_00_1R.jpg', 'cropped_img_trainval/1/train/img74813273_03_1R.jpg', 'cropped_img_trainval/1/train/img68588085_01_1R.jpg', 'cropped_img_trainval/1/train/img32606712_00_1R.jpg', 'cropped_img_trainval/1/train/img20322708_00_1R.jpg', 'cropped_img_trainval/1/train/img56037208_00_1R.jpg', 'cropped_img_trainval/1/train/img27104596_11_1R.jpg', 'cropped_img_trainval/1/train/img24135090_03_2L.jpg', 'cropped_img_trainval/1/train/img24135090_04_4L.jpg', 'cropped_img_trainval/1/train/img24135090_04_3L.jpg', 'cropped_img_trainval/1/train/img16933400_01_1R.jpg', 'cropped_img_trainval/1/train/img16933400_00_1R.jpg', 'cropped_img_trainval/1/train/img16933400_00_2L.jpg', 'cropped_img_trainval/1/train/img31805504_00_1R.jpg', 'cropped_img_trainval/1/train/img13298563_00_1R.jpg', 'cropped_img_trainval/1/train/img31805504_01_2L.jpg', 'cropped_img_trainval/1/train/img75418893_00_2L.jpg', 'cropped_img_trainval/1/train/img49763500_00_2L.jpg', 'cropped_img_trainval/1/train/img49763500_00_1R.jpg', 'cropped_img_trainval/1/train/img75418893_01_1R.jpg', 'cropped_img_trainval/1/train/img75418893_00_1R.jpg', 'cropped_img_trainval/1/train/img41607196_00_1R.jpg', 'cropped_img_trainval/1/train/img66384784_03_1R.jpg', 'cropped_img_trainval/1/train/img34230875_00_1R.jpg', 'cropped_img_trainval/1/train/img75468564_07_1R.jpg', 'cropped_img_trainval/1/train/img69187560_03_2L.jpg', 'cropped_img_trainval/1/train/img03031949_00_1R.jpg', 'cropped_img_trainval/1/train/img69187560_03_1R.jpg', 'cropped_img_trainval/1/train/img69187560_02_2L.jpg', 'cropped_img_trainval/1/train/img38600134_00_1R.jpg', 'cropped_img_trainval/1/train/img03031949_01_1L.jpg', 'cropped_img_trainval/1/train/img55114636_00_1R.jpg', 'cropped_img_trainval/1/train/img34729303_01_1R.jpg', 'cropped_img_trainval/1/train/img34729303_00_1R.jpg', 'cropped_img_trainval/1/train/img61960515_00_1R.jpg', 'cropped_img_trainval/1/train/img38724181_02_1R.jpg', 'cropped_img_trainval/1/train/img69536976_00_1R.jpg', 'cropped_img_trainval/1/train/img42180279_00_1R.jpg', 'cropped_img_trainval/1/train/img17740212_00_1R.jpg', 'cropped_img_trainval/1/train/img23570430_06_1R.jpg', 'cropped_img_trainval/1/train/img23570430_05_1R.jpg', 'cropped_img_trainval/1/train/img46587649_00_1R.jpg', 'cropped_img_trainval/1/train/img44610504_00_1R.jpg', 'cropped_img_trainval/1/train/img12528864_03_1R.jpg', 'cropped_img_trainval/1/train/img06993423_00_2L.jpg', 'cropped_img_trainval/1/train/img06993423_00_1R.jpg', 'cropped_img_trainval/1/train/img12528864_03_3L.jpg', 'cropped_img_trainval/1/train/img32291006_00_1R.jpg', 'cropped_img_trainval/1/train/img14082912_07_1R.jpg', 'cropped_img_trainval/1/train/img59962267_00_1R.jpg', 'cropped_img_trainval/1/train/img10916330_08_1R.jpg', 'cropped_img_trainval/1/train/img10916330_09_1R.jpg', 'cropped_img_trainval/1/train/img59962267_00_3L.jpg', 'cropped_img_trainval/1/train/img60146885_01_2L.jpg', 'cropped_img_trainval/1/train/img60146885_01_1R.jpg', 'cropped_img_trainval/1/train/img64228831_00_2L.jpg', 'cropped_img_trainval/1/train/img64228831_00_1R.jpg', 'cropped_img_trainval/1/train/img40574394_00_1R.jpg', 'cropped_img_trainval/1/train/img47427336_00_1R.jpg', 'cropped_img_trainval/1/train/img47427336_00_2L.jpg', 'cropped_img_trainval/1/train/img43477037_00_1R.jpg', 'cropped_img_trainval/1/train/img64042417_00_1R.jpg', 'cropped_img_trainval/1/train/img21339603_07_1R.jpg', 'cropped_img_trainval/1/train/img34846212_03_1R.jpg', 'cropped_img_trainval/1/train/img34846212_04_3L.jpg', 'cropped_img_trainval/1/train/img34846212_01_1R.jpg', 'cropped_img_trainval/1/train/img34846212_00_1L.jpg', 'cropped_img_trainval/1/train/img34846212_04_2R.jpg', 'cropped_img_trainval/1/train/img34846212_03_3L.jpg', 'cropped_img_trainval/1/train/img34846212_04_1R.jpg', 'cropped_img_trainval/1/train/img34846212_03_2R.jpg', 'cropped_img_trainval/1/train/img25877842_01_1R.jpg', 'cropped_img_trainval/1/train/img62794917_00_1R.jpg', 'cropped_img_trainval/1/train/img30957195_00_1R.jpg', 'cropped_img_trainval/1/train/img45391445_00_1L.jpg', 'cropped_img_trainval/1/train/img36811449_00_1R.jpg', 'cropped_img_trainval/1/train/img36811449_00_2L.jpg', 'cropped_img_trainval/1/train/img04709796_00_1R.jpg', 'cropped_img_trainval/1/train/img52283612_01_1R.jpg', 'cropped_img_trainval/1/train/img30157446_09_1R.jpg', 'cropped_img_trainval/1/train/img30157446_08_1R.jpg', 'cropped_img_trainval/1/train/img41578668_07_1R.jpg', 'cropped_img_trainval/1/train/img41578668_07_2L.jpg', 'cropped_img_trainval/1/train/img30757170_10_2L.jpg', 'cropped_img_trainval/1/train/img30757170_11_2L.jpg', 'cropped_img_trainval/1/train/img30757170_11_1R.jpg', 'cropped_img_trainval/1/train/img30757170_10_1R.jpg', 'cropped_img_trainval/1/train/img23859707_11_1R.jpg', 'cropped_img_trainval/1/train/img26797894_00_2L.jpg', 'cropped_img_trainval/1/train/img23859707_11_2L.jpg', 'cropped_img_trainval/1/train/img23859707_10_2L.jpg', 'cropped_img_trainval/1/train/img23859707_10_1R.jpg', 'cropped_img_trainval/1/train/img26797894_00_1R.jpg', 'cropped_img_trainval/1/train/img23016283_05_1R.jpg', 'cropped_img_trainval/1/train/img02330573_00_1R.jpg', 'cropped_img_trainval/1/train/img47528071_00_2L.jpg', 'cropped_img_trainval/1/train/img47528071_01_1R.jpg', 'cropped_img_trainval/1/train/img41411966_00_1R.jpg', 'cropped_img_trainval/1/train/img47528071_00_1R.jpg', 'cropped_img_trainval/1/train/img54582483_03_2L.jpg', 'cropped_img_trainval/1/train/img54582483_03_1R.jpg', 'cropped_img_trainval/1/train/img54582483_02_1R.jpg', 'cropped_img_trainval/1/train/img54582483_01_1R.jpg', 'cropped_img_trainval/1/train/img16104560_05_1R.jpg', 'cropped_img_trainval/1/train/img56532623_00_1R.jpg', 'cropped_img_trainval/1/train/img57763947_04_1R.jpg', 'cropped_img_trainval/1/train/img57763947_05_2L.jpg', 'cropped_img_trainval/1/train/img57763947_05_1R.jpg', 'cropped_img_trainval/1/train/img56086975_02_1R.jpg', 'cropped_img_trainval/1/train/img07914410_05_1R.jpg', 'cropped_img_trainval/1/train/img60774061_05_1R.jpg', 'cropped_img_trainval/1/train/img07914410_06_2L.jpg', 'cropped_img_trainval/1/train/img07598241_09_1R.jpg', 'cropped_img_trainval/1/train/img47315784_00_2L.jpg', 'cropped_img_trainval/1/train/img47315784_00_1R.jpg', 'cropped_img_trainval/1/train/img75842567_00_1R.jpg', 'cropped_img_trainval/1/train/img75842567_00_2L.jpg', 'cropped_img_trainval/1/train/img29986165_01_2L.jpg', 'cropped_img_trainval/1/train/img29986165_01_1R.jpg', 'cropped_img_trainval/1/train/img75842567_00_3L.jpg', 'cropped_img_trainval/1/train/img29986165_00_1R.jpg', 'cropped_img_trainval/1/train/img55719597_05_1R.jpg', 'cropped_img_trainval/1/train/img33726858_03_1R.jpg', 'cropped_img_trainval/1/train/img48372632_05_1R.jpg', 'cropped_img_trainval/1/train/img44509055_10_1R.jpg', 'cropped_img_trainval/1/train/img15589104_00_1R.jpg', 'cropped_img_trainval/1/train/img55141555_05_1R.jpg', 'cropped_img_trainval/1/train/img40200883_00_1R.jpg', 'cropped_img_trainval/1/train/img41832349_00_1R.jpg', 'cropped_img_trainval/1/train/img30672827_03_2L.jpg', 'cropped_img_trainval/1/train/img30672827_03_1R.jpg', 'cropped_img_trainval/1/train/img32668857_00_1R.jpg', 'cropped_img_trainval/1/train/img03344543_00_1R.jpg', 'cropped_img_trainval/1/train/img69058026_00_1R.jpg', 'cropped_img_trainval/1/train/img71493496_08_1R.jpg', 'cropped_img_trainval/1/train/img19500132_01_1R.jpg', 'cropped_img_trainval/1/train/img46199104_00_2L.jpg', 'cropped_img_trainval/1/train/img21443464_02_1R.jpg', 'cropped_img_trainval/1/train/img41578668_06_1R.jpg', 'cropped_img_trainval/1/train/img23514161_09_1R.jpg', 'cropped_img_trainval/1/train/img26516043_01_1R.jpg', 'cropped_img_trainval/1/train/img07349977_04_1R.jpg', 'cropped_img_trainval/1/train/img56381211_06_2L.jpg', 'cropped_img_trainval/1/train/img62657370_10_2L.jpg', 'cropped_img_trainval/1/train/img41168264_00_2L.jpg', 'cropped_img_trainval/1/train/img43473225_05_1R.jpg', 'cropped_img_trainval/1/train/img41589846_01_1R.jpg', 'cropped_img_trainval/1/train/img75859552_01_2R.jpg', 'cropped_img_trainval/1/train/img42053837_04_1R.jpg', 'cropped_img_trainval/1/train/img17225916_00_1R.jpg', 'cropped_img_trainval/1/train/img76888512_00_1R.jpg', 'cropped_img_trainval/1/train/img53994905_10_3L.jpg', 'cropped_img_trainval/1/train/img41268862_02_2L.jpg', 'cropped_img_trainval/1/train/img50844685_03_1R.jpg', 'cropped_img_trainval/1/train/img34865533_05_1R.jpg', 'cropped_img_trainval/1/train/img35047283_11_2L.jpg', 'cropped_img_trainval/1/train/img29187515_01_2L.jpg', 'cropped_img_trainval/1/train/img30672827_02_1R.jpg', 'cropped_img_trainval/1/train/img18347006_11_2L.jpg', 'cropped_img_trainval/1/train/img65805852_00_2L.jpg', 'cropped_img_trainval/1/train/img54712384_03_1R.jpg', 'cropped_img_trainval/1/train/img54489928_11_1R.jpg', 'cropped_img_trainval/1/train/img22355647_00_1R.jpg', 'cropped_img_trainval/1/train/img10638445_03_2L.jpg', 'cropped_img_trainval/1/train/img23647691_02_1R.jpg', 'cropped_img_trainval/1/train/img26927560_04_1R.jpg', 'cropped_img_trainval/1/train/img70868525_01_1R.jpg', 'cropped_img_trainval/1/train/img65805852_00_1R.jpg', 'cropped_img_trainval/1/train/img46990447_07_1R.jpg', 'cropped_img_trainval/1/train/img27582884_00_1R.jpg', 'cropped_img_trainval/1/train/img52922738_05_1R.jpg', 'cropped_img_trainval/1/train/img03136594_00_2L.jpg', 'cropped_img_trainval/1/train/img04599923_00_2L.jpg', 'cropped_img_trainval/1/train/img61482209_00_1R.jpg', 'cropped_img_trainval/1/train/img67159836_02_1R.jpg', 'cropped_img_trainval/1/train/img01802741_00_1R.jpg', 'cropped_img_trainval/1/train/img76843122_11_1R.jpg', 'cropped_img_trainval/1/train/img13495263_08_1R.jpg', 'cropped_img_trainval/1/train/img00085024_00_1R.jpg', 'cropped_img_trainval/1/train/img59260769_11_3L.jpg', 'cropped_img_trainval/1/train/img47593278_00_1R.jpg', 'cropped_img_trainval/1/train/img62916266_00_1R.jpg', 'cropped_img_trainval/1/train/img70926154_03_1R.jpg', 'cropped_img_trainval/1/train/img40413981_01_1R.jpg', 'cropped_img_trainval/1/train/img67361603_02_2L.jpg', 'cropped_img_trainval/1/train/img42124709_00_2L.jpg', 'cropped_img_trainval/1/train/img25223732_00_2L.jpg', 'cropped_img_trainval/1/train/img12034939_03_2L.jpg', 'cropped_img_trainval/1/train/img15381734_04_1R.jpg', 'cropped_img_trainval/1/train/img38622613_04_1R.jpg', 'cropped_img_trainval/1/train/img49561996_05_1R.jpg', 'cropped_img_trainval/1/train/img70143185_07_1R.jpg', 'cropped_img_trainval/1/train/img10760169_09_1R.jpg', 'cropped_img_trainval/1/train/img36421308_00_1R.jpg', 'cropped_img_trainval/1/train/img15444975_00_1R.jpg', 'cropped_img_trainval/1/train/img11540802_07_1R.jpg', 'cropped_img_trainval/1/train/img29653635_02_1R.jpg', 'cropped_img_trainval/1/train/img29091321_08_1R.jpg', 'cropped_img_trainval/1/train/img69527309_02_1R.jpg', 'cropped_img_trainval/1/train/img39577628_03_2L.jpg', 'cropped_img_trainval/1/train/img29899716_05_1R.jpg', 'cropped_img_trainval/1/train/img40594005_01_1R.jpg', 'cropped_img_trainval/1/train/img40263861_05_2L.jpg', 'cropped_img_trainval/1/train/img07153939_05_2L.jpg', 'cropped_img_trainval/1/train/img15381734_04_3L.jpg', 'cropped_img_trainval/1/train/img38049706_02_1R.jpg', 'cropped_img_trainval/1/train/img54582483_02_2L.jpg', 'cropped_img_trainval/1/train/img49209012_00_2L.jpg', 'cropped_img_trainval/1/train/img21778209_03_2L.jpg', 'cropped_img_trainval/1/train/img59260769_11_1R.jpg', 'cropped_img_trainval/1/train/img04836563_10_2L.jpg', 'cropped_img_trainval/1/train/img67159836_02_3L.jpg', 'cropped_img_trainval/1/train/img70926154_03_3L.jpg', 'cropped_img_trainval/1/train/img59714289_05_1R.jpg', 'cropped_img_trainval/1/train/img45162624_05_2L.jpg', 'cropped_img_trainval/1/train/img30932554_10_1R.jpg', 'cropped_img_trainval/1/train/img31601741_00_2L.jpg', 'cropped_img_trainval/1/train/img64457326_10_1R.jpg', 'cropped_img_trainval/1/train/img69187560_02_1R.jpg', 'cropped_img_trainval/1/train/img30998817_07_2L.jpg', 'cropped_img_trainval/1/train/img34827875_10_2L.jpg', 'cropped_img_trainval/1/train/img71758610_11_1R.jpg', 'cropped_img_trainval/1/train/img63755777_06_1R.jpg', 'cropped_img_trainval/1/train/img68412213_07_1R.jpg', 'cropped_img_trainval/1/train/img44368864_05_2L.jpg', 'cropped_img_trainval/1/train/img68404896_04_1L.jpg', 'cropped_img_trainval/1/train/img51637304_04_1R.jpg', 'cropped_img_trainval/1/train/img49466235_03_3L.jpg', 'cropped_img_trainval/1/train/img42893698_05_1R.jpg', 'cropped_img_trainval/1/train/img13810783_11_1R.jpg', 'cropped_img_trainval/1/train/img31605427_06_2L.jpg', 'cropped_img_trainval/1/train/img55737385_03_1R.jpg', 'cropped_img_trainval/1/train/img47190507_01_1R.jpg', 'cropped_img_trainval/1/train/img17469359_00_1R.jpg', 'cropped_img_trainval/1/train/img47398948_04_2L.jpg', 'cropped_img_trainval/1/train/img10117692_01_2R.jpg', 'cropped_img_trainval/1/train/img22471127_00_2L.jpg', 'cropped_img_trainval/1/train/img64148506_00_2L.jpg', 'cropped_img_trainval/1/train/img64402592_00_1R.jpg', 'cropped_img_trainval/1/train/img58170852_09_1R.jpg', 'cropped_img_trainval/1/train/img61480931_02_1R.jpg', 'cropped_img_trainval/1/train/img00085008_00_1R.jpg', 'cropped_img_trainval/1/train/img15409157_05_2R.jpg', 'cropped_img_trainval/1/train/img56039395_00_1R.jpg', 'cropped_img_trainval/1/train/img28414860_00_1R.jpg', 'cropped_img_trainval/1/train/img57230499_00_1R.jpg', 'cropped_img_trainval/1/train/img69313660_01_2L.jpg', 'cropped_img_trainval/1/train/img10117692_04_1R.jpg', 'cropped_img_trainval/1/train/img52066364_06_6L.jpg', 'cropped_img_trainval/1/train/img41566362_06_1R.jpg', 'cropped_img_trainval/1/train/img29242862_00_3L.jpg', 'cropped_img_trainval/1/train/img32396165_10_2L.jpg', 'cropped_img_trainval/1/train/img76679324_00_2L.jpg', 'cropped_img_trainval/1/train/img63360278_04_1R.jpg', 'cropped_img_trainval/1/train/img37973388_02_1R.jpg', 'cropped_img_trainval/1/train/img14393235_06_2L.jpg', 'cropped_img_trainval/1/train/img52066364_05_1R.jpg', 'cropped_img_trainval/1/train/img16062262_00_1R.jpg', 'cropped_img_trainval/1/train/img56086975_01_1R.jpg', 'cropped_img_trainval/1/train/img54594992_01_2L.jpg', 'cropped_img_trainval/1/train/img40335923_01_1R.jpg', 'cropped_img_trainval/1/train/img71116744_00_1R.jpg', 'cropped_img_trainval/1/train/img60774061_04_1R.jpg', 'cropped_img_trainval/1/train/img45251043_01_1R.jpg', 'cropped_img_trainval/1/train/img57986605_00_2R.jpg', 'cropped_img_trainval/1/train/img76888512_00_2L.jpg', 'cropped_img_trainval/1/train/img30672827_02_2L.jpg', 'cropped_img_trainval/1/train/img53994905_10_1R.jpg', 'cropped_img_trainval/1/train/img42053837_04_2L.jpg', 'cropped_img_trainval/1/train/img18347006_11_1R.jpg', 'cropped_img_trainval/1/train/img62338475_02_1R.jpg', 'cropped_img_trainval/1/train/img41268862_02_1R.jpg', 'cropped_img_trainval/1/train/img29187515_01_1R.jpg', 'cropped_img_trainval/1/train/img35047283_11_1R.jpg', 'cropped_img_trainval/1/train/img46199104_00_1R.jpg', 'cropped_img_trainval/1/train/img49466235_01_2L.jpg', 'cropped_img_trainval/1/train/img17381281_03_1R.jpg', 'cropped_img_trainval/1/train/img35520414_01_2L.jpg', 'cropped_img_trainval/1/train/img66807511_01_1R.jpg', 'cropped_img_trainval/1/train/img52424587_02_1R.jpg', 'cropped_img_trainval/1/train/img74813273_03_2L.jpg', 'cropped_img_trainval/1/train/img68183346_11_1R.jpg', 'cropped_img_trainval/1/train/img31780049_03_2L.jpg', 'cropped_img_trainval/1/train/img63926584_07_1R.jpg', 'cropped_img_trainval/1/train/img72494417_00_1R.jpg', 'cropped_img_trainval/1/train/img02878859_09_1R.jpg', 'cropped_img_trainval/1/train/img39920736_09_1R.jpg', 'cropped_img_trainval/1/train/img38774257_10_1R.jpg', 'cropped_img_trainval/1/train/img32015480_00_1R.jpg', 'cropped_img_trainval/1/train/img29242862_00_1R.jpg', 'cropped_img_trainval/1/train/img58160025_03_1R.jpg', 'cropped_img_trainval/1/train/img32291006_01_1R.jpg', 'cropped_img_trainval/1/train/img31097686_00_1R.jpg', 'cropped_img_trainval/1/train/img45916965_03_1R.jpg', 'cropped_img_trainval/1/train/img76665880_03_2L.jpg', 'cropped_img_trainval/1/train/img46384548_01_2L.jpg', 'cropped_img_trainval/1/train/img59160703_06_1R.jpg', 'cropped_img_trainval/1/train/img47451348_00_2L.jpg', 'cropped_img_trainval/1/train/img13426508_02_1R.jpg', 'cropped_img_trainval/1/train/img75705547_01_1R.jpg', 'cropped_img_trainval/1/train/img12674294_00_1R.jpg', 'cropped_img_trainval/1/train/img56936375_04_2L.jpg', 'cropped_img_trainval/1/train/img00592251_02_2R.jpg', 'cropped_img_trainval/1/train/img58312320_01_1R.jpg', 'cropped_img_trainval/1/train/img68183296_10_2L.jpg', 'cropped_img_trainval/1/train/img15495677_11_1R.jpg', 'cropped_img_trainval/1/train/img62944587_04_2L.jpg', 'cropped_img_trainval/1/train/img04135433_08_1R.jpg', 'cropped_img_trainval/1/train/img52791132_01_2L.jpg', 'cropped_img_trainval/1/train/img40731228_07_2L.jpg', 'cropped_img_trainval/1/train/img22974304_09_1R.jpg', 'cropped_img_trainval/1/train/img57310853_00_1R.jpg', 'cropped_img_trainval/1/train/img25716170_05_2L.jpg', 'cropped_img_trainval/1/train/img61171704_00_1R.jpg', 'cropped_img_trainval/1/train/img51950020_00_2L.jpg', 'cropped_img_trainval/1/train/img34729303_00_2L.jpg', 'cropped_img_trainval/1/train/img10117692_04_3L.jpg', 'cropped_img_trainval/1/train/img64571289_01_2L.jpg', 'cropped_img_trainval/1/train/img14848645_09_2L.jpg', 'cropped_img_trainval/1/train/img49466235_03_1R.jpg', 'cropped_img_trainval/1/train/img71493496_08_2L.jpg', 'cropped_img_trainval/1/train/img71493496_09_1R.jpg', 'cropped_img_trainval/1/train/img08667124_00_1R.jpg', 'cropped_img_trainval/1/train/img40102833_00_2L.jpg', 'cropped_img_trainval/1/train/img60744675_08_1R.jpg', 'cropped_img_trainval/1/train/img60744675_09_1R.jpg', 'cropped_img_trainval/1/train/img62338475_03_1R.jpg', 'cropped_img_trainval/1/train/img08667124_01_1R.jpg', 'cropped_img_trainval/1/train/img21505163_01_1R.jpg', 'cropped_img_trainval/1/train/img21778209_03_1R.jpg', 'cropped_img_trainval/1/train/img21778209_04_1R.jpg', 'cropped_img_trainval/1/train/img21505163_00_1R.jpg', 'cropped_img_trainval/1/train/img21778209_04_2L.jpg', 'cropped_img_trainval/1/train/img46917958_00_2L.jpg', 'cropped_img_trainval/1/train/img70863402_10_1R.jpg', 'cropped_img_trainval/1/train/img46917958_00_1R.jpg', 'cropped_img_trainval/1/train/img31601741_00_1R.jpg', 'cropped_img_trainval/1/train/img37877063_00_2L.jpg', 'cropped_img_trainval/1/train/img37877063_00_1R.jpg', 'cropped_img_trainval/1/train/img34683566_00_1R.jpg', 'cropped_img_trainval/1/train/img34683566_01_2L.jpg', 'cropped_img_trainval/1/train/img34683566_01_1R.jpg', 'cropped_img_trainval/1/train/img41589846_02_1R.jpg', 'cropped_img_trainval/1/train/img41589846_00_1R.jpg', 'cropped_img_trainval/1/train/img75595727_00_2L.jpg', 'cropped_img_trainval/1/train/img75595727_00_1R.jpg', 'cropped_img_trainval/1/train/img26943846_08_1R.jpg', 'cropped_img_trainval/1/train/img37973388_03_1R.jpg', 'cropped_img_trainval/1/train/img66074866_02_1R.jpg', 'cropped_img_trainval/1/train/img07082899_01_1R.jpg', 'cropped_img_trainval/1/train/img15925331_01_1R.jpg', 'cropped_img_trainval/1/train/img15925331_02_1R.jpg', 'cropped_img_trainval/1/train/img66074866_02_2L.jpg', 'cropped_img_trainval/1/train/img39596796_11_1R.jpg', 'cropped_img_trainval/1/train/img41168264_00_1R.jpg', 'cropped_img_trainval/1/train/img56354214_04_1R.jpg', 'cropped_img_trainval/1/train/img56354214_05_2L.jpg', 'cropped_img_trainval/1/train/img56354214_05_1R.jpg', 'cropped_img_trainval/1/train/img25223732_00_1R.jpg', 'cropped_img_trainval/1/train/img25580248_10_1R.jpg', 'cropped_img_trainval/1/train/img25223732_01_2L.jpg', 'cropped_img_trainval/1/train/img25223732_01_1R.jpg', 'cropped_img_trainval/1/train/img25580248_10_3L.jpg', 'cropped_img_trainval/1/train/img10760169_10_1R.jpg', 'cropped_img_trainval/1/train/img04135433_09_2L.jpg', 'cropped_img_trainval/1/train/img62924501_00_1R.jpg', 'cropped_img_trainval/1/train/img04135433_09_1R.jpg', 'cropped_img_trainval/1/train/img04135433_08_2L.jpg', 'cropped_img_trainval/1/train/img31817000_02_1R.jpg', 'cropped_img_trainval/1/train/img11569243_08_1R.jpg', 'cropped_img_trainval/1/train/img11569243_08_2L.jpg', 'cropped_img_trainval/1/train/img05622480_00_1R.jpg', 'cropped_img_trainval/1/train/img29589303_00_1R.jpg', 'cropped_img_trainval/1/train/img49652223_00_1R.jpg', 'cropped_img_trainval/1/train/img64146029_11_1R.jpg', 'cropped_img_trainval/1/train/img17469359_01_1R.jpg', 'cropped_img_trainval/1/train/img64146029_11_2L.jpg', 'cropped_img_trainval/1/train/img54712384_04_1R.jpg', 'cropped_img_trainval/1/train/img67993092_08_1R.jpg', 'cropped_img_trainval/1/train/img67993092_07_1R.jpg', 'cropped_img_trainval/1/train/img24738913_01_1R.jpg', 'cropped_img_trainval/1/train/img24738913_02_1R.jpg', 'cropped_img_trainval/1/train/img24738913_02_2L.jpg', 'cropped_img_trainval/1/train/img29826053_01_1R.jpg', 'cropped_img_trainval/1/train/img09422589_01_1R.jpg', 'cropped_img_trainval/1/train/img08922907_00_2L.jpg', 'cropped_img_trainval/1/train/img08922907_00_1R.jpg', 'cropped_img_trainval/1/train/img18291150_02_2L.jpg', 'cropped_img_trainval/1/train/img18291150_02_1R.jpg', 'cropped_img_trainval/1/train/img11905115_00_1R.jpg', 'cropped_img_trainval/1/train/img55285397_02_1R.jpg', 'cropped_img_trainval/1/train/img55285397_02_2L.jpg', 'cropped_img_trainval/1/train/img71758610_10_1R.jpg', 'cropped_img_trainval/1/train/img34476164_01_1R.jpg', 'cropped_img_trainval/1/train/img74261588_00_1R.jpg', 'cropped_img_trainval/1/train/img43523596_06_1R.jpg', 'cropped_img_trainval/1/train/img45251043_02_1R.jpg', 'cropped_img_trainval/1/train/img45251043_01_2L.jpg', 'cropped_img_trainval/1/train/img43523596_05_1R.jpg', 'cropped_img_trainval/1/train/img45251043_02_2L.jpg', 'cropped_img_trainval/1/train/img12210048_01_4L.jpg', 'cropped_img_trainval/1/train/img12210048_01_1R.jpg', 'cropped_img_trainval/1/train/img07360433_00_1R.jpg', 'cropped_img_trainval/1/train/img07360433_00_2L.jpg', 'cropped_img_trainval/1/train/img12210048_01_3L.jpg', 'cropped_img_trainval/1/train/img12210048_01_2R.jpg', 'cropped_img_trainval/1/train/img18261413_00_1R.jpg', 'cropped_img_trainval/1/train/img59919569_01_3L.jpg', 'cropped_img_trainval/1/train/img59919569_00_2L.jpg', 'cropped_img_trainval/1/train/img59919569_01_2R.jpg', 'cropped_img_trainval/1/train/img59919569_01_1R.jpg', 'cropped_img_trainval/1/train/img59919569_00_1R.jpg', 'cropped_img_trainval/1/train/img59919569_01_4L.jpg', 'cropped_img_trainval/1/train/img03706412_00_1R.jpg', 'cropped_img_trainval/1/train/img66048601_01_3L.jpg', 'cropped_img_trainval/1/train/img66048601_00_1R.jpg', 'cropped_img_trainval/1/train/img66048601_01_1R.jpg', 'cropped_img_trainval/1/train/img58170852_10_2L.jpg', 'cropped_img_trainval/1/train/img58170852_10_1R.jpg', 'cropped_img_trainval/1/train/img58170852_09_2L.jpg', 'cropped_img_trainval/1/train/img53364757_00_1R.jpg', 'cropped_img_trainval/1/train/img57941461_06_1R.jpg', 'cropped_img_trainval/1/train/img34633324_00_1R.jpg', 'cropped_img_trainval/1/train/img34633324_00_2L.jpg', 'cropped_img_trainval/1/train/img49209012_00_1R.jpg', 'cropped_img_trainval/1/train/img49209012_01_2L.jpg', 'cropped_img_trainval/1/train/img49209012_01_1R.jpg', 'cropped_img_trainval/1/train/img57176720_11_1R.jpg', 'cropped_img_trainval/1/train/img57176720_11_2L.jpg', 'cropped_img_trainval/1/train/img70305625_08_1R.jpg', 'cropped_img_trainval/1/train/img70305625_07_1R.jpg', 'cropped_img_trainval/1/train/img70305625_08_2L.jpg', 'cropped_img_trainval/1/train/img42326059_07_2L.jpg', 'cropped_img_trainval/1/train/img42326059_07_1R.jpg', 'cropped_img_trainval/1/train/img70305625_07_2L.jpg', 'cropped_img_trainval/1/train/img22664137_04_1R.jpg', 'cropped_img_trainval/1/train/img22664137_04_2L.jpg', 'cropped_img_trainval/1/train/img59158904_10_1R.jpg', 'cropped_img_trainval/1/train/img34985444_00_1R.jpg', 'cropped_img_trainval/1/train/img59441771_03_1R.jpg', 'cropped_img_trainval/1/train/img59158904_09_1R.jpg', 'cropped_img_trainval/1/train/img59158904_10_2L.jpg', 'cropped_img_trainval/1/train/img16278735_00_2L.jpg', 'cropped_img_trainval/1/train/img20419374_00_1L.jpg', 'cropped_img_trainval/1/train/img55733305_01_1R.jpg', 'cropped_img_trainval/1/train/img55733305_00_1R.jpg', 'cropped_img_trainval/1/train/img76703849_00_1R.jpg', 'cropped_img_trainval/1/train/img13571577_03_1R.jpg', 'cropped_img_trainval/1/train/img13571577_03_2L.jpg', 'cropped_img_trainval/1/train/img72712472_07_1R.jpg', 'cropped_img_trainval/1/train/img07144546_01_1R.jpg', 'cropped_img_trainval/1/train/img07144546_01_2L.jpg', 'cropped_img_trainval/1/train/img72712472_08_1R.jpg', 'cropped_img_trainval/1/train/img35841719_02_2L.jpg', 'cropped_img_trainval/1/train/img35841719_02_1R.jpg', 'cropped_img_trainval/1/train/img73019216_10_1R.jpg', 'cropped_img_trainval/1/train/img73019216_10_2L.jpg', 'cropped_img_trainval/1/train/img63939358_00_1R.jpg', 'cropped_img_trainval/1/train/img14005678_00_1R.jpg', 'cropped_img_trainval/1/train/img55506120_00_1R.jpg', 'cropped_img_trainval/1/train/img57986605_00_3L.jpg', 'cropped_img_trainval/1/train/img57986605_00_4L.jpg', 'cropped_img_trainval/1/train/img72689911_01_1R.jpg', 'cropped_img_trainval/1/train/img72689911_01_2L.jpg', 'cropped_img_trainval/1/train/img72201054_01_1R.jpg', 'cropped_img_trainval/1/train/img43981314_00_1R.jpg', 'cropped_img_trainval/1/train/img33368729_02_2L.jpg', 'cropped_img_trainval/1/train/img33368729_02_1R.jpg', 'cropped_img_trainval/1/train/img29176203_01_1R.jpg', 'cropped_img_trainval/1/train/img29176203_01_2L.jpg', 'cropped_img_trainval/1/train/img29176203_00_1R.jpg', 'cropped_img_trainval/1/train/img43617641_00_1R.jpg', 'cropped_img_trainval/1/train/img43617641_00_2L.jpg', 'cropped_img_trainval/1/train/img70491752_00_1R.jpg', 'cropped_img_trainval/1/train/img52403735_00_1R.jpg', 'cropped_img_trainval/1/train/img27065475_00_1R.jpg', 'cropped_img_trainval/1/train/img21412899_00_1R.jpg', 'cropped_img_trainval/1/train/img21412899_00_2R.jpg', 'cropped_img_trainval/1/train/img62657370_10_1R.jpg', 'cropped_img_trainval/1/train/img21412899_00_3L.jpg', 'cropped_img_trainval/1/train/img03913316_00_1R.jpg', 'cropped_img_trainval/1/train/img03913316_00_2L.jpg', 'cropped_img_trainval/1/train/img00693731_03_1R.jpg', 'cropped_img_trainval/1/train/img00693731_02_2L.jpg', 'cropped_img_trainval/1/train/img00592251_02_1R.jpg', 'cropped_img_trainval/1/train/img00693731_02_1R.jpg', 'cropped_img_trainval/1/train/img00592251_02_3L.jpg', 'cropped_img_trainval/1/train/img00693731_00_1R.jpg', 'cropped_img_trainval/1/train/img00693731_03_2L.jpg', 'cropped_img_trainval/1/train/img07989911_00_1R.jpg', 'cropped_img_trainval/1/train/img07989911_00_2L.jpg', 'cropped_img_trainval/1/train/img36633612_03_1L.jpg', 'cropped_img_trainval/1/train/img36633612_01_1L.jpg', 'cropped_img_trainval/1/train/img36633612_04_1L.jpg', 'cropped_img_trainval/1/train/img36633612_04_2L.jpg', 'cropped_img_trainval/1/train/img31618454_01_1R.jpg', 'cropped_img_trainval/1/train/img31618454_00_1R.jpg', 'cropped_img_trainval/1/train/img29242862_00_2R.jpg', 'cropped_img_trainval/1/train/img46074930_01_1R.jpg', 'cropped_img_trainval/1/train/img67169769_11_2L.jpg', 'cropped_img_trainval/1/train/img67169769_11_1R.jpg', 'cropped_img_trainval/1/train/img25759931_00_1R.jpg', 'cropped_img_trainval/1/train/img70165765_05_2L.jpg', 'cropped_img_trainval/1/train/img70165765_05_1R.jpg', 'cropped_img_trainval/1/train/img42257680_00_2L.jpg', 'cropped_img_trainval/1/train/img42257680_00_1R.jpg', 'cropped_img_trainval/1/train/img07349977_04_2L.jpg', 'cropped_img_trainval/1/train/img41397025_02_1R.jpg', 'cropped_img_trainval/1/train/img41397025_02_2L.jpg', 'cropped_img_trainval/1/train/img39609896_08_1R.jpg', 'cropped_img_trainval/1/train/img39609896_07_1R.jpg', 'cropped_img_trainval/1/train/img63926584_08_3L.jpg', 'cropped_img_trainval/1/train/img63926584_08_1R.jpg', 'cropped_img_trainval/1/train/img63926584_08_2R.jpg', 'cropped_img_trainval/1/train/img63926584_08_4L.jpg', 'cropped_img_trainval/1/train/img39920736_08_1R.jpg', 'cropped_img_trainval/1/train/img06713174_10_1R.jpg', 'cropped_img_trainval/1/train/img06713174_09_1R.jpg', 'cropped_img_trainval/1/train/img04103550_05_1R.jpg', 'cropped_img_trainval/1/train/img57759888_11_2L.jpg', 'cropped_img_trainval/1/train/img57759888_11_1R.jpg', 'cropped_img_trainval/1/train/img51260583_02_2L.jpg', 'cropped_img_trainval/1/train/img51260583_02_1R.jpg', 'cropped_img_trainval/1/train/img51260583_03_1R.jpg', 'cropped_img_trainval/1/train/img33016405_07_1R.jpg', 'cropped_img_trainval/1/train/img33016405_06_1R.jpg', 'cropped_img_trainval/1/train/img76791392_10_1R.jpg', 'cropped_img_trainval/1/train/img53338762_05_2L.jpg', 'cropped_img_trainval/1/train/img53338762_05_1R.jpg', 'cropped_img_trainval/1/train/img65853592_04_1R.jpg', 'cropped_img_trainval/1/train/img65853592_03_1R.jpg', 'cropped_img_trainval/1/train/img09194545_01_1R.jpg', 'cropped_img_trainval/1/train/img45566859_04_1R.jpg', 'cropped_img_trainval/1/train/img49307959_09_1R.jpg', 'cropped_img_trainval/1/train/img49307959_10_1R.jpg', 'cropped_img_trainval/1/train/img36120795_08_3L.jpg', 'cropped_img_trainval/1/train/img36120795_08_1R.jpg', 'cropped_img_trainval/1/train/img36120795_09_2L.jpg', 'cropped_img_trainval/1/train/img36120795_09_1R.jpg', 'cropped_img_trainval/1/train/img36120795_08_2R.jpg', 'cropped_img_trainval/1/train/img23403422_08_1R.jpg', 'cropped_img_trainval/1/train/img23403422_09_1R.jpg', 'cropped_img_trainval/1/train/img66244694_05_1R.jpg', 'cropped_img_trainval/1/train/img21552717_05_1R.jpg', 'cropped_img_trainval/1/train/img60137422_05_1R.jpg', 'cropped_img_trainval/1/train/img43018859_02_1R.jpg', 'cropped_img_trainval/1/train/img67587873_01_1R.jpg', 'cropped_img_trainval/1/train/img70355293_05_3L.jpg', 'cropped_img_trainval/1/train/img70355293_05_1R.jpg', 'cropped_img_trainval/1/train/img70355293_05_2R.jpg', 'cropped_img_trainval/1/train/img44874369_04_1R.jpg', 'cropped_img_trainval/1/train/img14980414_02_1R.jpg', 'cropped_img_trainval/1/train/img59793338_05_1R.jpg', 'cropped_img_trainval/1/train/img69400239_04_2L.jpg', 'cropped_img_trainval/1/train/img69400239_04_1R.jpg', 'cropped_img_trainval/1/train/img61900998_05_1R.jpg', 'cropped_img_trainval/1/train/img61900998_04_1R.jpg', 'cropped_img_trainval/1/train/img24496488_03_1R.jpg', 'cropped_img_trainval/1/train/img24496488_03_2L.jpg', 'cropped_img_trainval/1/train/img02878859_10_1R.jpg', 'cropped_img_trainval/1/train/img19785851_01_1R.jpg', 'cropped_img_trainval/1/train/img12627157_03_1R.jpg', 'cropped_img_trainval/1/train/img10059159_08_1R.jpg', 'cropped_img_trainval/1/train/img10059159_09_1R.jpg', 'cropped_img_trainval/1/train/img63009490_02_1R.jpg', 'cropped_img_trainval/1/train/img43618854_05_1R.jpg', 'cropped_img_trainval/1/train/img43618854_05_2L.jpg', 'cropped_img_trainval/1/train/img47491392_02_2L.jpg', 'cropped_img_trainval/1/train/img47491392_02_1R.jpg', 'cropped_img_trainval/1/train/img74465180_09_1R.jpg', 'cropped_img_trainval/1/train/img69313660_01_1R.jpg', 'cropped_img_trainval/1/train/img67513694_04_1R.jpg', 'cropped_img_trainval/1/train/img67513694_05_1R.jpg', 'cropped_img_trainval/1/train/img68412213_07_2L.jpg', 'cropped_img_trainval/1/train/img18347006_10_2L.jpg', 'cropped_img_trainval/1/train/img18347006_10_1R.jpg', 'cropped_img_trainval/1/train/img63557039_10_1R.jpg', 'cropped_img_trainval/1/train/img05834794_10_2L.jpg', 'cropped_img_trainval/1/train/img05834794_10_1R.jpg', 'cropped_img_trainval/1/train/img39709495_03_1R.jpg', 'cropped_img_trainval/1/train/img13259746_06_1R.jpg', 'cropped_img_trainval/1/train/img15168560_04_1R.jpg', 'cropped_img_trainval/1/train/img61863873_09_1R.jpg', 'cropped_img_trainval/1/train/img26260553_03_1R.jpg', 'cropped_img_trainval/1/train/img27806229_04_1R.jpg', 'cropped_img_trainval/1/train/img01342796_07_1R.jpg', 'cropped_img_trainval/1/train/img27202504_10_1R.jpg', 'cropped_img_trainval/1/train/img27202504_09_2L.jpg', 'cropped_img_trainval/1/train/img27202504_09_1R.jpg', 'cropped_img_trainval/1/train/img70882169_02_1R.jpg', 'cropped_img_trainval/1/train/img51950020_00_1R.jpg', 'cropped_img_trainval/1/train/img00699409_00_1R.jpg', 'cropped_img_trainval/1/train/img39306088_00_1R.jpg', 'cropped_img_trainval/1/train/img03119762_00_1R.jpg', 'cropped_img_trainval/1/train/img64571289_00_1R.jpg', 'cropped_img_trainval/1/train/img64571289_01_1R.jpg', 'cropped_img_trainval/1/train/img70338032_07_1L.jpg', 'cropped_img_trainval/1/train/img70338032_08_1R.jpg', 'cropped_img_trainval/1/train/img33522858_01_1R.jpg', 'cropped_img_trainval/1/train/img13676553_10_1R.jpg', 'cropped_img_trainval/1/train/img13676553_09_2L.jpg', 'cropped_img_trainval/1/train/img13676553_10_2L.jpg', 'cropped_img_trainval/1/train/img13676553_09_1R.jpg', 'cropped_img_trainval/1/train/img05922508_00_1R.jpg', 'cropped_img_trainval/1/train/img05922508_00_2L.jpg', 'cropped_img_trainval/1/train/img28189064_01_1R.jpg', 'cropped_img_trainval/1/train/img28742331_00_1R.jpg', 'cropped_img_trainval/1/train/img28742331_01_4L.jpg', 'cropped_img_trainval/1/train/img28742331_01_2R.jpg', 'cropped_img_trainval/1/train/img28742331_01_3L.jpg', 'cropped_img_trainval/1/train/img28742331_01_1R.jpg', 'cropped_img_trainval/1/train/img63396275_00_1R.jpg', 'cropped_img_trainval/1/train/img63396275_00_2L.jpg', 'cropped_img_trainval/1/train/img49466235_01_1R.jpg', 'cropped_img_trainval/1/train/img53697861_01_2L.jpg', 'cropped_img_trainval/1/train/img53697861_01_1R.jpg', 'cropped_img_trainval/1/train/img49466235_02_2R.jpg', 'cropped_img_trainval/1/train/img49466235_02_1R.jpg', 'cropped_img_trainval/1/train/img49466235_02_3L.jpg', 'cropped_img_trainval/1/train/img49466235_02_4L.jpg', 'cropped_img_trainval/1/train/img49466235_03_2R.jpg', 'cropped_img_trainval/1/train/img49466235_03_4L.jpg', 'cropped_img_trainval/1/train/img41386095_00_2L.jpg', 'cropped_img_trainval/1/train/img41386095_00_1R.jpg', 'cropped_img_trainval/1/train/img41386095_01_1R.jpg', 'cropped_img_trainval/1/train/img41386095_01_2L.jpg', 'cropped_img_trainval/1/train/img01951855_07_1L.jpg', 'cropped_img_trainval/1/train/img03136594_00_1R.jpg', 'cropped_img_trainval/1/train/img25947765_00_1R.jpg', 'cropped_img_trainval/1/train/img54594992_01_1R.jpg', 'cropped_img_trainval/1/train/img54209894_03_1R.jpg', 'cropped_img_trainval/1/train/img54209894_03_2L.jpg', 'cropped_img_trainval/1/train/img60317724_00_1R.jpg', 'cropped_img_trainval/1/train/img34045200_00_1R.jpg', 'cropped_img_trainval/1/train/img34045200_01_1R.jpg', 'cropped_img_trainval/1/train/img39508525_03_1R.jpg', 'cropped_img_trainval/1/train/img39508525_03_2L.jpg', 'cropped_img_trainval/1/train/img39508525_01_1R.jpg', 'cropped_img_trainval/1/train/img39508525_00_1R.jpg', 'cropped_img_trainval/1/train/img28768900_00_2L.jpg', 'cropped_img_trainval/1/train/img28768900_01_2L.jpg', 'cropped_img_trainval/1/train/img28768900_01_1R.jpg', 'cropped_img_trainval/1/train/img28768900_00_1R.jpg', 'cropped_img_trainval/1/train/img66134736_06_1R.jpg', 'cropped_img_trainval/1/train/img55137546_05_2L.jpg', 'cropped_img_trainval/1/train/img67247777_02_2L.jpg', 'cropped_img_trainval/1/train/img40566913_00_1R.jpg', 'cropped_img_trainval/1/train/img74747641_02_1R.jpg', 'cropped_img_trainval/1/train/img36548197_02_1R.jpg', 'cropped_img_trainval/1/train/img30561348_00_1R.jpg', 'cropped_img_trainval/1/train/img66993260_10_2L.jpg', 'cropped_img_trainval/1/train/img68682155_11_3L.jpg', 'cropped_img_trainval/1/train/img32566823_01_1R.jpg', 'cropped_img_trainval/1/train/img29059152_04_1R.jpg', 'cropped_img_trainval/1/train/img28206284_07_1R.jpg', 'cropped_img_trainval/1/train/img28206284_07_3L.jpg', 'cropped_img_trainval/1/train/img74747641_02_2L.jpg', 'cropped_img_trainval/1/train/img09765475_00_2L.jpg', 'cropped_img_trainval/1/train/img35316432_00_1R.jpg', 'cropped_img_trainval/1/train/img09156423_06_3L.jpg', 'cropped_img_trainval/1/train/img59191778_00_1R.jpg', 'cropped_img_trainval/1/train/img53451998_06_2L.jpg', 'cropped_img_trainval/1/train/img11171803_05_1R.jpg', 'cropped_img_trainval/1/train/img68183346_12_2L.jpg', 'cropped_img_trainval/1/train/img70846819_06_1R.jpg', 'cropped_img_trainval/1/train/img40566913_00_2L.jpg', 'cropped_img_trainval/1/train/img68682155_11_1R.jpg', 'cropped_img_trainval/1/train/img22008858_08_2L.jpg', 'cropped_img_trainval/1/train/img53451998_05_1R.jpg', 'cropped_img_trainval/1/train/img53366903_01_2L.jpg', 'cropped_img_trainval/1/train/img48881191_09_2L.jpg', 'cropped_img_trainval/1/train/img24356572_06_4L.jpg', 'cropped_img_trainval/1/train/img37390443_00_2L.jpg', 'cropped_img_trainval/1/train/img22008858_08_1R.jpg', 'cropped_img_trainval/1/train/img53366903_01_1R.jpg', 'cropped_img_trainval/1/train/img47701062_03_1R.jpg', 'cropped_img_trainval/1/train/img11594645_01_1R.jpg', 'cropped_img_trainval/1/train/img54103052_03_1R.jpg', 'cropped_img_trainval/1/train/img20052837_05_2L.jpg', 'cropped_img_trainval/1/train/img32566823_01_2L.jpg', 'cropped_img_trainval/1/train/img20052837_06_1R.jpg', 'cropped_img_trainval/1/train/img09765475_00_1R.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg_lhEMldF5v"
      },
      "source": [
        "#**Load network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rVSslGCJNPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7939b51-f295-47c5-e5e4-1f35716dc046"
      },
      "source": [
        "name = \"vascular\"\n",
        "model = \"A2\"  #A2 or B3\n",
        "\n",
        "MODEL_NAME = name +\"_\"+model+\"_pretrained\"\n",
        "DATASET_NAME = name+'_img_trainval'\n",
        "DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "NET_NAME = \"RepVGG_\" +model  #RepVGG_A2 or RepVGG_B3\n",
        "PRETRAINED = True\n",
        "\n",
        "TRAIN_FOLDER_NAME = 'train' #TRAINイメージのフォルダ\n",
        "VAL_FOLDER_NAME = 'val' #VALイメージのフォルダ\n",
        "\n",
        "FILENAME_LABELCSV = 'name_age.csv' #年齢の値のcsv\n",
        "FILENAME_RESULTCSV = 'result.csv' #年齢推定結果を書き出すcsv\n",
        "FILENAME_RESULT_ANALYSISCSV = 'result_analysis.csv' #推定結果の解析結果を書き出すcsv\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto/model'\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "\n",
        "if NET_NAME == \"RepVGG_A2\":\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "elif NET_NAME == \"RepVGG_B3\":\n",
        "    model_ft = create_RepVGG_B3(deploy=False)\n",
        "\n",
        "else:\n",
        "    print(\"RepVGG_A2あるいはRepVGG_B3を指定して下さい\")\n",
        "    sys.exit(1)\n",
        "\n",
        "#model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7Jlr21roBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f65adea9-5936-4aa6-b1d6-1652ec8e1bf0"
      },
      "source": [
        "#ここからがメイン\n",
        "process = [0,1,2,3,4]\n",
        "for i in process:\n",
        "    print(\"Start \"+ str(i) + \" th analysis!\")\n",
        "\n",
        "    #トレーニングしたパラメーターを適用\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    model_ft.load_state_dict(torch.load(PATH))\n",
        "    model_ft.eval()\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    print(PATH)\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    #valフォルダ内のファイル名を取得\n",
        "    train_data_path = glob.glob(DATASET_NAME + \"/\" +str(i) + \"/\" + TRAIN_FOLDER_NAME+\"/*\")\n",
        "    val_data_path = glob.glob(DATASET_NAME + \"/\" + str(i) + \"/\" + VAL_FOLDER_NAME+\"/*\")\n",
        "\n",
        "    data_path = [train_data_path, val_data_path]\n",
        "    preds,targets,errors =[], [], []\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        for m in j:\n",
        "              image_name, label = getlabel(df_result, os.path.basename(m))  #画像の名前とラベルを取得\n",
        "              image_tensor = image_transform(m)  #予測のための画像下処理\n",
        "              pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "              write_result(df_result, image_name, pred, MODEL_NAME+\"_\"+str(i))\n",
        "              print(str(k)+\"/\"+str(len(df_result))+\" th image: \"+str(image_name)+\", pred: \"+str(my_round(pred, d=1))+\", label: \"+str(label))\n",
        "\n",
        "              preds.append(pred)      \n",
        "              targets.append(label)\n",
        "              errors.append(pred-label)\n",
        "\n",
        "              k+=1\n",
        "    print(df_result)\n",
        "\n",
        "    AbsError = [abs(i) for i in errors]\n",
        "    MeanError = str(statistics.mean(errors))\n",
        "    StdError = str(statistics.stdev(errors))\n",
        "    MeanAbsError = str(statistics.mean(AbsError))\n",
        "    StdAbsError = str(statistics.stdev(AbsError))\n",
        "    print('MeanError: '+MeanError)\n",
        "    print('StdError: '+StdError)\n",
        "    print('MeanAbsError: '+MeanAbsError)\n",
        "    print('StdAbsError: '+StdAbsError)\n",
        "    print()\n",
        "\n",
        "    #Resultファイルを書き出し\n",
        "    df_result.to_csv(FILENAME_RESULTCSV, index=False)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start 0 th analysis!\n",
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/model/vascular_A2_pretrained_0.pth\n",
            "Calculating prediction results!\n",
            "0/1414 th image: img67180094_09_1R.jpg, pred: 55.3, label: 61\n",
            "1/1414 th image: img67180094_10_1R.jpg, pred: 57.1, label: 61\n",
            "2/1414 th image: img67198698_01_1R.jpg, pred: 65.4, label: 60\n",
            "3/1414 th image: img67247777_02_2L.jpg, pred: 71.2, label: 75\n",
            "4/1414 th image: img67361603_02_1R.jpg, pred: 36.7, label: 36\n",
            "5/1414 th image: img67361603_02_2L.jpg, pred: 38.5, label: 36\n",
            "6/1414 th image: img67361603_03_1R.jpg, pred: 26.0, label: 36\n",
            "7/1414 th image: img67457175_06_1R.jpg, pred: 53.0, label: 67\n",
            "8/1414 th image: img67457175_06_2L.jpg, pred: 60.4, label: 67\n",
            "9/1414 th image: img67479127_11_1R.jpg, pred: 63.9, label: 63\n",
            "10/1414 th image: img67479127_12_2L.jpg, pred: 72.3, label: 63\n",
            "11/1414 th image: img67513694_04_1R.jpg, pred: 36.0, label: 27\n",
            "12/1414 th image: img67513694_05_1R.jpg, pred: 32.5, label: 27\n",
            "13/1414 th image: img67587873_01_1R.jpg, pred: 59.7, label: 39\n",
            "14/1414 th image: img67665685_00_1R.jpg, pred: 62.2, label: 61\n",
            "15/1414 th image: img67762668_09_1R.jpg, pred: 36.6, label: 48\n",
            "16/1414 th image: img67762668_10_1R.jpg, pred: 28.0, label: 48\n",
            "17/1414 th image: img67993092_07_1R.jpg, pred: 35.3, label: 59\n",
            "18/1414 th image: img67993092_08_1R.jpg, pred: 39.9, label: 59\n",
            "19/1414 th image: img67994073_06_1R.jpg, pred: 34.4, label: 46\n",
            "20/1414 th image: img67994073_07_1R.jpg, pred: 34.9, label: 46\n",
            "21/1414 th image: img68183296_09_1L.jpg, pred: 32.8, label: 51\n",
            "22/1414 th image: img68183296_10_1R.jpg, pred: 64.3, label: 51\n",
            "23/1414 th image: img68183296_10_2L.jpg, pred: 49.7, label: 51\n",
            "24/1414 th image: img68183346_11_1R.jpg, pred: 77.2, label: 80\n",
            "25/1414 th image: img68183346_12_2L.jpg, pred: 76.0, label: 80\n",
            "26/1414 th image: img68237122_06_1L.jpg, pred: 36.4, label: 35\n",
            "27/1414 th image: img68237122_07_1R.jpg, pred: 46.2, label: 35\n",
            "28/1414 th image: img68404896_04_1L.jpg, pred: 52.1, label: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-28-973b17a10592>\", line 25, in <module>\n",
            "    image_tensor = image_transform(m)  #予測のための画像下処理\n",
            "  File \"<ipython-input-25-c9841ddac96d>\", line 551, in image_transform\n",
            "    image=Image.open(image_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2852, in open\n",
            "    prefix = fp.read(16)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 732, in getmodule\n",
            "    for modname, module in sys.modules.copy().items():\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdMWm5gkEsXa",
        "outputId": "3fe2aae0-dc55-4962-87be-95b8dbbd3fef"
      },
      "source": [
        "#######################\n",
        "##1枚の画像のみを判定\n",
        "#######################\n",
        "\n",
        "print(MODEL_PATH)\n",
        "print(MODEL_NAME)\n",
        "\n",
        "#ファイル名を取得\n",
        "img_name = \"img00085008_00_1R.jpg\"\n",
        "img_path1 = \"/content/drive/MyDrive/Deep_learning/FundusPhoto/\"+name+\"_img_trainval/0/train/\"+img_name\n",
        "img_path2 = \"/content/drive/MyDrive/Deep_learning/FundusPhoto/\"+name+\"_img_trainval/0/val/\"+img_name\n",
        "\n",
        "for i in [img_path1, img_path2]:\n",
        "    is_file = os.path.isfile(i)\n",
        "    if is_file:\n",
        "        img_path = i\n",
        "        print(\"aaa\")\n",
        "    else:\n",
        "        pass # パスが存在しないかファイルではない\n",
        "        print(\"bbb\")\n",
        "\n",
        "\n",
        "outputs = []\n",
        "for i in range(5):\n",
        "    #トレーニングしたパラメーターを適用\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    model_ft.load_state_dict(torch.load(PATH))\n",
        "    model_ft.eval()\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    print(MODEL_NAME+'_'+str(i)+'.pth')\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    image_tensor = image_transform(img_path)  #予測のための画像下処理\n",
        "    pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "\n",
        "    outputs.append(pred)\n",
        "\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/model\n",
            "vascular_A2_pretrained\n",
            "aaa\n",
            "bbb\n",
            "vascular_A2_pretrained_0.pth\n",
            "Calculating prediction results!\n",
            "vascular_A2_pretrained_1.pth\n",
            "Calculating prediction results!\n",
            "vascular_A2_pretrained_2.pth\n",
            "Calculating prediction results!\n",
            "vascular_A2_pretrained_3.pth\n",
            "Calculating prediction results!\n",
            "vascular_A2_pretrained_4.pth\n",
            "Calculating prediction results!\n",
            "[51.482975482940674, 56.42057657241821, 60.83461046218872, 51.64870023727417, 50.59090852737427]\n"
          ]
        }
      ]
    }
  ]
}