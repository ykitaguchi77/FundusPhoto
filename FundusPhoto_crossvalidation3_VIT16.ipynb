{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled90.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/FundusPhoto/blob/main/FundusPhoto_crossvalidation3_VIT16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjtHca50fine"
      },
      "source": [
        "#変更点\n",
        "・TIMMを導入→EfficientNetv2 (480px→回転→450px)<br>\n",
        "・OptimizerにRangerAdabelief<br>\n",
        "・平均と標準偏差による標準化は行っていない<br>\n",
        "・回転の前に250px切り抜きを入れ、回転により画像が切れないようにした<br>\n",
        "・GaussianBlurを入れて解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4vbMuKXy9W6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fadee6-ba3c-4a44-9915-bcf037edb5d9"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "!pip install timm\n",
        "\n",
        "#!pip install adabelief-pytorch==0.1.0\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "import statistics\n",
        "import time\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "#あればGPUを使用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi -L\n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.1.0-py3-none-any.whl (72 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 37.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 71 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 902 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu111)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.1.0\n",
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n",
            "Collecting ranger-adabelief==0.1.0\n",
            "  Downloading ranger_adabelief-0.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from ranger-adabelief==0.1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (3.7.4.3)\n",
            "Installing collected packages: ranger-adabelief\n",
            "Successfully installed ranger-adabelief-0.1.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-af8e13bf-22ec-13df-849d-8aa467a6df22)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV9UyGl4BL3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "4f47d56e-d858-4f75-8713-11baf26ab51b"
      },
      "source": [
        "name = \"cropped_2\"\n",
        "model =  'vit16'\n",
        "version = \"\"\n",
        "if version is not \"\":\n",
        "    version = \"_\"+str(version)\n",
        "\n",
        "MODEL_NAME = name +\"_\"+model+version+\"_pretrained\"\n",
        "DATASET_NAME = name+'_img_trainval'\n",
        "DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "PRETRAINED = True\n",
        "\n",
        "os.chdir(DATASET_PATH)\n",
        "\n",
        "TRAIN_FOLDER_NAME = 'train' #TRAINイメージのフォルダ\n",
        "VAL_FOLDER_NAME = 'val' #VALイメージのフォルダ\n",
        "\n",
        "FILENAME_LABELCSV = 'name_age.csv' #年齢の値のcsv\n",
        "FILENAME_RESULTCSV = 'result_6.csv' #年齢推定結果を書き出すcsv\n",
        "FILENAME_RESULT_ANALYSISCSV = 'result_analysis_6.csv' #推定結果の解析結果を書き出すcsv\n",
        "\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto/model'\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "LOG_PATH = \"./log_multi.txt\"\n",
        "ROC_PATH = \"./roc_multi.png\"\n",
        "CHECKPOINT_COUNT = 10\n",
        "EPOCH = 100\n",
        "PATIENCE = 20 #early stopping patience; how long to wait after last time validation loss improved.\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "\n",
        "# transforms param\n",
        "PX = 224 #画像のサイズ\n",
        "\n",
        "#cropped_CLAHE_img\n",
        "NORMALIZE_AVE = [0.543, 0.353, 0.228]\n",
        "NORMALIZE_STD = [0.135, 0.11,  0.072]\n",
        "\n",
        "TRAIN_CROP_SCALE =(0.85,1.0)\n",
        "TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "TRAIN_CONTRAST_PARAM = 0.1\n",
        "TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "\n",
        "\n",
        "#csvファイルを開く\n",
        "df_labelcsv = pd.read_csv(FILENAME_LABELCSV)\n",
        "\n",
        "#csvファイルを表示\n",
        "print(df_labelcsv)\n",
        "\n",
        "#ID,ageの列の値をリストとして取り出す\n",
        "df_filename = df_labelcsv['filename'].values\n",
        "df_age = df_labelcsv['age'].values\n",
        "\n",
        "#CSVファイル内の画像数\n",
        "print(len(df_labelcsv))\n",
        "\n",
        "\"\"\"\n",
        "#画像フォルダ内の画像数\n",
        "print(len(os.listdir(DATASET_NAME +\"/\"+ TRAIN_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_NAME +\"/\"+ VAL_FOLDER_NAME))\n",
        "+len(os.listdir(DATASET_NAME +\"/\"+ TEST_FOLDER_NAME)))\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   filename  age\n",
            "0     img00085008_00_1R.jpg   61\n",
            "1     img00085024_00_1R.jpg   29\n",
            "2     img00241280_10_1R.jpg   51\n",
            "3     img00265140_00_1R.jpg   29\n",
            "4     img00265140_00_2L.jpg   29\n",
            "...                     ...  ...\n",
            "1409  img76791392_10_1R.jpg   38\n",
            "1410  img76843122_10_1R.jpg   49\n",
            "1411  img76843122_11_1R.jpg   49\n",
            "1412  img76888512_00_1R.jpg   74\n",
            "1413  img76888512_00_2L.jpg   74\n",
            "\n",
            "[1414 rows x 2 columns]\n",
            "1414\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#画像フォルダ内の画像数\\nprint(len(os.listdir(DATASET_NAME +\"/\"+ TRAIN_FOLDER_NAME))\\n+len(os.listdir(DATASET_NAME +\"/\"+ VAL_FOLDER_NAME))\\n+len(os.listdir(DATASET_NAME +\"/\"+ TEST_FOLDER_NAME)))\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ejg4rneA3qI"
      },
      "source": [
        "#**Modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srdzPaN3A1nr"
      },
      "source": [
        "####################################\n",
        "#Test with early-stopping\n",
        "####################################\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print, device=\"cuda:0\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "        self.device =device\n",
        "    def __call__(self, train_loss, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            if val_loss < train_loss/3:\n",
        "                #val_loss<train_loss/3であれば保存しない（収束が早すぎる）\n",
        "                self.trace_func('Excluded from counter due to too early convergence (val_loss<train_loss/3)')\n",
        "                self.counter = 0\n",
        "                #evaluator(model, device)\n",
        "            else:\n",
        "                self.best_score = score\n",
        "                self.save_checkpoint(val_loss, model)\n",
        "                self.counter = 0\n",
        "                #evaluator(model, device)\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, loss_func, batch_size, optimizer, patience, n_epochs, device):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    #Optimize GPU computation\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "        for batch, (image_tensor, target) in enumerate(train_loader, 1):\n",
        "            # convert batch-size labels to batch-size x 1 tensor\n",
        "            #target = target.squeeze(1)\n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=True):\n",
        "                output = model(image_tensor)      \n",
        "                # calculate the loss\n",
        "                loss = loss_func(output, target)\n",
        "\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            scaler.scale(loss).backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            scaler.update()\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "       \n",
        "        model.eval() # prep model for evaluation\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        for image_tensor, target in val_loader:  \n",
        "            #target = target.squeeze(1)         \n",
        "            target = target.view(len(target), 1)\n",
        "\n",
        "            image_tensor = image_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(image_tensor)\n",
        "            # calculate the loss\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' )\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(train_loss, valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "#####################################\n",
        "##### Evaluation of Accuracy #############\n",
        "#####################################\n",
        "\n",
        "def evaluator(model, device):\n",
        "    model_ft.eval() # prep model for evaluation\n",
        "    outputs,targets,errors =[], [], []\n",
        "    for image_tensor, target in val_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append((output[0]*100).item())      \n",
        "          targets.append((target[0]*100).item())\n",
        "          #print('estimate R:'+str(my_round(output[0,0].item()))+'mm, L:'+str(my_round(output[0,1].item()))+'mm / target R:'+str(target[0,0].item())+'mm, L:'+str(target[0,1].item())+'mm')\n",
        "\n",
        "          errors.append((output[0]*100).item()-(target[0]*100).item())\n",
        "    \n",
        "    AbsError = [abs(i) for i in errors]\n",
        "    MeanError = str(statistics.mean(errors))\n",
        "    StdError = str(statistics.stdev(errors))\n",
        "    MeanAbsError = str(statistics.mean(AbsError))\n",
        "    StdAbsError = str(statistics.stdev(AbsError))\n",
        "    print(\"Validation set:\")\n",
        "    print('MeanError: '+MeanError)\n",
        "    print('StdError: '+StdError)\n",
        "    print('MeanAbsError: '+MeanAbsError)\n",
        "    print('StdAbsError: '+StdAbsError)\n",
        "\n",
        "    for image_tensor, target in train_loader:  \n",
        "          target = target.view(len(target), 1)         \n",
        "          image_tensor = image_tensor.to(device)\n",
        "          target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model_ft(image_tensor)\n",
        "\n",
        "          outputs.append((output[0]*100).item())      \n",
        "          targets.append((target[0]*100).item())\n",
        "          #print('estimate R:'+str(my_round(output[0,0].item()))+'mm, L:'+str(my_round(output[0,1].item()))+'mm / target R:'+str(target[0,0].item())+'mm, L:'+str(target[0,1].item())+'mm')\n",
        "\n",
        "          errors.append((output[0]*100).item()-(target[0]*100).item())\n",
        "    \n",
        "    AbsError = [abs(i) for i in errors]\n",
        "    MeanError = str(statistics.mean(errors))\n",
        "    StdError = str(statistics.stdev(errors))\n",
        "    MeanAbsError = str(statistics.mean(AbsError))\n",
        "    StdAbsError = str(statistics.stdev(AbsError))\n",
        "    print(\"Train set:\")\n",
        "    print('MeanError: '+MeanError)\n",
        "    print('StdError: '+StdError)\n",
        "    print('MeanAbsError: '+MeanAbsError)\n",
        "    print('StdAbsError: '+StdAbsError)\n",
        "\n",
        "\n",
        "\n",
        "#Calculating result\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(result_csv, image_name):\n",
        "      image_name = image_name\n",
        "      label = df_result[df_result.iloc[:,0].str.contains(image_name)].iloc[0,1] #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "      return(image_name, label)\n",
        "\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor()])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def my_round(x, d=0): #四捨五入\n",
        "    p = 10 ** d\n",
        "    return float(math.floor((x * p) + math.copysign(0.5, x)))/p\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を出力\n",
        "def image_eval(image_tensor, model_ft): \n",
        "    output = model_ft(image_tensor).item()*100\n",
        "    return output\n",
        "\n",
        "#result.csvに結果を記入\n",
        "def write_result(df, image_name, pred, row):\n",
        "    df.loc[df_result.iloc[:,0].str.contains(image_name), row] = pred  #df_resultよりimage_nameが含まれる行を抜き出して年齢を取得\n",
        "\n",
        "\n",
        "\n",
        "#水増し後の画像を可視化する関数\n",
        "def show_img(dataset):\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(5):\n",
        "        image, label = dataset[i]\n",
        "        #image = image.permute(1, 2, 0)\n",
        "        image = image.numpy().transpose((1,2,0))\n",
        "        image = np.clip(image, 0, 1)\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
        "        plt.tick_params(bottom=False, left=False, right=False, top=False)\n",
        "        plt.imshow(image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####################################\n",
        "##### Datasets and Dataloader ############\n",
        "#####################################\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, folder_path, csv_path, transform):\n",
        "        self.transform = transform\n",
        "        self.folder_path = folder_path\n",
        "        self.item_paths = []\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "\n",
        "        for i in range(len(os.listdir(folder_path))):\n",
        "              img_name = os.listdir(self.folder_path)[i]\n",
        "              name = os.path.splitext(img_name)[0] #拡張子を削除したもの\n",
        "              age_temp = df_labelcsv[df_labelcsv['filename'].str.contains(name)].iloc[0,1] #age\n",
        "              self.age.append(float(age_temp)/100)\n",
        "\n",
        "              img_path = os.path.join(self.folder_path, img_name)\n",
        "              self.item_paths.append(img_path)\n",
        "              #self.item_dict[image_path] = self.age\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.item_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.item_paths[idx]\n",
        "        pilr_image = read_image(image_path)\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor([self.age[idx]])      \n",
        "        return tensor_image, target\n",
        "\n",
        "\n",
        "train_data_transforms = nn.Sequential(\n",
        "                transforms.RandomResizedCrop(250, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomRotation(degrees=10),\n",
        "                transforms.CenterCrop(PX),\n",
        "                transforms.GaussianBlur(3, sigma=(0.01, 3.0)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),        \n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                #transforms.Normalize(NORMALIZE_AVE, NORMALIZE_STD)\n",
        "                )\n",
        "val_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                #transforms.Normalize(NORMALIZE_AVE, NORMALIZE_STD)\n",
        "                ) \n",
        "test_data_transforms = nn.Sequential(\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ConvertImageDtype(torch.float32),\n",
        "                #transforms.Normalize(NORMALIZE_AVE, NORMALIZE_STD)\n",
        "                ) \n",
        "\n",
        "\n",
        "#画像の可視化\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, \"1\", TRAIN_FOLDER_NAME), FILENAME_LABELCSV, train_data_transforms)\n",
        "show_img(train_dataset)\n",
        "\n",
        "#print(train_dataset[1])\n",
        "\n",
        "elapsed_time = round(time.time() - start_time, 2)\n",
        "print(str(elapsed_time)+\" second\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_vu_7ypLCq1"
      },
      "source": [
        "#**Select Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3xB9sWXK-Pa"
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(timm.list_models(pretrained = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKFWkJs5zGgb"
      },
      "source": [
        "#**Data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM3zE1Ft0exa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdcca223-77f8-403b-dd3d-b2eb2a8af1dc"
      },
      "source": [
        "#ワンタッチ解析（process, model(A2/B3), dataset(cropped, disc, macula, vascular))\n",
        "#ここからがメイン\n",
        "start_time = time.time()\n",
        "\n",
        "name = [\"cropped_2\", \"disc_2\", \"macula_2\", \"vascular_2_RGB\"]\n",
        "version =  'vit16'\n",
        "if version is not \"\":\n",
        "    version = \"_\"+str(version)\n",
        "\n",
        "EPOCH = 160\n",
        "PATIENCE = 20\n",
        "\n",
        "process = [0,1,2,3,4]\n",
        "for n in name:\n",
        "        for i in process:\n",
        "            print(\"Start \"+str(n)+ \", \" +str(i)+\" th analysis!\")\n",
        "            DATASET_NAME = str(n) +'_img_trainval'\n",
        "            MODEL_NAME = str(n) +version+\"_pretrained\"\n",
        "\n",
        "            train_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, str(i), TRAIN_FOLDER_NAME), FILENAME_LABELCSV, train_data_transforms)\n",
        "            val_dataset = SimpleImageDataset(os.path.join(DATASET_NAME, str(i), VAL_FOLDER_NAME), FILENAME_LABELCSV,  val_data_transforms)\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "            #print(TRAIN_FOLDER_NAME + \"_dataset_size：\" + str(len(train_dataset)))\n",
        "            #print(VAL_FOLDER_NAME + \"_dataset_size：\" + str(len(val_dataset)))\n",
        "\n",
        "            ####################################\n",
        "            #ConvNetの調整\n",
        "            ####################################\n",
        "\n",
        "            model_ft = timm.create_model('vit_base_patch16_224_in21k', pretrained=True, num_classes=1)\n",
        "\n",
        "            #GPU使用\n",
        "            model_ft = model_ft.to(device)\n",
        "\n",
        "            #損失関数を定義\n",
        "            loss_func = nn.MSELoss()\n",
        "\n",
        "            #Optimizer\n",
        "            #optimizer_ft = torch.optim.AdamW(model_ft.parameters(), 0.0002)\n",
        "            \"\"\"\n",
        "            optimizer_ft = optim.AdaBound(\n",
        "                model_ft.parameters(),\n",
        "                lr= 1e-3,\n",
        "                betas= (0.9, 0.999),\n",
        "                final_lr = 0.1,\n",
        "                gamma=1e-3,\n",
        "                eps= 1e-8,\n",
        "                weight_decay=0,\n",
        "                amsbound=False,\n",
        "            )\n",
        "            \"\"\"\n",
        "            #optimizer_ft = AdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = False)\n",
        "            #optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999), weight_decouple = True)\n",
        "            optimizer_ft = optim.DiffGrad(\n",
        "                model.parameters(),\n",
        "                lr= 1e-3,\n",
        "                betas=(0.9, 0.999),\n",
        "                eps=1e-8,\n",
        "                weight_decay=0,\n",
        "            )\n",
        "\n",
        "            ####################################\n",
        "            # Train and Save network\n",
        "            ####################################\n",
        "\n",
        "            model, train_loss, valid_loss = train_model(model_ft, loss_func, BATCH_SIZE, optimizer_ft, PATIENCE, EPOCH, device)\n",
        "\n",
        "            #ネットワークの保存\n",
        "            PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "            torch.save(model_ft.state_dict(), PATH)\n",
        "\n",
        "            ####################################\n",
        "            # Result Analysis\n",
        "            ####################################\n",
        "\n",
        "            model_ft.eval() # prep model for evaluation\n",
        "\n",
        "            outputs,targets,errors =[], [], []\n",
        "            for image_tensor, target in val_loader:  \n",
        "                  target = target.view(len(target), 1)         \n",
        "                  image_tensor = image_tensor.to(device)\n",
        "                  target = target.to(device)\n",
        "                  # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                  output = model_ft(image_tensor)\n",
        "\n",
        "                  outputs.append((output[0]*100).item())      \n",
        "                  targets.append((target[0]*100).item())\n",
        "                  #print('estimate R:'+str(my_round(output[0,0].item()))+'mm, L:'+str(my_round(output[0,1].item()))+'mm / target R:'+str(target[0,0].item())+'mm, L:'+str(target[0,1].item())+'mm')\n",
        "\n",
        "                  errors.append((output[0]*100).item()-(target[0]*100).item())\n",
        "            \n",
        "            print(\"Validation set:\")\n",
        "            AbsError = [abs(i) for i in errors]\n",
        "            MeanError = str(statistics.mean(errors))\n",
        "            StdError = str(statistics.stdev(errors))\n",
        "            MeanAbsError = str(statistics.mean(AbsError))\n",
        "            StdAbsError = str(statistics.stdev(AbsError))\n",
        "\n",
        "            print('MeanError: '+MeanError)\n",
        "            print('StdError: '+StdError)\n",
        "            print('MeanAbsError: '+MeanAbsError)\n",
        "            print('StdAbsError: '+StdAbsError)\n",
        "\n",
        "            \n",
        "            #result_analysis.csv作成（ファイルがなければ）\n",
        "            if os.path.exists(FILENAME_RESULT_ANALYSISCSV) == False:\n",
        "                columns = []\n",
        "                index = [\"AveError\", \"StdError\", \"AveAbsError\", \"StdAbsError\"]\n",
        "                df_result_analysis = pd.DataFrame(index=index, columns=columns)\n",
        "                df_result_analysis.to_csv(FILENAME_RESULT_ANALYSISCSV)\n",
        "            else:\n",
        "                print(FILENAME_RESULT_ANALYSISCSV + \" already exists!\")\n",
        "\n",
        "            df_result_analysis = pd.read_csv(FILENAME_RESULT_ANALYSISCSV, index_col=0)\n",
        "            df_result_analysis[MODEL_NAME+\"_\"+str(i)] = [MeanError, StdError, MeanAbsError, StdAbsError]\n",
        "\n",
        "\n",
        "            PATH = MODEL_PATH+'/'+MODEL_NAME+'.csv'\n",
        "            df_result_analysis.to_csv(FILENAME_RESULT_ANALYSISCSV, index=True)\n",
        "            \n",
        "\n",
        "\n",
        "            # Drawing learning curves\n",
        "            # visualize the loss as the network trained\n",
        "            fig = plt.figure(figsize=(10,8))\n",
        "            plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "            plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "            # find position of lowest validation loss\n",
        "            minposs = valid_loss.index(min(valid_loss))+1 \n",
        "            plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "            plt.xlabel('epochs')\n",
        "            plt.ylabel('loss')\n",
        "            plt.ylim(0, 0.1) # consistent scale\n",
        "            plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "            plt.grid(True)\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "            #result.csv作成（ファイルがなければ）\n",
        "            if os.path.exists(FILENAME_RESULTCSV) == False:\n",
        "                df_result = df_labelcsv.copy()\n",
        "                df_result.to_csv(FILENAME_RESULTCSV, index=False)\n",
        "            else:\n",
        "                print(FILENAME_RESULTCSV + \" already exists!\")\n",
        "\n",
        "            df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "            #print(df_result)\n",
        "            print(\"Calculating prediction results!\")\n",
        "\n",
        "            #valフォルダ内のファイル名を取得\n",
        "            train_data_path = glob.glob(DATASET_NAME + \"/\" +str(i) + \"/\" + TRAIN_FOLDER_NAME+\"/*\")\n",
        "            val_data_path = glob.glob(DATASET_NAME + \"/\" + str(i) + \"/\" + VAL_FOLDER_NAME+\"/*\")\n",
        "\n",
        "            data_path = [train_data_path, val_data_path]\n",
        "            k=0\n",
        "            for j in data_path:\n",
        "                for m in j:\n",
        "                      #print(m)\n",
        "                      #print(os.path.splitext(os.path.basename(m))[0])\n",
        "                      image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前（拡張子なし）とラベルを取得\n",
        "                      image_tensor = image_transform(m)  #予測のための画像下処理\n",
        "                      pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "                      write_result(df_result, image_name, pred, MODEL_NAME+\"_\"+str(i))\n",
        "                      #print(str(k)+\"/\"+str(len(df_result)) + \" images processed! label: \"+str(label)+ \" , pred: \"+str(pred))\n",
        "                      k+=1\n",
        "            #print(df_result)\n",
        "\n",
        "            #Resultファイルを書き出し\n",
        "            df_result.to_csv(FILENAME_RESULTCSV, index=False)\n",
        "\n",
        "\n",
        "            # calculate elapsed time\n",
        "            elapsed_time = int(time.time() - start_time)\n",
        "\n",
        "            # convert second to hour, minute and seconds\n",
        "            elapsed_hour = elapsed_time // 3600\n",
        "            elapsed_minute = (elapsed_time % 3600) // 60\n",
        "            elapsed_second = (elapsed_time % 3600 % 60)\n",
        "\n",
        "            # print as 00:00:00\n",
        "            print(str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start cropped_2, 0 th analysis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg_lhEMldF5v"
      },
      "source": [
        "#**Load network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rVSslGCJNPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed575fe8-4639-4774-9a36-0768cbf84415"
      },
      "source": [
        "name = \"macula_2\"\n",
        "model = \"A2\"  #A2 or B3\n",
        "\n",
        "MODEL_NAME = name +\"_\"+model+\"_pretrained\"\n",
        "DATASET_NAME = name+'_img_trainval'\n",
        "DATASET_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto'\n",
        "NET_NAME = \"RepVGG_\" +model  #RepVGG_A2 or RepVGG_B3\n",
        "PRETRAINED = True\n",
        "\n",
        "TRAIN_FOLDER_NAME = 'train' #TRAINイメージのフォルダ\n",
        "VAL_FOLDER_NAME = 'val' #VALイメージのフォルダ\n",
        "\n",
        "FILENAME_LABELCSV = 'name_age.csv' #年齢の値のcsv\n",
        "FILENAME_RESULTCSV = 'result_2.csv' #年齢推定結果を書き出すcsv\n",
        "FILENAME_RESULT_ANALYSISCSV = 'result_analysis_2.csv' #推定結果の解析結果を書き出すcsv\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/Deep_learning/FundusPhoto/model'\n",
        "#OPTIMIZER_PATH = \"./optimizer_multi.pth\"\n",
        "\n",
        "if NET_NAME == \"RepVGG_A2\":\n",
        "    model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "elif NET_NAME == \"RepVGG_B3\":\n",
        "    model_ft = create_RepVGG_B3(deploy=False)\n",
        "\n",
        "else:\n",
        "    print(\"RepVGG_A2あるいはRepVGG_B3を指定して下さい\")\n",
        "    sys.exit(1)\n",
        "\n",
        "#model_ft.load_state_dict(torch.load(MODEL_PATH)) \n",
        "model_ft = mod_RepVGG()\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7Jlr21roBg"
      },
      "source": [
        "#ここからがメイン\n",
        "process = [0,1,2,3,4]\n",
        "for i in process:\n",
        "    print(\"Start \"+ str(i) + \" th analysis!\")\n",
        "\n",
        "    #トレーニングしたパラメーターを適用\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    model_ft.load_state_dict(torch.load(PATH))\n",
        "    model_ft.eval()\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    print(PATH)\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    #valフォルダ内のファイル名を取得\n",
        "    train_data_path = glob.glob(DATASET_NAME + \"/\" +str(i) + \"/\" + TRAIN_FOLDER_NAME+\"/*\")\n",
        "    val_data_path = glob.glob(DATASET_NAME + \"/\" + str(i) + \"/\" + VAL_FOLDER_NAME+\"/*\")\n",
        "\n",
        "    data_path = [train_data_path, val_data_path]\n",
        "    preds,targets,errors =[], [], []\n",
        "    k=0\n",
        "    for j in data_path:\n",
        "        for m in j:\n",
        "              image_name, label = getlabel(df_result, os.path.splitext(os.path.basename(m))[0])  #画像の名前とラベルを取得\n",
        "              image_tensor = image_transform(m)  #予測のための画像下処理\n",
        "              pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "              write_result(df_result, image_name, pred, MODEL_NAME+\"_\"+str(i))\n",
        "              print(str(k)+\"/\"+str(len(df_result))+\" th image: \"+str(image_name)+\", pred: \"+str(my_round(pred, d=1))+\", label: \"+str(label))\n",
        "\n",
        "              preds.append(pred)      \n",
        "              targets.append(label)\n",
        "              errors.append(pred-label)\n",
        "\n",
        "              k+=1\n",
        "    print(df_result)\n",
        "\n",
        "    AbsError = [abs(i) for i in errors]\n",
        "    MeanError = str(statistics.mean(errors))\n",
        "    StdError = str(statistics.stdev(errors))\n",
        "    MeanAbsError = str(statistics.mean(AbsError))\n",
        "    StdAbsError = str(statistics.stdev(AbsError))\n",
        "    print('MeanError: '+MeanError)\n",
        "    print('StdError: '+StdError)\n",
        "    print('MeanAbsError: '+MeanAbsError)\n",
        "    print('StdAbsError: '+StdAbsError)\n",
        "    print()\n",
        "\n",
        "    #Resultファイルを書き出し\n",
        "    df_result.to_csv(FILENAME_RESULTCSV, index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdMWm5gkEsXa",
        "outputId": "642f43dc-b323-470b-93f7-3f30f9a70175"
      },
      "source": [
        "#######################\n",
        "##1枚の画像のみを判定\n",
        "#######################\n",
        "\n",
        "print(MODEL_PATH)\n",
        "print(MODEL_NAME)\n",
        "\n",
        "#ファイル名を取得\n",
        "img_name = \"img00085008_00_1R.png\"\n",
        "img_path1 = \"/content/drive/MyDrive/Deep_learning/FundusPhoto/\"+name+\"_img_trainval/0/train/\"+img_name\n",
        "img_path2 = \"/content/drive/MyDrive/Deep_learning/FundusPhoto/\"+name+\"_img_trainval/0/val/\"+img_name\n",
        "\n",
        "for i in [img_path1, img_path2]:\n",
        "    is_file = os.path.isfile(i)\n",
        "    if is_file:\n",
        "        img_path = i\n",
        "        print(\"aaa\")\n",
        "    else:\n",
        "        pass # パスが存在しないかファイルではない\n",
        "        print(\"bbb\")\n",
        "\n",
        "\n",
        "outputs = []\n",
        "for i in range(5):\n",
        "    #トレーニングしたパラメーターを適用\n",
        "    PATH = MODEL_PATH+'/'+MODEL_NAME+'_'+str(i)+'.pth'\n",
        "    model_ft.load_state_dict(torch.load(PATH))\n",
        "    model_ft.eval()\n",
        "\n",
        "    df_result = pd.read_csv(FILENAME_RESULTCSV)\n",
        "    print(MODEL_NAME+'_'+str(i)+'.pth')\n",
        "    print(\"Calculating prediction results!\")\n",
        "\n",
        "    image_tensor = image_transform(img_path)  #予測のための画像下処理\n",
        "    pred = image_eval(image_tensor, model_ft)  #予測結果を出力   \n",
        "\n",
        "    outputs.append(pred)\n",
        "\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/FundusPhoto/model\n",
            "macula_2_A2_pretrained\n",
            "aaa\n",
            "bbb\n",
            "macula_2_A2_pretrained_0.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_1.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_2.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_3.pth\n",
            "Calculating prediction results!\n",
            "macula_2_A2_pretrained_4.pth\n",
            "Calculating prediction results!\n",
            "[44.820716977119446, 68.22026371955872, 54.96704578399658, 54.79089617729187, 50.11647343635559]\n"
          ]
        }
      ]
    }
  ]
}